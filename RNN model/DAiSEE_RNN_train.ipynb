{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DAiSEE_RNN_train.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM3zZEjk/+Q6pJI/mBH7hCd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["https://keras.io/examples/vision/video_classification/"],"metadata":{"id":"LlbtXNGHWs0G"}},{"cell_type":"code","source":["# === Imports === #\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","\n","from tqdm import tqdm\n","\n","# Various python packages are used in this notebook. Please get yourself used to them (optional).\n","import pandas as pd  # used for storing a tabular representation of the dataset, similar to XLS files.\n","from pathlib import Path # used to check if the saved model files and accessories.\n","import requests #used to request remote judge.csv evaluation \n","from sklearn.preprocessing import StandardScaler  # used for normalization of dataset\n","from sklearn.preprocessing   import LabelBinarizer    # used for splitting the gender column\n","from sklearn.preprocessing   import MinMaxScaler      # used for normalization of dataset\n","from sklearn.model_selection import train_test_split  # used for performing the train-test split of a dataframe\n","import cv2                                            # OpenCV used for image processing\n","import random   #random number generator\n","import datetime #used to get current date/time\n","import math     #math/numerical functions\n","import os       #os specific functions, like file open/close etc.\n","import gc       #garbage collection module -- used to manually clean up memory spaces/references.\n","\n","\n","from sklearn.preprocessing import OneHotEncoder   #My favorite categorical to numerical feature conversion tool\n","from tensorflow import keras  # keras used for construction of the Artificial neural network\n","from keras.models import Model, Sequential #keras model architectures\n","from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D #types of layers\n","from keras.losses import mean_squared_error, huber, log_cosh  #built-in loss \n","from tensorflow.python.keras.saving import hdf5_format  #used for saving models \n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard  #callbacks\n","from keras.models import model_from_json  #used for loading model architecture from json file\n","import h5py  #saved model type\n","\n","import matplotlib.pyplot as plt  # used for training visualization\n","import numpy as np  # numpy arrays used for matrix computations\n","\n","# === Extra Configurations for the GPU Environment === #\n","import tensorflow as tf\n","physical_devices = tf.config.list_physical_devices('GPU') \n","if len(physical_devices)>0: #If you have at least one \"configured\" GPU, let's use it; otherwise, pass\n","    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n","\n","# https://github.com/zaid478/Transfer-Learning-from-Xception-Model-in-Keras-/blob/master/transfer_learn.py\n","\n","from keras.applications import xception\n","from keras import backend as K\n","from keras.utils import np_utils\n","\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n","\n","import pickle "],"metadata":{"id":"VOMh4LFxDbL2","executionInfo":{"status":"ok","timestamp":1650004247652,"user_tz":360,"elapsed":3558,"user":{"displayName":"James Thiering","userId":"02262056658604878482"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Setting work environment with dataset. If on Google colaboratory, we need to extract dataset stored in google drive,\n","otherwise the dataset is already there.\n","\"\"\"\n","try:\n","    from google.colab import drive\n","    print('Running on Google colab...')\n","    drive.mount('/content/drive')\n","except:\n","    print('Running on local machine...')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D21GsWN-CCy9","executionInfo":{"status":"ok","timestamp":1650004248188,"user_tz":360,"elapsed":540,"user":{"displayName":"James Thiering","userId":"02262056658604878482"}},"outputId":"d37a8cba-c4af-41a9-84d7-765a046b6622"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on Google colab...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# IMPORTANT PARAMETERS"],"metadata":{"id":"hs5sRWTO9OyD"}},{"cell_type":"code","source":["preprocessor_folder = 'gen-rnn-7'\n","\n","train_path = 'drive/MyDrive/Colab Notebooks/DAiSEE/'+preprocessor_folder+'/Train/'\n","test_path = 'drive/MyDrive/Colab Notebooks/DAiSEE/'+preprocessor_folder+'/Test/'\n","\n","image_shape = (224, 299, 3) # HEIGHT, WIDTH, CHANNELS\n","\n","#IMG_SIZE = 224\n","BATCH_SIZE = 64\n","EPOCHS = 50\n","\n","MAX_SEQ_LENGTH = 10\n","NUM_FEATURES = 2048"],"metadata":{"id":"gN52UDNE9OkO","executionInfo":{"status":"ok","timestamp":1650006727903,"user_tz":360,"elapsed":133,"user":{"displayName":"James Thiering","userId":"02262056658604878482"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# Build a feature extractor"],"metadata":{"id":"iOqN6MfCHilD"}},{"cell_type":"code","source":["def build_feature_extractor():\n","    feature_extractor = keras.applications.InceptionV3(\n","        weights=\"imagenet\",\n","        include_top=False,\n","        pooling=\"avg\",\n","        input_shape=image_shape,\n","    )\n","    preprocess_input = keras.applications.inception_v3.preprocess_input\n","\n","    inputs = keras.Input(image_shape)\n","    preprocessed = preprocess_input(inputs)\n","\n","    outputs = feature_extractor(preprocessed)\n","    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n","\n","\n","feature_extractor = build_feature_extractor()"],"metadata":{"id":"Z87ORte19p33","executionInfo":{"status":"ok","timestamp":1650004253361,"user_tz":360,"elapsed":5174,"user":{"displayName":"James Thiering","userId":"02262056658604878482"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly"],"metadata":{"id":"SHtOo-WqSWVy"}},{"cell_type":"code","source":["class DataGenerator(tf.keras.utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, path, list_IDs, labels, batch_size=32, dim=(480,640), n_channels=3,\n","                 n_classes=4, shuffle=True):\n","        self.dim = dim\n","        self.batch_size = batch_size\n","        self.labels = labels\n","        self.list_IDs = list_IDs\n","        self.path = path\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        # Find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","\n","        # Generate data\n","        X, y = self.__data_generation(indexes)\n","\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, list_IDs_temp):\n","        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n","        # Initialization\n","        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n","        y = np.empty((self.batch_size, 4), dtype='float32')\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            filename = os.path.join(self.path, self.list_IDs[ID])\n","            filehandler = open(filename, 'rb') \n","            x = pickle.load(filehandler)\n","            X[i,] = x\n","            y[i,:] = tf.one_hot(self.labels[ID][1], depth=4)\n","\n","        #### DO INFERENCE ON CNN MODEL #####\n","\n","        # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n","        # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n","        # masked with padding or not.\n","        frame_masks = np.zeros(shape=(self.batch_size, MAX_SEQ_LENGTH), dtype=\"bool\")\n","        frame_features = np.zeros(\n","            shape=(self.batch_size, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n","        )\n","\n","        # For each video.\n","        for i in range(X.shape[0]):\n","        #for idx, path in enumerate(video_paths):\n","            # Gather all its frames and add a batch dimension.\n","            frames = X[i]\n","            frames = frames[None, ...]\n","\n","            # Initialize placeholders to store the masks and features of the current video.\n","            temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n","            temp_frame_features = np.zeros(\n","                shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n","            )\n","\n","            # Extract features from the frames of the current video.\n","            for i, batch in enumerate(frames):\n","                video_length = batch.shape[0]\n","                length = min(MAX_SEQ_LENGTH, video_length)\n","                for j in range(length):\n","                    temp_frame_features[i, j, :] = feature_extractor.predict(\n","                        batch[None, j, :]\n","                    )\n","                temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n","\n","            frame_features[i,] = temp_frame_features.squeeze()\n","            frame_masks[i,] = temp_frame_mask.squeeze()\n","\n","        ### END INFERENCE ###\n","\n","        #print(tf.convert_to_tensor(y).shape)\n","\n","        return (frame_features, frame_masks), tf.convert_to_tensor(y)"],"metadata":{"id":"PYUPtMD2tpbx","executionInfo":{"status":"ok","timestamp":1650004253362,"user_tz":360,"elapsed":4,"user":{"displayName":"James Thiering","userId":"02262056658604878482"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import os\n","import shutil\n","#os.getcwd()\n","\n","temp_data_location = 'temp_data'\n","\n","if temp_data_location in os.listdir(os.getcwd()):\n","    shutil.rmtree(temp_data_location)\n","\n","os.mkdir(temp_data_location)\n","\n","#assert temp_data_location not in os.listdir(os.getcwd())\n","\n","\n","local_train_path = os.path.join(temp_data_location, 'train')\n","local_test_path = os.path.join(temp_data_location, 'test') \n","\n","# Copytree makes the folders\n","#os.mkdir(local_train_path)\n","#os.mkdir(local_test_path)\n","\n","shutil.copytree(train_path, local_train_path) \n","shutil.copytree(test_path, local_test_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"3Qns-HBP6pun","executionInfo":{"status":"ok","timestamp":1650004779701,"user_tz":360,"elapsed":526342,"user":{"displayName":"James Thiering","userId":"02262056658604878482"}},"outputId":"4e3036a0-0133-4939-84cc-018c4e7dc164"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'temp_data/test'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Generator Parameters\n","params = {'dim': (MAX_SEQ_LENGTH, image_shape[0], image_shape[1]),\n","          'batch_size': BATCH_SIZE,\n","          'n_classes': 4,\n","          'n_channels': 3,\n","          'shuffle': True}\n","\n","folder_path = './drive/MyDrive/Colab Notebooks/DAiSEE/'\n","all_labels = pd.read_csv(os.path.join(folder_path, 'Labels/AllLabels.csv'))\n","all_labels['ID_num'] = all_labels['ClipID'].str[:-4]\n","\n","train_labels = pd.read_csv(os.path.join(folder_path, 'Labels/TrainLabels.csv'))\n","train_labels['ID_num'] = train_labels['ClipID'].str[:-4]\n","\n","test_labels = pd.read_csv(os.path.join(folder_path, 'Labels/TestLabels.csv'))\n","test_labels['ID_num'] = test_labels['ClipID'].str[:-4]\n","\n","# Train Set\n","file_labels = []\n","print(\"building train set\")\n","for filename in tqdm(os.listdir(local_train_path)):\n","    try:\n","        #sample_ID = filename[:filename.index('-')]\n","        sample_ID = filename[:-4]\n","        label = all_labels[all_labels['ID_num']==sample_ID].values.tolist()[0][1:-1]\n","        file_labels.append((filename, np.array(label)))\n","    except IndexError:\n","        print(sample_ID)\n","\n","label_arr = np.array(file_labels, dtype=object)\n","X_train = label_arr[:, 0]\n","y_train = label_arr[:, 1]\n","\n","# Test Set\n","file_labels = []\n","print(\"building test set\")\n","for filename in tqdm(os.listdir(local_test_path)):\n","    try:\n","        #sample_ID = filename[:filename.index('-')]\n","        sample_ID = filename[:-4]\n","        \n","        label = test_labels[test_labels['ID_num']==sample_ID].values.tolist()[0][1:-1]\n","        file_labels.append((filename, np.array(label)))\n","    except IndexError:\n","        print(sample_ID)\n","\n","label_arr = np.array(file_labels, dtype=object)\n","X_test = label_arr[:, 0]\n","y_test = label_arr[:, 1]"],"metadata":{"id":"8R8qKEZUtmTx","executionInfo":{"status":"ok","timestamp":1650006741276,"user_tz":360,"elapsed":6963,"user":{"displayName":"James Thiering","userId":"02262056658604878482"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fd020a5c-0089-445f-925d-f9052054838a"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["building train set\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5482/5482 [00:05<00:00, 984.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["building test set\n"]},{"output_type":"stream","name":"stderr","text":[" 18%|█▊        | 331/1866 [00:00<00:00, 1657.68it/s]"]},{"output_type":"stream","name":"stdout","text":["9988260143\n","9988260248\n","9988260241\n","9988260137\n","998826022\n","9988260264\n","9988260247\n","9988260215\n","9988260254\n","9988260259\n","9988260144\n","9988260273\n","9988260152\n","9988260126\n","9988260165\n","9988260141\n","9988260134\n","998826019\n","9988260250\n"]},{"output_type":"stream","name":"stderr","text":[" 45%|████▌     | 841/1866 [00:00<00:00, 1698.95it/s]"]},{"output_type":"stream","name":"stdout","text":["9988260240\n","9988260127\n","9988260212\n","9988260237\n","9988260130\n","9988260138\n","9988260132\n","9988260232\n","9988260276\n","9988260281\n","9988260275\n","9988260150\n","9988260257\n","9988260145\n","9988260224\n","9988260227\n","998826017\n"]},{"output_type":"stream","name":"stderr","text":[" 73%|███████▎  | 1363/1866 [00:00<00:00, 1663.87it/s]"]},{"output_type":"stream","name":"stdout","text":["9988260236\n","9988260210\n","9988260214\n","9988260133\n","9988260123\n","9988260217\n","9988260251\n","9988260211\n","998826016\n","9988260242\n","9988260245\n","998826026\n","9988260228\n","998826014\n","9988260279\n","9988260255\n","9988260163\n","9988260160\n","9988260222\n","9988260167\n","9988260246\n","9988260146\n","9988260230\n","9988260139\n","9988260270\n","9988260249\n","9988260277\n","9988260216\n","9988260243\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1866/1866 [00:01<00:00, 1663.88it/s]"]},{"output_type":"stream","name":"stdout","text":["998826021\n","9988260121\n","9988260239\n","9988260157\n","9988260231\n","9988260269\n","998826024\n","9988260268\n","9988260235\n","998826013\n","9988260135\n","9988260229\n","9988260154\n","9988260233\n","9988260129\n","9988260234\n","998826023\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["X_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"keKY7tzhVSbx","executionInfo":{"status":"ok","timestamp":1650004786564,"user_tz":360,"elapsed":18,"user":{"displayName":"James Thiering","userId":"02262056658604878482"}},"outputId":"e6a071ee-acf1-4a51-f21c-41d6db6f0730"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1784,)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DlwtmfYouyw2","executionInfo":{"status":"ok","timestamp":1650004786564,"user_tz":360,"elapsed":15,"user":{"displayName":"James Thiering","userId":"02262056658604878482"}},"outputId":"6a18ac00-e79f-4a9d-f072-cd39bfc98cbc"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1784,)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["y_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjHex-pTVUEU","executionInfo":{"status":"ok","timestamp":1650004786564,"user_tz":360,"elapsed":14,"user":{"displayName":"James Thiering","userId":"02262056658604878482"}},"outputId":"2ec4cc9c-bcca-4b8e-cbf4-f2de80182d4e"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([array([1, 2, 1, 1]), array([0, 3, 1, 0]), array([0, 2, 0, 0]), ...,\n","       array([1, 3, 0, 0]), array([1, 2, 0, 0]), array([0, 2, 3, 2])],\n","      dtype=object)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Generators\n","training_generator = DataGenerator(local_train_path, X_train, y_train, **params)\n","validation_generator = DataGenerator(local_test_path, X_test, y_test, **params) "],"metadata":{"id":"IoXYxDuy1X65","executionInfo":{"status":"ok","timestamp":1650006745923,"user_tz":360,"elapsed":160,"user":{"displayName":"James Thiering","userId":"02262056658604878482"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["'''\n","class_weight = {0: 75.,\n","                1: 10.,\n","                2: 1.,\n","                3: 1.}\n","'''\n","class_weight = {0: 1.,\n","                1: 1.,\n","                2: 1.,\n","                3: 1.}"],"metadata":{"id":"t6iQBFAtojoK","executionInfo":{"status":"ok","timestamp":1650004786565,"user_tz":360,"elapsed":13,"user":{"displayName":"James Thiering","userId":"02262056658604878482"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# RNN"],"metadata":{"id":"iUL2wYS9uzQT"}},{"cell_type":"code","source":["%reload_ext tensorboard\n","model_path = os.path.join(folder_path, 'saved_models/model_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '_.sav')\n","log_dir = os.path.join(folder_path, \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","\n","tensorboard_cbk = TensorBoard(log_dir=log_dir, histogram_freq=1)\n","early_stopping_cbk = EarlyStopping(monitor='val_accuracy', patience=10, verbose=0, mode='min')\n","mcp_save_cbk = ModelCheckpoint(model_path+'.mcp.hdf5', save_best_only=True, monitor='val_accuracy', mode='min')\n","reduce_lr_plateau_cbk = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, mode='min')\n","#callbacks = [early_stopping_cbk, mcp_save_cbk, reduce_lr_plateau_cbk, tensorboard_cbk]\n","callbacks = [mcp_save_cbk, tensorboard_cbk]"],"metadata":{"id":"Jm4cbl5VQVe1","executionInfo":{"status":"ok","timestamp":1650004786687,"user_tz":360,"elapsed":134,"user":{"displayName":"James Thiering","userId":"02262056658604878482"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class_vocab = 4\n","\n","frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n","mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n","\n","# Refer to the following tutorial to understand the significance of using `mask`:\n","# https://keras.io/api/layers/recurrent_layers/gru/\n","x = keras.layers.GRU(128, return_sequences=True)(\n","    frame_features_input, mask=mask_input\n",")\n","x = keras.layers.GRU(64)(x)\n","x = keras.layers.Dropout(0.4)(x)\n","x = keras.layers.Dense(64, activation=\"relu\")(x) # Increase last FC layer nodes??\n","output = keras.layers.Dense(4, activation=\"softmax\")(x)\n","\n","rnn_model = keras.Model([frame_features_input, mask_input], output)\n","\n","#loss = \"sparse_categorical_crossentropy\" ### Requires integer labels\n","loss = 'categorical_crossentropy'\n","\n","rnn_model.compile(\n","    loss=loss, optimizer=\"adam\", metrics=[\"accuracy\"]\n",")"],"metadata":{"id":"OhObO9XFKc50","executionInfo":{"status":"ok","timestamp":1650004789120,"user_tz":360,"elapsed":2434,"user":{"displayName":"James Thiering","userId":"02262056658604878482"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["history = rnn_model.fit(\n","    training_generator,\n","    validation_data=validation_generator,\n","    epochs=EPOCHS,\n","    batch_size = BATCH_SIZE,\n","    callbacks=callbacks\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":747},"id":"uEDVEU4kKh6J","executionInfo":{"status":"error","timestamp":1650039107362,"user_tz":360,"elapsed":32344042,"user":{"displayName":"James Thiering","userId":"02262056658604878482"}},"outputId":"382cac1a-6b94-41db-aa0b-d04b76f72ba2"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","85/85 [==============================] - 4149s 49s/step - loss: 0.8675 - accuracy: 0.4710 - val_loss: 0.8737 - val_accuracy: 0.4525\n","Epoch 2/50\n","85/85 [==============================] - 4072s 48s/step - loss: 0.8652 - accuracy: 0.4811 - val_loss: 0.8723 - val_accuracy: 0.4971\n","Epoch 3/50\n","85/85 [==============================] - 4016s 47s/step - loss: 0.8646 - accuracy: 0.4831 - val_loss: 0.8731 - val_accuracy: 0.4919\n","Epoch 4/50\n","85/85 [==============================] - 3987s 47s/step - loss: 0.8662 - accuracy: 0.4790 - val_loss: 0.8667 - val_accuracy: 0.4959\n","Epoch 5/50\n","85/85 [==============================] - 4013s 47s/step - loss: 0.8650 - accuracy: 0.4818 - val_loss: 0.8652 - val_accuracy: 0.4936\n","Epoch 6/50\n","85/85 [==============================] - 4023s 47s/step - loss: 0.8657 - accuracy: 0.4838 - val_loss: 0.8705 - val_accuracy: 0.4965\n","Epoch 7/50\n","85/85 [==============================] - 4020s 47s/step - loss: 0.8655 - accuracy: 0.4800 - val_loss: 0.8650 - val_accuracy: 0.4959\n","Epoch 8/50\n","85/85 [==============================] - ETA: 0s - loss: 0.8655 - accuracy: 0.4752 "]},{"output_type":"error","ename":"FailedPreconditionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-f1909d7b56ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorboard/plugins/scalar/summary_v2.py\u001b[0m in \u001b[0;36mscalar\u001b[0;34m(name, data, step, description)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msummary_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         )\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFailedPreconditionError\u001b[0m: drive/MyDrive/Colab Notebooks/DAiSEE/logs/fit/20220415-063947/validation/events.out.tfevents.1650009958.391c6e8e6494.361882.2.v2; Transport endpoint is not connected\n\tFailed to flush 1 events to ./drive/MyDrive/Colab Notebooks/DAiSEE/logs/fit/20220415-063947/validation/events.out.tfevents.1650009958.391c6e8e6494.361882.2.v2\n\tCould not flush events file. [Op:WriteSummary]"]}]}]}