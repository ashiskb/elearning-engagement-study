{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this notebook:\n",
    "- Implement attribute-orthogonal multi-task training\n",
    "- Train a model for engagement grading with the DAiSEE dataset\n",
    "\n",
    "### Status:\n",
    "- Multi-task training is implemented, but overfitting on the test set for gender\n",
    "- attribute-orthogonal loss still needs to be implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "- This requires a folder structure similar to:\n",
    "\n",
    "parent directory<br>\n",
    "├─this notebook<br>\n",
    "├─/dataset<br>\n",
    "│  ├─/GenderClips<br>\n",
    "│  │  ├─Females<br>\n",
    "│  │  └─Males<br>\n",
    "│  ├─/Labels<br>\n",
    "│  ├─/Test<br>\n",
    "│  ├─/Train<br>\n",
    "│  └─/Validation<br>\n",
    "├─/OUI gender dataset<br>\n",
    "│  └─/OUI_model.h5\n",
    "\n",
    "- Note: .gitignore includes the /dataset folder so that it can be co-located with the git repo for ease of use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sections\n",
    "[section 1](#section1)<br />\n",
    "[section 2](#section2)<br />\n",
    "[section 3](#section3)<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5960,
     "status": "ok",
     "timestamp": 1649616990205,
     "user": {
      "displayName": "James Thiering",
      "userId": "02262056658604878482"
     },
     "user_tz": 360
    },
    "id": "VOMh4LFxDbL2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd  # used for storing a tabular representation of the dataset, similar to XLS files.\n",
    "from pathlib import Path # used to check if the saved model files and accessories.\n",
    "import requests #used to request remote judge.csv evaluation \n",
    "from sklearn.preprocessing import StandardScaler  # used for normalization of dataset\n",
    "from sklearn.preprocessing   import LabelBinarizer    # used for splitting the gender column\n",
    "from sklearn.preprocessing   import MinMaxScaler      # used for normalization of dataset\n",
    "from sklearn.model_selection import train_test_split  # used for performing the train-test split of a dataframe\n",
    "import cv2                                            # OpenCV used for image processing\n",
    "import random   #random number generator\n",
    "import datetime #used to get current date/time\n",
    "import math     #math/numerical functions\n",
    "import os       #os specific functions, like file open/close etc.\n",
    "import gc       #garbage collection module -- used to manually clean up memory spaces/references.\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder   #My favorite categorical to numerical feature conversion tool\n",
    "from tensorflow import keras  # keras used for construction of the Artificial neural network\n",
    "from keras.models import Model, Sequential #keras model architectures\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D #types of layers\n",
    "from keras.losses import mean_squared_error, huber, log_cosh  #built-in loss \n",
    "from tensorflow.python.keras.saving import hdf5_format  #used for saving models \n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard  #callbacks\n",
    "from keras.models import model_from_json  #used for loading model architecture from json file\n",
    "import h5py  #saved model type\n",
    "\n",
    "import matplotlib.pyplot as plt  # used for training visualization\n",
    "import numpy as np  # numpy arrays used for matrix computations\n",
    "\n",
    "from keras.applications import xception\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "# File handling imports\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# === Extra Configurations for the GPU Environment === #\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "if len(physical_devices)>0: #If you have at least one \"configured\" GPU, let's use it; otherwise, pass\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "print(f'Discovered devices: {physical_devices}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_spec = tf.DeviceSpec(job =\"localhost\", replica = 0, device_type = \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Spec:  /job:localhost/replica:0/device:CPU:*\n"
     ]
    }
   ],
   "source": [
    "print('Device Spec: ', device_spec.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "- https://github.com/zaid478/Transfer-Learning-from-Xception-Model-in-Keras-/blob/master/transfer_learn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hs5sRWTO9OyD"
   },
   "source": [
    "# Important Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1649617004555,
     "user": {
      "displayName": "James Thiering",
      "userId": "02262056658604878482"
     },
     "user_tz": 360
    },
    "id": "gN52UDNE9OkO"
   },
   "outputs": [],
   "source": [
    "train_path = 'dataset/Train/'\n",
    "test_path = 'dataset/Test/'\n",
    "image_shape = (224, 299, 3) # HEIGHT, WIDTH, CHANNELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOqN6MfCHilD"
   },
   "source": [
    "# Train a new Xception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4439,
     "status": "ok",
     "timestamp": 1649617008991,
     "user": {
      "displayName": "James Thiering",
      "userId": "02262056658604878482"
     },
     "user_tz": 360
    },
    "id": "agbrvwtvHlck",
    "outputId": "8cb237b1-ffa7-4f15-9afd-e2d2e8d0ecba"
   },
   "outputs": [],
   "source": [
    "xception_tl = tf.keras.applications.Xception(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=image_shape,\n",
    "    pooling=None,\n",
    "    classes=4,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1649617008992,
     "user": {
      "displayName": "James Thiering",
      "userId": "02262056658604878482"
     },
     "user_tz": 360
    },
    "id": "vLcjutnAH9ys"
   },
   "outputs": [],
   "source": [
    "# Freeze training on all layers\n",
    "for layer in xception_tl.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-task model references\n",
    "https://medium.com/swlh/multi-task-learning-with-tf-keras-5b28dd60246e <br>\n",
    "https://datascience.stackexchange.com/questions/27498/multi-task-learning-in-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/api/layers/initializers/\n",
    "initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1649617008992,
     "user": {
      "displayName": "James Thiering",
      "userId": "02262056658604878482"
     },
     "user_tz": 360
    },
    "id": "LvUg3bslEvab"
   },
   "outputs": [],
   "source": [
    "x = xception_tl.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(rate=0.50)(x)\n",
    "\n",
    "bifurcation = Dense(\n",
    "    128,\n",
    "    activation='relu',\n",
    "    name='bifurcation_layer',\n",
    "    kernel_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
    ")(x)\n",
    "\n",
    "cls1 = Dense(64, activation='relu', name='cls1_learning_layer', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=1.))(bifurcation)\n",
    "cls1b = Dense(32, activation='relu', name='cls1b_learning_layer', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=1.))(cls1)\n",
    "cls1_y = Dense(4, activation='softmax', name='cls1_output', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=1.))(cls1b)\n",
    "\n",
    "cls2 = Dense(64, activation='relu', name='cls2_learning_layer', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=1.))(bifurcation)\n",
    "cls2b = Dense(32, activation='relu', name='cls2b_learning_layer', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=1.))(cls2)\n",
    "cls2_y = Dense(1, activation='sigmoid', name='cls2_output', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=1.))(cls2b)\n",
    "\n",
    "xception_tl_DAiSEE=Model(inputs=xception_tl.input, outputs=[cls1_y, cls2_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1649617008992,
     "user": {
      "displayName": "James Thiering",
      "userId": "02262056658604878482"
     },
     "user_tz": 360
    },
    "id": "zOsBUKv5KlJe",
    "outputId": "eb1fd78b-ab13-4d1e-e563-e1fd8d3a7fda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'cls1_output')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'cls2_output')>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xception_tl_DAiSEE.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 111, 149, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv1_bn (BatchNormaliz  (None, 111, 149, 32  128        ['block1_conv1[0][0]']           \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv1_act (Activation)  (None, 111, 149, 32  0           ['block1_conv1_bn[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 109, 147, 64  18432       ['block1_conv1_act[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2_bn (BatchNormaliz  (None, 109, 147, 64  256        ['block1_conv2[0][0]']           \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2_act (Activation)  (None, 109, 147, 64  0           ['block1_conv2_bn[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2_sepconv1 (SeparableConv  (None, 109, 147, 12  8768       ['block1_conv2_act[0][0]']       \n",
      " 2D)                            8)                                                                \n",
      "                                                                                                  \n",
      " block2_sepconv1_bn (BatchNorma  (None, 109, 147, 12  512        ['block2_sepconv1[0][0]']        \n",
      " lization)                      8)                                                                \n",
      "                                                                                                  \n",
      " block2_sepconv2_act (Activatio  (None, 109, 147, 12  0          ['block2_sepconv1_bn[0][0]']     \n",
      " n)                             8)                                                                \n",
      "                                                                                                  \n",
      " block2_sepconv2 (SeparableConv  (None, 109, 147, 12  17536      ['block2_sepconv2_act[0][0]']    \n",
      " 2D)                            8)                                                                \n",
      "                                                                                                  \n",
      " block2_sepconv2_bn (BatchNorma  (None, 109, 147, 12  512        ['block2_sepconv2[0][0]']        \n",
      " lization)                      8)                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 55, 74, 128)  8192        ['block1_conv2_act[0][0]']       \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 55, 74, 128)  0           ['block2_sepconv2_bn[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 55, 74, 128)  512        ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 55, 74, 128)  0           ['block2_pool[0][0]',            \n",
      "                                                                  'batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " block3_sepconv1_act (Activatio  (None, 55, 74, 128)  0          ['add[0][0]']                    \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block3_sepconv1 (SeparableConv  (None, 55, 74, 256)  33920      ['block3_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block3_sepconv1_bn (BatchNorma  (None, 55, 74, 256)  1024       ['block3_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3_sepconv2_act (Activatio  (None, 55, 74, 256)  0          ['block3_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block3_sepconv2 (SeparableConv  (None, 55, 74, 256)  67840      ['block3_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block3_sepconv2_bn (BatchNorma  (None, 55, 74, 256)  1024       ['block3_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 28, 37, 256)  32768       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 28, 37, 256)  0           ['block3_sepconv2_bn[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 28, 37, 256)  1024       ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 28, 37, 256)  0           ['block3_pool[0][0]',            \n",
      "                                                                  'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " block4_sepconv1_act (Activatio  (None, 28, 37, 256)  0          ['add_1[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block4_sepconv1 (SeparableConv  (None, 28, 37, 728)  188672     ['block4_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block4_sepconv1_bn (BatchNorma  (None, 28, 37, 728)  2912       ['block4_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4_sepconv2_act (Activatio  (None, 28, 37, 728)  0          ['block4_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block4_sepconv2 (SeparableConv  (None, 28, 37, 728)  536536     ['block4_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4_sepconv2_bn (BatchNorma  (None, 28, 37, 728)  2912       ['block4_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 14, 19, 728)  186368      ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 14, 19, 728)  0           ['block4_sepconv2_bn[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 14, 19, 728)  2912       ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 14, 19, 728)  0           ['block4_pool[0][0]',            \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " block5_sepconv1_act (Activatio  (None, 14, 19, 728)  0          ['add_2[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block5_sepconv1 (SeparableConv  (None, 14, 19, 728)  536536     ['block5_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5_sepconv1_bn (BatchNorma  (None, 14, 19, 728)  2912       ['block5_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5_sepconv2_act (Activatio  (None, 14, 19, 728)  0          ['block5_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block5_sepconv2 (SeparableConv  (None, 14, 19, 728)  536536     ['block5_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5_sepconv2_bn (BatchNorma  (None, 14, 19, 728)  2912       ['block5_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5_sepconv3_act (Activatio  (None, 14, 19, 728)  0          ['block5_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block5_sepconv3 (SeparableConv  (None, 14, 19, 728)  536536     ['block5_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5_sepconv3_bn (BatchNorma  (None, 14, 19, 728)  2912       ['block5_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 14, 19, 728)  0           ['block5_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " block6_sepconv1_act (Activatio  (None, 14, 19, 728)  0          ['add_3[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block6_sepconv1 (SeparableConv  (None, 14, 19, 728)  536536     ['block6_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6_sepconv1_bn (BatchNorma  (None, 14, 19, 728)  2912       ['block6_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6_sepconv2_act (Activatio  (None, 14, 19, 728)  0          ['block6_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block6_sepconv2 (SeparableConv  (None, 14, 19, 728)  536536     ['block6_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6_sepconv2_bn (BatchNorma  (None, 14, 19, 728)  2912       ['block6_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6_sepconv3_act (Activatio  (None, 14, 19, 728)  0          ['block6_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block6_sepconv3 (SeparableConv  (None, 14, 19, 728)  536536     ['block6_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6_sepconv3_bn (BatchNorma  (None, 14, 19, 728)  2912       ['block6_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 14, 19, 728)  0           ['block6_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " block7_sepconv1_act (Activatio  (None, 14, 19, 728)  0          ['add_4[0][0]']                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block7_sepconv1 (SeparableConv  (None, 14, 19, 728)  536536     ['block7_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block7_sepconv1_bn (BatchNorma  (None, 14, 19, 728)  2912       ['block7_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block7_sepconv2_act (Activatio  (None, 14, 19, 728)  0          ['block7_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block7_sepconv2 (SeparableConv  (None, 14, 19, 728)  536536     ['block7_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block7_sepconv2_bn (BatchNorma  (None, 14, 19, 728)  2912       ['block7_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block7_sepconv3_act (Activatio  (None, 14, 19, 728)  0          ['block7_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block7_sepconv3 (SeparableConv  (None, 14, 19, 728)  536536     ['block7_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block7_sepconv3_bn (BatchNorma  (None, 14, 19, 728)  2912       ['block7_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 14, 19, 728)  0           ['block7_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " block8_sepconv1_act (Activatio  (None, 14, 19, 728)  0          ['add_5[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block8_sepconv1 (SeparableConv  (None, 14, 19, 728)  536536     ['block8_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block8_sepconv1_bn (BatchNorma  (None, 14, 19, 728)  2912       ['block8_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block8_sepconv2_act (Activatio  (None, 14, 19, 728)  0          ['block8_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block8_sepconv2 (SeparableConv  (None, 14, 19, 728)  536536     ['block8_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block8_sepconv2_bn (BatchNorma  (None, 14, 19, 728)  2912       ['block8_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block8_sepconv3_act (Activatio  (None, 14, 19, 728)  0          ['block8_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block8_sepconv3 (SeparableConv  (None, 14, 19, 728)  536536     ['block8_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block8_sepconv3_bn (BatchNorma  (None, 14, 19, 728)  2912       ['block8_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 14, 19, 728)  0           ['block8_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " block9_sepconv1_act (Activatio  (None, 14, 19, 728)  0          ['add_6[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block9_sepconv1 (SeparableConv  (None, 14, 19, 728)  536536     ['block9_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block9_sepconv1_bn (BatchNorma  (None, 14, 19, 728)  2912       ['block9_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block9_sepconv2_act (Activatio  (None, 14, 19, 728)  0          ['block9_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block9_sepconv2 (SeparableConv  (None, 14, 19, 728)  536536     ['block9_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block9_sepconv2_bn (BatchNorma  (None, 14, 19, 728)  2912       ['block9_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block9_sepconv3_act (Activatio  (None, 14, 19, 728)  0          ['block9_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block9_sepconv3 (SeparableConv  (None, 14, 19, 728)  536536     ['block9_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block9_sepconv3_bn (BatchNorma  (None, 14, 19, 728)  2912       ['block9_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 14, 19, 728)  0           ['block9_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " block10_sepconv1_act (Activati  (None, 14, 19, 728)  0          ['add_7[0][0]']                  \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block10_sepconv1 (SeparableCon  (None, 14, 19, 728)  536536     ['block10_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block10_sepconv1_bn (BatchNorm  (None, 14, 19, 728)  2912       ['block10_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block10_sepconv2_act (Activati  (None, 14, 19, 728)  0          ['block10_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block10_sepconv2 (SeparableCon  (None, 14, 19, 728)  536536     ['block10_sepconv2_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block10_sepconv2_bn (BatchNorm  (None, 14, 19, 728)  2912       ['block10_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block10_sepconv3_act (Activati  (None, 14, 19, 728)  0          ['block10_sepconv2_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block10_sepconv3 (SeparableCon  (None, 14, 19, 728)  536536     ['block10_sepconv3_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block10_sepconv3_bn (BatchNorm  (None, 14, 19, 728)  2912       ['block10_sepconv3[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 14, 19, 728)  0           ['block10_sepconv3_bn[0][0]',    \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " block11_sepconv1_act (Activati  (None, 14, 19, 728)  0          ['add_8[0][0]']                  \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block11_sepconv1 (SeparableCon  (None, 14, 19, 728)  536536     ['block11_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block11_sepconv1_bn (BatchNorm  (None, 14, 19, 728)  2912       ['block11_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block11_sepconv2_act (Activati  (None, 14, 19, 728)  0          ['block11_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block11_sepconv2 (SeparableCon  (None, 14, 19, 728)  536536     ['block11_sepconv2_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block11_sepconv2_bn (BatchNorm  (None, 14, 19, 728)  2912       ['block11_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block11_sepconv3_act (Activati  (None, 14, 19, 728)  0          ['block11_sepconv2_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block11_sepconv3 (SeparableCon  (None, 14, 19, 728)  536536     ['block11_sepconv3_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block11_sepconv3_bn (BatchNorm  (None, 14, 19, 728)  2912       ['block11_sepconv3[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 14, 19, 728)  0           ['block11_sepconv3_bn[0][0]',    \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " block12_sepconv1_act (Activati  (None, 14, 19, 728)  0          ['add_9[0][0]']                  \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block12_sepconv1 (SeparableCon  (None, 14, 19, 728)  536536     ['block12_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block12_sepconv1_bn (BatchNorm  (None, 14, 19, 728)  2912       ['block12_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block12_sepconv2_act (Activati  (None, 14, 19, 728)  0          ['block12_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block12_sepconv2 (SeparableCon  (None, 14, 19, 728)  536536     ['block12_sepconv2_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block12_sepconv2_bn (BatchNorm  (None, 14, 19, 728)  2912       ['block12_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " block12_sepconv3_act (Activati  (None, 14, 19, 728)  0          ['block12_sepconv2_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block12_sepconv3 (SeparableCon  (None, 14, 19, 728)  536536     ['block12_sepconv3_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block12_sepconv3_bn (BatchNorm  (None, 14, 19, 728)  2912       ['block12_sepconv3[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 14, 19, 728)  0           ['block12_sepconv3_bn[0][0]',    \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " block13_sepconv1_act (Activati  (None, 14, 19, 728)  0          ['add_10[0][0]']                 \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block13_sepconv1 (SeparableCon  (None, 14, 19, 728)  536536     ['block13_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block13_sepconv1_bn (BatchNorm  (None, 14, 19, 728)  2912       ['block13_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block13_sepconv2_act (Activati  (None, 14, 19, 728)  0          ['block13_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block13_sepconv2 (SeparableCon  (None, 14, 19, 1024  752024     ['block13_sepconv2_act[0][0]']   \n",
      " v2D)                           )                                                                 \n",
      "                                                                                                  \n",
      " block13_sepconv2_bn (BatchNorm  (None, 14, 19, 1024  4096       ['block13_sepconv2[0][0]']       \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 7, 10, 1024)  745472      ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " block13_pool (MaxPooling2D)    (None, 7, 10, 1024)  0           ['block13_sepconv2_bn[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 7, 10, 1024)  4096       ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 7, 10, 1024)  0           ['block13_pool[0][0]',           \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " block14_sepconv1 (SeparableCon  (None, 7, 10, 1536)  1582080    ['add_11[0][0]']                 \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block14_sepconv1_bn (BatchNorm  (None, 7, 10, 1536)  6144       ['block14_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block14_sepconv1_act (Activati  (None, 7, 10, 1536)  0          ['block14_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block14_sepconv2 (SeparableCon  (None, 7, 10, 2048)  3159552    ['block14_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block14_sepconv2_bn (BatchNorm  (None, 7, 10, 2048)  8192       ['block14_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block14_sepconv2_act (Activati  (None, 7, 10, 2048)  0          ['block14_sepconv2_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['block14_sepconv2_act[0][0]']   \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2048)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " bifurcation_layer (Dense)      (None, 128)          262272      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " cls1_learning_layer (Dense)    (None, 64)           8256        ['bifurcation_layer[0][0]']      \n",
      "                                                                                                  \n",
      " cls2_learning_layer (Dense)    (None, 64)           8256        ['bifurcation_layer[0][0]']      \n",
      "                                                                                                  \n",
      " cls1b_learning_layer (Dense)   (None, 32)           2080        ['cls1_learning_layer[0][0]']    \n",
      "                                                                                                  \n",
      " cls2b_learning_layer (Dense)   (None, 32)           2080        ['cls2_learning_layer[0][0]']    \n",
      "                                                                                                  \n",
      " cls1_output (Dense)            (None, 4)            132         ['cls1b_learning_layer[0][0]']   \n",
      "                                                                                                  \n",
      " cls2_output (Dense)            (None, 1)            33          ['cls2b_learning_layer[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,144,589\n",
      "Trainable params: 283,109\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xception_tl_DAiSEE.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create labels list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_dataset_location = './dataset/Validation'\n",
    "\n",
    "labels = pd.read_csv(os.path.join(os.getcwd(), 'dataset', 'Labels', 'AllLabels.csv'))\n",
    "females = pd.read_csv(os.path.join(os.getcwd(), 'dataset', 'GenderClips', 'Females'), header=None)\n",
    "males = pd.read_csv(os.path.join(os.getcwd(), 'dataset', 'GenderClips', 'Males'), header=None)\n",
    "\n",
    "females_list = [x[0] for x in females.values.tolist()]\n",
    "males_list = [x[0] for x in males.values.tolist()]\n",
    "\n",
    "# Add gender feature columns\n",
    "labels['male'] = labels.apply(lambda x: x['ClipID'] in males_list, axis=1)\n",
    "labels['female'] = labels.apply(lambda x: x['ClipID'] in females_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClipID</th>\n",
       "      <th>Boredom</th>\n",
       "      <th>Engagement</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Frustration</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1100011003.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100011004.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100011005.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100011006.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8920</th>\n",
       "      <td>9877360164.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8921</th>\n",
       "      <td>9877360165.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8922</th>\n",
       "      <td>9877360166.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8923</th>\n",
       "      <td>9877360168.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8924</th>\n",
       "      <td>9877360169.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8925 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ClipID  Boredom  Engagement  Confusion  Frustration    male  \\\n",
       "0     1100011002.avi        0           2          0             0   True   \n",
       "1     1100011003.avi        0           2          0             0   True   \n",
       "2     1100011004.avi        0           3          0             0   True   \n",
       "3     1100011005.avi        0           3          0             0   True   \n",
       "4     1100011006.avi        0           3          0             0   True   \n",
       "...              ...      ...         ...        ...           ...    ...   \n",
       "8920  9877360164.avi        1           3          0             0  False   \n",
       "8921  9877360165.avi        0           3          0             0  False   \n",
       "8922  9877360166.avi        1           3          0             2  False   \n",
       "8923  9877360168.avi        1           3          1             1  False   \n",
       "8924  9877360169.avi        0           1          0             0  False   \n",
       "\n",
       "      female  \n",
       "0      False  \n",
       "1      False  \n",
       "2      False  \n",
       "3      False  \n",
       "4      False  \n",
       "...      ...  \n",
       "8920    True  \n",
       "8921    True  \n",
       "8922    True  \n",
       "8923    True  \n",
       "8924    True  \n",
       "\n",
       "[8925 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLabels = pd.read_csv(os.path.join(os.getcwd(), 'dataset', 'Labels', 'TestLabels.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1100011002.avi',\n",
       " '1100011003.avi',\n",
       " '1100011004.avi',\n",
       " '1100011005.avi',\n",
       " '1100011006.avi',\n",
       " '1100011007.avi',\n",
       " '1100011008.avi',\n",
       " '1100011009.avi',\n",
       " '1100011010.avi',\n",
       " '1100011011.avi',\n",
       " '1100011012.avi',\n",
       " '1100011013.avi',\n",
       " '1100011014.avi',\n",
       " '1100011015.avi',\n",
       " '1100011016.avi',\n",
       " '1100011017.avi',\n",
       " '1100011018.avi',\n",
       " '1100011019.avi',\n",
       " '1100011020.avi',\n",
       " '1100011021.avi',\n",
       " '1100011022.avi',\n",
       " '1100011023.avi',\n",
       " '1100011025.avi',\n",
       " '1100011026.avi',\n",
       " '1100011027.avi',\n",
       " '1100011028.avi',\n",
       " '1100011029.avi',\n",
       " '1100011031.avi',\n",
       " '1100011032.avi',\n",
       " '1100011034.avi',\n",
       " '1100011035.avi',\n",
       " '1100011037.avi',\n",
       " '1100011038.avi',\n",
       " '1100011040.avi',\n",
       " '1100011046.avi',\n",
       " '1100011047.avi',\n",
       " '1100011048.avi',\n",
       " '1100011049.avi',\n",
       " '1100011050.avi',\n",
       " '1100011051.avi',\n",
       " '1100011052.avi',\n",
       " '1100011053.avi',\n",
       " '1100011054.avi',\n",
       " '1100011055.avi',\n",
       " '1100011056.avi',\n",
       " '1100011057.avi',\n",
       " '1100011058.avi',\n",
       " '1100011059.avi',\n",
       " '1100011060.avi',\n",
       " '1100011062.avi',\n",
       " '1100011063.avi',\n",
       " '1100011064.avi',\n",
       " '1100011066.avi',\n",
       " '1100011067.avi',\n",
       " '1100011068.avi',\n",
       " '1100011069.avi',\n",
       " '1100011070.avi',\n",
       " '1100011071.avi',\n",
       " '1100011072.avi',\n",
       " '1100011073.avi',\n",
       " '1100011075.avi',\n",
       " '1100011076.avi',\n",
       " '1100011078.avi',\n",
       " '1100011079.avi',\n",
       " '1100011080.avi',\n",
       " '1100011081.avi',\n",
       " '1100011082.avi',\n",
       " '1100011083.avi',\n",
       " '1100012001.avi',\n",
       " '1100012003.avi',\n",
       " '1100012007.avi',\n",
       " '1100012008.avi',\n",
       " '1100012009.avi',\n",
       " '1100012010.avi',\n",
       " '1100012011.avi',\n",
       " '1100012013.avi',\n",
       " '1100012014.avi',\n",
       " '1100012015.avi',\n",
       " '1100012016.avi',\n",
       " '1100012017.avi',\n",
       " '1100012018.avi',\n",
       " '1100012021.avi',\n",
       " '1100012022.avi',\n",
       " '1100012023.avi',\n",
       " '1100012025.avi',\n",
       " '1100012026.avi',\n",
       " '1100012027.avi',\n",
       " '1100012028.avi',\n",
       " '1100012030.avi',\n",
       " '1100012031.avi',\n",
       " '1100012032.avi',\n",
       " '1100012033.avi',\n",
       " '1100012036.avi',\n",
       " '1100012037.avi',\n",
       " '1100012038.avi',\n",
       " '1100012041.avi',\n",
       " '1100012042.avi',\n",
       " '1100012045.avi',\n",
       " '1100012046.avi',\n",
       " '1100012047.avi',\n",
       " '1100012049.avi',\n",
       " '1100012050.avi',\n",
       " '1100012051.avi',\n",
       " '1100012052.avi',\n",
       " '1100012057.avi',\n",
       " '1100012059.avi',\n",
       " '1100012060.avi',\n",
       " '1100012061.avi',\n",
       " '1100012062.avi',\n",
       " '1100012063.avi',\n",
       " '1100012064.avi',\n",
       " '1100012065.avi',\n",
       " '1100012066.avi',\n",
       " '1100012069.avi',\n",
       " '1100021001.avi',\n",
       " '1100021003.avi',\n",
       " '1100021015.avi',\n",
       " '1100021038.avi',\n",
       " '1100021039.avi',\n",
       " '1100021040.avi',\n",
       " '1100021045.avi',\n",
       " '1100021050.avi',\n",
       " '1100021055.avi',\n",
       " '1100022001.avi',\n",
       " '1100022002.avi',\n",
       " '1100022003.avi',\n",
       " '1100022004.avi',\n",
       " '1100022005.avi',\n",
       " '1100022008.avi',\n",
       " '1100022009.avi',\n",
       " '1100022014.avi',\n",
       " '1100022019.avi',\n",
       " '1100022020.avi',\n",
       " '1100022021.avi',\n",
       " '1100022022.avi',\n",
       " '1100022026.avi',\n",
       " '1100022027.avi',\n",
       " '1100022028.avi',\n",
       " '1100022029.avi',\n",
       " '1100022031.avi',\n",
       " '1100022035.avi',\n",
       " '1100022038.avi',\n",
       " '1100022039.avi',\n",
       " '1100022045.avi',\n",
       " '1100022046.avi',\n",
       " '1100022047.avi',\n",
       " '1100022048.avi',\n",
       " '1100022049.avi',\n",
       " '1100022051.avi',\n",
       " '1100022052.avi',\n",
       " '1100022053.avi',\n",
       " '1100022054.avi',\n",
       " '1100022055.avi',\n",
       " '1100022056.avi',\n",
       " '1100022057.avi',\n",
       " '1100041006.avi',\n",
       " '1100041015.avi',\n",
       " '1100041016.avi',\n",
       " '1100041017.avi',\n",
       " '1100041018.avi',\n",
       " '1100041021.avi',\n",
       " '1100041022.avi',\n",
       " '1100041023.avi',\n",
       " '1100041024.avi',\n",
       " '1100041029.avi',\n",
       " '1100041034.avi',\n",
       " '1100041044.avi',\n",
       " '1100041051.avi',\n",
       " '1100041052.avi',\n",
       " '1100042009.avi',\n",
       " '1100042010.avi',\n",
       " '1100042011.avi',\n",
       " '1100042017.avi',\n",
       " '1100042018.avi',\n",
       " '1100042019.avi',\n",
       " '1100042020.avi',\n",
       " '1100042023.avi',\n",
       " '1100042024.avi',\n",
       " '1100042025.avi',\n",
       " '1100042026.avi',\n",
       " '1100042029.avi',\n",
       " '1100042030.avi',\n",
       " '1100042031.avi',\n",
       " '1100042034.avi',\n",
       " '1100042040.avi',\n",
       " '1100042041.avi',\n",
       " '1100042058.avi',\n",
       " '1100042059.avi',\n",
       " '1100042060.avi',\n",
       " '1100051002.avi',\n",
       " '1100051004.avi',\n",
       " '1100051006.avi',\n",
       " '1100051007.avi',\n",
       " '1100051008.avi',\n",
       " '1100051009.avi',\n",
       " '1100051011.avi',\n",
       " '1100051012.avi',\n",
       " '1100051013.avi',\n",
       " '1100051014.avi',\n",
       " '1100051016.avi',\n",
       " '1100051017.avi',\n",
       " '1100051019.avi',\n",
       " '1100051020.avi',\n",
       " '1100051021.avi',\n",
       " '1100051022.avi',\n",
       " '1100051023.avi',\n",
       " '1100051024.avi',\n",
       " '1100051025.avi',\n",
       " '1100051026.avi',\n",
       " '1100051028.avi',\n",
       " '1100051029.avi',\n",
       " '1100051030.avi',\n",
       " '1100051031.avi',\n",
       " '1100051032.avi',\n",
       " '1100051033.avi',\n",
       " '1100051034.avi',\n",
       " '1100051035.avi',\n",
       " '1100051036.avi',\n",
       " '1100051037.avi',\n",
       " '1100051039.avi',\n",
       " '1100051041.avi',\n",
       " '1100051042.avi',\n",
       " '1100051044.avi',\n",
       " '1100051045.avi',\n",
       " '1100051046.avi',\n",
       " '1100051048.avi',\n",
       " '1100051049.avi',\n",
       " '1100051050.avi',\n",
       " '1100051051.avi',\n",
       " '1100051052.avi',\n",
       " '1100051053.avi',\n",
       " '1100051054.avi',\n",
       " '1100051055.avi',\n",
       " '1100051056.avi',\n",
       " '1100051057.avi',\n",
       " '1100051059.avi',\n",
       " '1100051061.avi',\n",
       " '1100051062.avi',\n",
       " '1100051064.avi',\n",
       " '1100051065.avi',\n",
       " '1100051066.avi',\n",
       " '1100051067.avi',\n",
       " '1100051068.avi',\n",
       " '1100051071.avi',\n",
       " '1100051076.avi',\n",
       " '1100051078.avi',\n",
       " '1100051079.avi',\n",
       " '1100052001.avi',\n",
       " '1100052002.avi',\n",
       " '1100052006.avi',\n",
       " '1100052007.avi',\n",
       " '1100052008.avi',\n",
       " '1100052009.avi',\n",
       " '1100052014.avi',\n",
       " '1100052023.avi',\n",
       " '1100052024.avi',\n",
       " '1100052026.avi',\n",
       " '1100052027.avi',\n",
       " '1100052028.avi',\n",
       " '1100052030.avi',\n",
       " '1100052031.avi',\n",
       " '1100052032.avi',\n",
       " '1100052033.avi',\n",
       " '1100052035.avi',\n",
       " '1100052036.avi',\n",
       " '1100052037.avi',\n",
       " '1100052038.avi',\n",
       " '1100052039.avi',\n",
       " '1100052040.avi',\n",
       " '1100052041.avi',\n",
       " '1100052047.avi',\n",
       " '1100052048.avi',\n",
       " '1100052049.avi',\n",
       " '1100052051.avi',\n",
       " '1100052055.avi',\n",
       " '1100052057.avi',\n",
       " '1100052060.avi',\n",
       " '1100052061.avi',\n",
       " '1100052062.avi',\n",
       " '1100052065.avi',\n",
       " '1100052068.avi',\n",
       " '1100052070.avi',\n",
       " '1100061009.avi',\n",
       " '1100061010.avi',\n",
       " '1100061011.avi',\n",
       " '1100061012.avi',\n",
       " '1100061013.avi',\n",
       " '1100061015.avi',\n",
       " '1100061016.avi',\n",
       " '1100061018.avi',\n",
       " '1100061019.avi',\n",
       " '1100061022.avi',\n",
       " '1100061023.avi',\n",
       " '1100061025.avi',\n",
       " '1100061027.avi',\n",
       " '1100061028.avi',\n",
       " '1100061030.avi',\n",
       " '1100061031.avi',\n",
       " '1100061032.avi',\n",
       " '1100061033.avi',\n",
       " '1100061034.avi',\n",
       " '1100061035.avi',\n",
       " '1100061036.avi',\n",
       " '1100061038.avi',\n",
       " '1100061039.avi',\n",
       " '1100061040.avi',\n",
       " '1100061042.avi',\n",
       " '1100061043.avi',\n",
       " '1100061044.avi',\n",
       " '1100061046.avi',\n",
       " '1100061047.avi',\n",
       " '1100061048.avi',\n",
       " '1100061049.avi',\n",
       " '1100061050.avi',\n",
       " '1100061051.avi',\n",
       " '1100061053.avi',\n",
       " '1100061057.avi',\n",
       " '1100061058.avi',\n",
       " '1100061061.avi',\n",
       " '1100061063.avi',\n",
       " '1100061064.avi',\n",
       " '1100061067.avi',\n",
       " '1100061068.avi',\n",
       " '1100061069.avi',\n",
       " '1100061073.avi',\n",
       " '1100061074.avi',\n",
       " '1100061077.avi',\n",
       " '1100061078.avi',\n",
       " '1100062004.avi',\n",
       " '1100062005.avi',\n",
       " '1100062007.avi',\n",
       " '1100062008.avi',\n",
       " '1100062009.avi',\n",
       " '1100062016.avi',\n",
       " '1100062017.avi',\n",
       " '1100062024.avi',\n",
       " '1100062028.avi',\n",
       " '1100062029.avi',\n",
       " '1100062036.avi',\n",
       " '1100062037.avi',\n",
       " '1100062044.avi',\n",
       " '1100062045.avi',\n",
       " '1100062046.avi',\n",
       " '1100062049.avi',\n",
       " '1100062051.avi',\n",
       " '1100062053.avi',\n",
       " '1100062054.avi',\n",
       " '1100062059.avi',\n",
       " '1100062060.avi',\n",
       " '1100062061.avi',\n",
       " '1100062062.avi',\n",
       " '1100062063.avi',\n",
       " '1100062064.avi',\n",
       " '1100062065.avi',\n",
       " '1100062066.avi',\n",
       " '1100062067.avi',\n",
       " '1100062068.avi',\n",
       " '1100062069.avi',\n",
       " '1100062070.avi',\n",
       " '1100062071.avi',\n",
       " '1100062072.avi',\n",
       " '1100071005.avi',\n",
       " '1100071006.avi',\n",
       " '1100071007.avi',\n",
       " '1100071008.avi',\n",
       " '1100071009.avi',\n",
       " '1100071010.avi',\n",
       " '1100071011.avi',\n",
       " '1100071012.avi',\n",
       " '1100071013.avi',\n",
       " '1100071014.avi',\n",
       " '1100071015.avi',\n",
       " '1100071016.avi',\n",
       " '1100071017.avi',\n",
       " '1100071018.avi',\n",
       " '1100071019.avi',\n",
       " '1100071020.avi',\n",
       " '1100071021.avi',\n",
       " '1100071022.avi',\n",
       " '1100071023.avi',\n",
       " '1100071024.avi',\n",
       " '1100071026.avi',\n",
       " '1100071027.avi',\n",
       " '1100071028.avi',\n",
       " '1100071029.avi',\n",
       " '1100071030.avi',\n",
       " '1100071031.avi',\n",
       " '1100071032.avi',\n",
       " '1100071033.avi',\n",
       " '1100071034.avi',\n",
       " '1100071035.avi',\n",
       " '1100071036.avi',\n",
       " '1100071037.avi',\n",
       " '1100071040.avi',\n",
       " '1100071041.avi',\n",
       " '1100071042.avi',\n",
       " '1100071043.avi',\n",
       " '1100071044.avi',\n",
       " '1100071045.avi',\n",
       " '1100071046.avi',\n",
       " '1100071047.avi',\n",
       " '1100071049.avi',\n",
       " '1100071050.avi',\n",
       " '1100071052.avi',\n",
       " '1100071054.avi',\n",
       " '1100071055.avi',\n",
       " '1100071056.avi',\n",
       " '1100071057.avi',\n",
       " '1100071058.avi',\n",
       " '1100071059.avi',\n",
       " '1100071060.avi',\n",
       " '1100071061.avi',\n",
       " '1100071062.avi',\n",
       " '1100071063.avi',\n",
       " '1100071064.avi',\n",
       " '1100071065.avi',\n",
       " '1100071066.avi',\n",
       " '1100071067.avi',\n",
       " '1100071069.avi',\n",
       " '1100071070.avi',\n",
       " '1100071071.avi',\n",
       " '1100071072.avi',\n",
       " '1100071073.avi',\n",
       " '1100071074.avi',\n",
       " '1100071075.avi',\n",
       " '1100071076.avi',\n",
       " '1100071077.avi',\n",
       " '1100071078.avi',\n",
       " '1100071079.avi',\n",
       " '1100071080.avi',\n",
       " '1100071081.avi',\n",
       " '1100072001.avi',\n",
       " '1100072002.avi',\n",
       " '1100072003.avi',\n",
       " '1100072004.avi',\n",
       " '1100072006.avi',\n",
       " '1100072007.avi',\n",
       " '1100072008.avi',\n",
       " '1100072009.avi',\n",
       " '1100072010.avi',\n",
       " '1100072011.avi',\n",
       " '1100072012.avi',\n",
       " '1100072013.avi',\n",
       " '1100072014.avi',\n",
       " '1100072015.avi',\n",
       " '1100072016.avi',\n",
       " '1100072021.avi',\n",
       " '1100072022.avi',\n",
       " '1100072023.avi',\n",
       " '1100072024.avi',\n",
       " '1100072027.avi',\n",
       " '1100072028.avi',\n",
       " '1100072029.avi',\n",
       " '1100072030.avi',\n",
       " '1100072031.avi',\n",
       " '1100072032.avi',\n",
       " '1100072033.avi',\n",
       " '1100072034.avi',\n",
       " '1100072036.avi',\n",
       " '1100072037.avi',\n",
       " '1100072038.avi',\n",
       " '1100072039.avi',\n",
       " '1100072040.avi',\n",
       " '1100072042.avi',\n",
       " '1100072043.avi',\n",
       " '1100072045.avi',\n",
       " '1100072047.avi',\n",
       " '1100072048.avi',\n",
       " '1100072049.avi',\n",
       " '1100072050.avi',\n",
       " '1100072051.avi',\n",
       " '1100072052.avi',\n",
       " '1100072053.avi',\n",
       " '1100072054.avi',\n",
       " '1100072056.avi',\n",
       " '1100072057.avi',\n",
       " '1100072058.avi',\n",
       " '1100072059.avi',\n",
       " '1100072060.avi',\n",
       " '1100072061.avi',\n",
       " '1100072062.avi',\n",
       " '1100072063.avi',\n",
       " '1100072065.avi',\n",
       " '1100072066.avi',\n",
       " '1100072067.avi',\n",
       " '1100072068.avi',\n",
       " '1100072069.avi',\n",
       " '1100072070.avi',\n",
       " '1100072071.avi',\n",
       " '1100072072.avi',\n",
       " '1100072073.avi',\n",
       " '1100072074.avi',\n",
       " '1100072075.avi',\n",
       " '1100072076.avi',\n",
       " '1100072077.avi',\n",
       " '1100072078.avi',\n",
       " '1100072079.avi',\n",
       " '1100072080.avi',\n",
       " '1100072081.avi',\n",
       " '1100072082.avi',\n",
       " '1100072083.avi',\n",
       " '1100072084.avi',\n",
       " '1100072085.avi',\n",
       " '1100081044.avi',\n",
       " '1100081045.avi',\n",
       " '1100081046.avi',\n",
       " '1100081047.avi',\n",
       " '1100081048.avi',\n",
       " '1100082002.avi',\n",
       " '1100082003.avi',\n",
       " '1100082018.avi',\n",
       " '1100082027.avi',\n",
       " '1100102003.avi',\n",
       " '1100111001.avi',\n",
       " '1100111002.avi',\n",
       " '1100111003.avi',\n",
       " '1100111008.avi',\n",
       " '1100111009.avi',\n",
       " '1100111010.avi',\n",
       " '1100111011.avi',\n",
       " '1100111012.avi',\n",
       " '1100111013.avi',\n",
       " '1100111014.avi',\n",
       " '1100111016.avi',\n",
       " '1100111017.avi',\n",
       " '1100111018.avi',\n",
       " '1100111019.avi',\n",
       " '1100111021.avi',\n",
       " '1100111023.avi',\n",
       " '1100111025.avi',\n",
       " '1100111026.avi',\n",
       " '1100111027.avi',\n",
       " '1100111029.avi',\n",
       " '1100111030.avi',\n",
       " '1100111032.avi',\n",
       " '1100112001.avi',\n",
       " '1100112002.avi',\n",
       " '1100112003.avi',\n",
       " '1100112004.avi',\n",
       " '1100112006.avi',\n",
       " '1100112007.avi',\n",
       " '1100112008.avi',\n",
       " '1100112009.avi',\n",
       " '1100112010.avi',\n",
       " '1100112011.avi',\n",
       " '1100112012.avi',\n",
       " '1100112013.avi',\n",
       " '1100112014.avi',\n",
       " '1100112015.avi',\n",
       " '1100112016.avi',\n",
       " '1100112017.avi',\n",
       " '1100112018.avi',\n",
       " '1100112021.avi',\n",
       " '1100112022.avi',\n",
       " '1100112024.avi',\n",
       " '1100112025.avi',\n",
       " '1100112026.avi',\n",
       " '1100112029.avi',\n",
       " '1100112030.avi',\n",
       " '1100112033.avi',\n",
       " '1100112035.avi',\n",
       " '1100112036.avi',\n",
       " '1100112037.avi',\n",
       " '1100112038.avi',\n",
       " '1100112039.avi',\n",
       " '1100112040.avi',\n",
       " '1100112041.avi',\n",
       " '1100112042.avi',\n",
       " '1100112043.avi',\n",
       " '1100112044.avi',\n",
       " '1100112045.avi',\n",
       " '1100112047.avi',\n",
       " '1100112048.avi',\n",
       " '1100112051.avi',\n",
       " '1100112052.avi',\n",
       " '1100112053.avi',\n",
       " '1100112056.avi',\n",
       " '1100112057.avi',\n",
       " '1100112058.avi',\n",
       " '1100112059.avi',\n",
       " '1100112060.avi',\n",
       " '1100112061.avi',\n",
       " '1100112062.avi',\n",
       " '1100112063.avi',\n",
       " '1100112064.avi',\n",
       " '1100112065.avi',\n",
       " '1100112066.avi',\n",
       " '1100112068.avi',\n",
       " '1100121002.avi',\n",
       " '1100121003.avi',\n",
       " '1100121004.avi',\n",
       " '1100121005.avi',\n",
       " '1100121006.avi',\n",
       " '1100121007.avi',\n",
       " '1100121008.avi',\n",
       " '1100121009.avi',\n",
       " '1100121010.avi',\n",
       " '1100121011.avi',\n",
       " '1100121012.avi',\n",
       " '1100121015.avi',\n",
       " '1100121016.avi',\n",
       " '1100121017.avi',\n",
       " '1100121018.avi',\n",
       " '1100121019.avi',\n",
       " '1100121020.avi',\n",
       " '1100121024.avi',\n",
       " '1100121025.avi',\n",
       " '1100121028.avi',\n",
       " '1100121031.avi',\n",
       " '1100121032.avi',\n",
       " '1100121033.avi',\n",
       " '1100121034.avi',\n",
       " '1100121035.avi',\n",
       " '1100121036.avi',\n",
       " '1100121038.avi',\n",
       " '1100121040.avi',\n",
       " '1100121041.avi',\n",
       " '1100121042.avi',\n",
       " '1100121044.avi',\n",
       " '1100121045.avi',\n",
       " '1100121047.avi',\n",
       " '1100121049.avi',\n",
       " '1100121050.avi',\n",
       " '1100121052.avi',\n",
       " '1100121053.avi',\n",
       " '1100121054.avi',\n",
       " '1100121056.avi',\n",
       " '1100121057.avi',\n",
       " '1100121059.avi',\n",
       " '1100121060.avi',\n",
       " '1100121061.avi',\n",
       " '1100121064.avi',\n",
       " '1100122001.avi',\n",
       " '1100122002.avi',\n",
       " '1100122003.avi',\n",
       " '1100122005.avi',\n",
       " '1100122006.avi',\n",
       " '1100122007.avi',\n",
       " '1100122008.avi',\n",
       " '1100122009.avi',\n",
       " '1100122010.avi',\n",
       " '1100122011.avi',\n",
       " '1100122012.avi',\n",
       " '1100122013.avi',\n",
       " '1100122014.avi',\n",
       " '1100122015.avi',\n",
       " '1100122017.avi',\n",
       " '1100122018.avi',\n",
       " '1100122019.avi',\n",
       " '1100122020.avi',\n",
       " '1100122021.avi',\n",
       " '1100122023.avi',\n",
       " '1100122024.avi',\n",
       " '1100122025.avi',\n",
       " '1100122026.avi',\n",
       " '1100122031.avi',\n",
       " '1100122032.avi',\n",
       " '1100122033.avi',\n",
       " '1100122034.avi',\n",
       " '1100122035.avi',\n",
       " '1100122036.avi',\n",
       " '1100122037.avi',\n",
       " '1100122038.avi',\n",
       " '1100122039.avi',\n",
       " '1100122040.avi',\n",
       " '1100122041.avi',\n",
       " '1100122045.avi',\n",
       " '1100122047.avi',\n",
       " '1100122048.avi',\n",
       " '1100122050.avi',\n",
       " '1100122051.avi',\n",
       " '1100122052.avi',\n",
       " '1100122053.avi',\n",
       " '1100122054.avi',\n",
       " '1100122056.avi',\n",
       " '1100131006.avi',\n",
       " '1100131007.avi',\n",
       " '1100131009.avi',\n",
       " '1100131010.avi',\n",
       " '1100131011.avi',\n",
       " '1100131012.avi',\n",
       " '1100131017.avi',\n",
       " '1100131019.avi',\n",
       " '1100141001.avi',\n",
       " '1100141002.avi',\n",
       " '1100141003.avi',\n",
       " '1100141004.avi',\n",
       " '1100141005.avi',\n",
       " '1100141006.avi',\n",
       " '1100141007.avi',\n",
       " '1100141008.avi',\n",
       " '1100141009.avi',\n",
       " '1100141010.avi',\n",
       " '1100141011.avi',\n",
       " '1100141012.avi',\n",
       " '1100141013.avi',\n",
       " '1100141014.avi',\n",
       " '1100141015.avi',\n",
       " '1100141016.avi',\n",
       " '1100141017.avi',\n",
       " '1100141019.avi',\n",
       " '1100141020.avi',\n",
       " '1100141021.avi',\n",
       " '1100141023.avi',\n",
       " '1100141027.avi',\n",
       " '1100141028.avi',\n",
       " '1100141029.avi',\n",
       " '1100141030.avi',\n",
       " '1100141031.avi',\n",
       " '1100141032.avi',\n",
       " '1100141033.avi',\n",
       " '1100141034.avi',\n",
       " '1100141035.avi',\n",
       " '1100141036.avi',\n",
       " '1100141039.avi',\n",
       " '1100141040.avi',\n",
       " '1100141042.avi',\n",
       " '1100141044.avi',\n",
       " '1100141045.avi',\n",
       " '1100141046.avi',\n",
       " '1100141049.avi',\n",
       " '1100141050.avi',\n",
       " '1100141052.avi',\n",
       " '1100141053.avi',\n",
       " '1100141054.avi',\n",
       " '1100141055.avi',\n",
       " '1100141056.avi',\n",
       " '1100141057.avi',\n",
       " '1100142002.avi',\n",
       " '1100142003.avi',\n",
       " '1100142004.avi',\n",
       " '1100142007.avi',\n",
       " '1100142008.avi',\n",
       " '1100142009.avi',\n",
       " '1100142010.avi',\n",
       " '1100142011.avi',\n",
       " '1100142013.avi',\n",
       " '1100142014.avi',\n",
       " '1100142015.avi',\n",
       " '1100142017.avi',\n",
       " '1100142018.avi',\n",
       " '1100142019.avi',\n",
       " '1100142021.avi',\n",
       " '1100142022.avi',\n",
       " '1100142023.avi',\n",
       " '1100142024.avi',\n",
       " '1100142027.avi',\n",
       " '1100142028.avi',\n",
       " '1100142029.avi',\n",
       " '1100142030.avi',\n",
       " '1100142031.avi',\n",
       " '1100142032.avi',\n",
       " '1100142033.avi',\n",
       " '1100142034.avi',\n",
       " '1100142035.avi',\n",
       " '1100142038.avi',\n",
       " '1100142041.avi',\n",
       " '1100142043.avi',\n",
       " '1100142044.avi',\n",
       " '1100142045.avi',\n",
       " '1100142046.avi',\n",
       " '1100142048.avi',\n",
       " '1100142049.avi',\n",
       " '1100142050.avi',\n",
       " '1100142051.avi',\n",
       " '1100142052.avi',\n",
       " '1100142053.avi',\n",
       " '1100142056.avi',\n",
       " '1100142057.avi',\n",
       " '1100142058.avi',\n",
       " '1100142059.avi',\n",
       " '1100142060.avi',\n",
       " '1100151003.avi',\n",
       " '1100151004.avi',\n",
       " '1100151008.avi',\n",
       " '1100151009.avi',\n",
       " '1100151010.avi',\n",
       " '1100151011.avi',\n",
       " '1100151012.avi',\n",
       " '1100151013.avi',\n",
       " '1100151014.avi',\n",
       " '1100151015.avi',\n",
       " '1100151016.avi',\n",
       " '1100151017.avi',\n",
       " '1100151018.avi',\n",
       " '1100151019.avi',\n",
       " '1100151020.avi',\n",
       " '1100151021.avi',\n",
       " '1100151022.avi',\n",
       " '1100151023.avi',\n",
       " '1100151024.avi',\n",
       " '1100151028.avi',\n",
       " '1100151030.avi',\n",
       " '1100151032.avi',\n",
       " '1100151033.avi',\n",
       " '1100151035.avi',\n",
       " '1100151037.avi',\n",
       " '1100151038.avi',\n",
       " '1100151039.avi',\n",
       " '1100151040.avi',\n",
       " '1100151042.avi',\n",
       " '1100151043.avi',\n",
       " '1100151044.avi',\n",
       " '1100151047.avi',\n",
       " '1100151049.avi',\n",
       " '1100151050.avi',\n",
       " '1100151051.avi',\n",
       " '1100151052.avi',\n",
       " '1100151054.avi',\n",
       " '1100151055.avi',\n",
       " '1100151056.avi',\n",
       " '1100151057.avi',\n",
       " '1100151058.avi',\n",
       " '1100151062.avi',\n",
       " '1100152001.avi',\n",
       " '1100152004.avi',\n",
       " '1100152005.avi',\n",
       " '1100152006.avi',\n",
       " '1100152008.avi',\n",
       " '1100152009.avi',\n",
       " '1100152010.avi',\n",
       " '1100152013.avi',\n",
       " '1100152014.avi',\n",
       " '1100152015.avi',\n",
       " '1100152017.avi',\n",
       " '1100152019.avi',\n",
       " '1100152020.avi',\n",
       " '1100152022.avi',\n",
       " '1100152024.avi',\n",
       " '1100152025.avi',\n",
       " '1100152026.avi',\n",
       " '1100152027.avi',\n",
       " '1100152031.avi',\n",
       " '1100152032.avi',\n",
       " '1100152039.avi',\n",
       " '1100152040.avi',\n",
       " '1100152041.avi',\n",
       " '1100152042.avi',\n",
       " '1100152043.avi',\n",
       " '1100152048.avi',\n",
       " '1100152049.avi',\n",
       " '1100152050.avi',\n",
       " '1100152051.avi',\n",
       " '1100152055.avi',\n",
       " '1100152056.avi',\n",
       " '1100152061.avi',\n",
       " '1100152062.avi',\n",
       " '1100152067.avi',\n",
       " '1100152069.avi',\n",
       " '1100152070.avi',\n",
       " '1100161002.avi',\n",
       " '1100161004.avi',\n",
       " '1100161011.avi',\n",
       " '1100161012.avi',\n",
       " '1100161013.avi',\n",
       " '1100161014.avi',\n",
       " '1100161015.avi',\n",
       " '1100161016.avi',\n",
       " '1100161020.avi',\n",
       " '1100161021.avi',\n",
       " '1100161022.avi',\n",
       " '1100161023.avi',\n",
       " '1100161028.avi',\n",
       " '1100161029.avi',\n",
       " '1100161032.avi',\n",
       " '1100161035.avi',\n",
       " '1100161036.avi',\n",
       " '1100161038.avi',\n",
       " '1100161039.avi',\n",
       " '1100161041.avi',\n",
       " '1100161043.avi',\n",
       " '1100161044.avi',\n",
       " '1100161045.avi',\n",
       " '1100161046.avi',\n",
       " '1100161048.avi',\n",
       " '1100161050.avi',\n",
       " '1100161053.avi',\n",
       " '1100162005.avi',\n",
       " '1100162007.avi',\n",
       " '1100162011.avi',\n",
       " '1100162016.avi',\n",
       " '1100171001.avi',\n",
       " '1100171002.avi',\n",
       " '1100171004.avi',\n",
       " '1100171005.avi',\n",
       " '1100171007.avi',\n",
       " '1100171008.avi',\n",
       " '1100171009.avi',\n",
       " '1100171010.avi',\n",
       " '1100171011.avi',\n",
       " '1100171012.avi',\n",
       " '1100171013.avi',\n",
       " '1100171015.avi',\n",
       " '1100171016.avi',\n",
       " '1100171017.avi',\n",
       " '1100171019.avi',\n",
       " '1100171021.avi',\n",
       " '1100171022.avi',\n",
       " '1100171023.avi',\n",
       " '1100171031.avi',\n",
       " '1100171035.avi',\n",
       " '1100171036.avi',\n",
       " '1100171038.avi',\n",
       " '1100171039.avi',\n",
       " '1100171040.avi',\n",
       " '1100171041.avi',\n",
       " '1100171043.avi',\n",
       " '1100171045.avi',\n",
       " '1100171049.avi',\n",
       " '1100171055.avi',\n",
       " '1100171056.avi',\n",
       " '1100171057.avi',\n",
       " '1100171059.avi',\n",
       " '1100171061.avi',\n",
       " '1100171063.avi',\n",
       " '1100171064.avi',\n",
       " '1100171065.avi',\n",
       " '1100171067.avi',\n",
       " '1100171069.avi',\n",
       " '1100171070.avi',\n",
       " '1100171071.avi',\n",
       " '1100171072.avi',\n",
       " '1100171073.avi',\n",
       " '1100171074.avi',\n",
       " '1100171075.avi',\n",
       " '1100171076.avi',\n",
       " '1100171077.avi',\n",
       " '1100171078.avi',\n",
       " '1100171080.avi',\n",
       " '1100171083.avi',\n",
       " '1100172003.avi',\n",
       " '1100172004.avi',\n",
       " '1100172007.avi',\n",
       " '1100172012.avi',\n",
       " '1100172013.avi',\n",
       " '1100172014.avi',\n",
       " '1100172015.avi',\n",
       " '1100172016.avi',\n",
       " '1100172017.avi',\n",
       " '1100172018.avi',\n",
       " '1100172020.avi',\n",
       " '1100172021.avi',\n",
       " '1100172022.avi',\n",
       " '1100172026.avi',\n",
       " '1100172028.avi',\n",
       " '1100172030.avi',\n",
       " '1100172032.avi',\n",
       " '1100172033.avi',\n",
       " '1100172034.avi',\n",
       " '1100172035.avi',\n",
       " '1100172037.avi',\n",
       " '1100172039.avi',\n",
       " '1100172042.avi',\n",
       " '1100172043.avi',\n",
       " '1100172047.avi',\n",
       " '1100172050.avi',\n",
       " '1100172058.avi',\n",
       " '1100172063.avi',\n",
       " '1100172066.avi',\n",
       " '1100411010.avi',\n",
       " '1100411011.avi',\n",
       " '1100411012.avi',\n",
       " '1100411013.avi',\n",
       " '1100411015.avi',\n",
       " '1100411016.avi',\n",
       " '1100411018.avi',\n",
       " '1100411020.avi',\n",
       " '1100411023.avi',\n",
       " '1100411036.avi',\n",
       " '1100411041.avi',\n",
       " '1100411045.avi',\n",
       " '1100411047.avi',\n",
       " '1100411048.avi',\n",
       " '1100411049.avi',\n",
       " '1100411050.avi',\n",
       " '1100411051.avi',\n",
       " '1100411053.avi',\n",
       " '1100411054.avi',\n",
       " '1100411055.avi',\n",
       " '1100411057.avi',\n",
       " '1100412001.avi',\n",
       " '1100412003.avi',\n",
       " '1100412010.avi',\n",
       " '1100412018.avi',\n",
       " '1100412033.avi',\n",
       " '1100412038.avi',\n",
       " '1100412039.avi',\n",
       " '1100412040.avi',\n",
       " '1110031003.avi',\n",
       " '1110031007.avi',\n",
       " '1110031010.avi',\n",
       " '1110031011.avi',\n",
       " '1110031012.avi',\n",
       " '1110031014.avi',\n",
       " '1110031019.avi',\n",
       " '1110031020.avi',\n",
       " '1110031021.avi',\n",
       " '1110031025.avi',\n",
       " '1110031027.avi',\n",
       " '1110031031.avi',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['ClipID'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 61 samples without labels!\n"
     ]
    }
   ],
   "source": [
    "missing = len(set(testLabels['ClipID'].values.tolist()) - set(labels['ClipID'].values.tolist()))\n",
    "print(f'There are {missing} samples without labels!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['ID_num'] = labels['ClipID'].str[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to make sure that there is a binary constraint\n",
    "assert labels.loc[labels['male']!=labels['female']].shape == labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single column for gender\n",
    "labels['gender'] = labels.apply(lambda x: 1 if x['ClipID'] in males_list else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ClipID', 'Boredom', 'Engagement', 'Confusion', 'Frustration ', 'male',\n",
       "       'female', 'ID_num', 'gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.drop(['male', 'female'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're only concerned with engagement\n",
    "labels.drop(['Boredom', 'Confusion', 'Frustration '], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14357,
     "status": "ok",
     "timestamp": 1649617004554,
     "user": {
      "displayName": "James Thiering",
      "userId": "02262056658604878482"
     },
     "user_tz": 360
    },
    "id": "D21GsWN-CCy9",
    "outputId": "7fdb4fd3-3d28-4301-e607-11e214022687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       2\n",
       "2       3\n",
       "3       3\n",
       "4       3\n",
       "       ..\n",
       "8920    3\n",
       "8921    3\n",
       "8922    3\n",
       "8923    3\n",
       "8924    1\n",
       "Name: Engagement, Length: 8925, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['Engagement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ohe = pd.get_dummies(labels.Engagement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14357,
     "status": "ok",
     "timestamp": 1649617004554,
     "user": {
      "displayName": "James Thiering",
      "userId": "02262056658604878482"
     },
     "user_tz": 360
    },
    "id": "D21GsWN-CCy9",
    "outputId": "7fdb4fd3-3d28-4301-e607-11e214022687"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3\n",
       "0  0  0  1  0\n",
       "1  0  0  1  0\n",
       "2  0  0  0  1\n",
       "3  0  0  0  1\n",
       "4  0  0  0  1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14357,
     "status": "ok",
     "timestamp": 1649617004554,
     "user": {
      "displayName": "James Thiering",
      "userId": "02262056658604878482"
     },
     "user_tz": 360
    },
    "id": "D21GsWN-CCy9",
    "outputId": "7fdb4fd3-3d28-4301-e607-11e214022687"
   },
   "outputs": [],
   "source": [
    "labels_ohe['tensor'] = labels_ohe.apply(lambda x: np.array([x[0], x[1], x[2], x[3]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>tensor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8920</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8921</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8922</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8923</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8924</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8925 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3        tensor\n",
       "0     0  0  1  0  [0, 0, 1, 0]\n",
       "1     0  0  1  0  [0, 0, 1, 0]\n",
       "2     0  0  0  1  [0, 0, 0, 1]\n",
       "3     0  0  0  1  [0, 0, 0, 1]\n",
       "4     0  0  0  1  [0, 0, 0, 1]\n",
       "...  .. .. .. ..           ...\n",
       "8920  0  0  0  1  [0, 0, 0, 1]\n",
       "8921  0  0  0  1  [0, 0, 0, 1]\n",
       "8922  0  0  0  1  [0, 0, 0, 1]\n",
       "8923  0  0  0  1  [0, 0, 0, 1]\n",
       "8924  0  1  0  0  [0, 1, 0, 0]\n",
       "\n",
       "[8925 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.join(labels_ohe['tensor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.drop(['Engagement'], axis=1, inplace=True)\n",
    "labels.drop(['ClipID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_num</th>\n",
       "      <th>gender</th>\n",
       "      <th>tensor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100011002</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1100011003</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100011004</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100011005</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100011006</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID_num  gender        tensor\n",
       "0  1100011002       1  [0, 0, 1, 0]\n",
       "1  1100011003       1  [0, 0, 1, 0]\n",
       "2  1100011004       1  [0, 0, 0, 1]\n",
       "3  1100011005       1  [0, 0, 0, 1]\n",
       "4  1100011006       1  [0, 0, 0, 1]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 38374/38374 [00:31<00:00, 1200.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 samples without labels!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"building training set\")\n",
    "missing_count = 0\n",
    "train_set = []\n",
    "for filename in tqdm(os.listdir(train_path)):\n",
    "    try:\n",
    "        sample_ID = filename[:filename.index('-')]\n",
    "        #engagement = labels[labels['ID_num']==sample_ID].values.tolist()[0][1:-1]\n",
    "        #gender = labels[labels['ID_num']==sample_ID].values.tolist()[1]\n",
    "        row = labels[labels['ID_num']==sample_ID]\n",
    "        engagement = row['tensor'].values[0]\n",
    "        gender = row['gender'].values[0]\n",
    "        train_set.append([filename, engagement, gender])\n",
    "    except IndexError:\n",
    "        missing_count += 1\n",
    "print(f'There are {missing_count} samples without labels!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 13062/13062 [00:10<00:00, 1227.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1001 samples without labels!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"building test set\")\n",
    "missing_count = 0\n",
    "test_set = []\n",
    "for filename in tqdm(os.listdir(test_path)):\n",
    "    try:\n",
    "        sample_ID = filename[:filename.index('-')]\n",
    "        #engagement = labels[labels['ID_num']==sample_ID].values.tolist()[0][1:-1]\n",
    "        #gender = labels[labels['ID_num']==sample_ID].values.tolist()[1]\n",
    "        row = labels[labels['ID_num']==sample_ID]\n",
    "        engagement = row['tensor'].values[0]\n",
    "        gender = row['gender'].values[0]\n",
    "        test_set.append([filename, engagement, gender])\n",
    "    except IndexError:\n",
    "        missing_count += 1\n",
    "print(f'There are {missing_count} samples without labels!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_set, columns=['filename', 'engagement', 'gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_set, columns=['filename', 'engagement', 'gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38374.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.682050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.465686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             gender\n",
       "count  38374.000000\n",
       "mean       0.682050\n",
       "std        0.465686\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>engagement</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100011002-1.jpg</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1100011002-2.jpg</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100011002-3.jpg</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100011002-4.jpg</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100011002-5.jpg</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename    engagement  gender\n",
       "0  1100011002-1.jpg  [0, 0, 1, 0]       1\n",
       "1  1100011002-2.jpg  [0, 0, 1, 0]       1\n",
       "2  1100011002-3.jpg  [0, 0, 1, 0]       1\n",
       "3  1100011002-4.jpg  [0, 0, 1, 0]       1\n",
       "4  1100011002-5.jpg  [0, 0, 1, 0]       1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageDataGenerator concept\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "- https://studymachinelearning.com/keras-imagedatagenerator-with-flow_from_dataframe/\n",
    "- https://stackoverflow.com/questions/60621008/imagedatagenerator-for-multi-task-output-in-keras-using-flow-from-directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.xception.preprocess_input\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38374 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "training_generator = image_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=train_path,\n",
    "    x_col=\"filename\",\n",
    "    y_col=[\"engagement\", \"gender\"],\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    class_mode='multi_output'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12061 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = image_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=test_path,\n",
    "    x_col=\"filename\",\n",
    "    y_col=[\"engagement\", \"gender\"],\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    class_mode='multi_output'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Attribute Orthogonal Regularized Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthogonal_loss(y_true, y_pred, alpha=1):\n",
    "    # requires cls1, cls2 layers to be defined through functional API\n",
    "    cls1_cls2 = tf.linalg.matmul(cls1, cls2, transpose_b=True)\n",
    "    numerator = tf.norm(cls1_cls2, ord=1)\n",
    "    cls1_norm = tf.norm(cls1, ord=2)\n",
    "    cls2_norm = tf.norm(cls2, ord=2)\n",
    "    denominator = tf.math.multiply(cls1_norm, cls2_norm)\n",
    "    loss_ortho = tf.math.divide_no_nan(numerator, denominator)\n",
    "    \n",
    "    loss_categorical = keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    return loss_categorical + alpha * loss_ortho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "model_path = os.path.join('saved_models/model_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '_.sav')\n",
    "log_dir = os.path.join(\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "monitor_accuracy = 'val_cls2_output_accuracy'\n",
    "monitor_mae = 'val_cls2_output_mean_absolute_error'\n",
    "\n",
    "tensorboard_cbk = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping_cbk = EarlyStopping(monitor=monitor_accuracy, patience=10, verbose=0, mode='min')\n",
    "mcp_save_cbk = ModelCheckpoint(model_path+'.mcp.hdf5', save_best_only=True, monitor=monitor_accuracy, mode='min')\n",
    "reduce_lr_plateau_cbk = ReduceLROnPlateau(monitor=monitor_mae, factor=0.1, patience=7, verbose=1, mode='min')\n",
    "callbacks = [early_stopping_cbk, mcp_save_cbk, reduce_lr_plateau_cbk, tensorboard_cbk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    'cls1_output': 'categorical_crossentropy',\n",
    "    'cls2_output': 'binary_crossentropy'\n",
    "}\n",
    "lossWeights = {\"cls1_output\": 1.0, \"cls2_output\": 5.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1649629256597,
     "user": {
      "displayName": "James Thiering",
      "userId": "02262056658604878482"
     },
     "user_tz": 360
    },
    "id": "iT--vGRHkJA6"
   },
   "outputs": [],
   "source": [
    "xception_tl_DAiSEE.compile(\n",
    "    loss = losses,\n",
    "    loss_weights=lossWeights,\n",
    "    optimizer='adam',\n",
    "    metrics = ['mean_absolute_error', 'accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7507208,
     "status": "ok",
     "timestamp": 1649636763802,
     "user": {
      "displayName": "James Thiering",
      "userId": "02262056658604878482"
     },
     "user_tz": 360
    },
    "id": "E162Dgb5tdCT",
    "outputId": "7da61639-52e9-4015-d25c-0ddc07105797"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1200/1200 [==============================] - 455s 374ms/step - loss: 684.9946 - cls1_output_loss: 403.2958 - cls2_output_loss: 56.3398 - cls1_output_mean_absolute_error: 0.2640 - cls1_output_accuracy: 0.4719 - cls2_output_mean_absolute_error: 0.0917 - cls2_output_accuracy: 0.9083 - val_loss: 687.0070 - val_cls1_output_loss: 79.2861 - val_cls2_output_loss: 121.5442 - val_cls1_output_mean_absolute_error: 0.2704 - val_cls1_output_accuracy: 0.4593 - val_cls2_output_mean_absolute_error: 0.2116 - val_cls2_output_accuracy: 0.7882 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1200/1200 [==============================] - 429s 357ms/step - loss: 93.4226 - cls1_output_loss: 61.7405 - cls2_output_loss: 6.3364 - cls1_output_mean_absolute_error: 0.2660 - cls1_output_accuracy: 0.4678 - cls2_output_mean_absolute_error: 0.0232 - cls2_output_accuracy: 0.9768 - val_loss: 515.7750 - val_cls1_output_loss: 7.9535 - val_cls2_output_loss: 101.5642 - val_cls1_output_mean_absolute_error: 0.2579 - val_cls1_output_accuracy: 0.4959 - val_cls2_output_mean_absolute_error: 0.1937 - val_cls2_output_accuracy: 0.8058 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1200/1200 [==============================] - 434s 362ms/step - loss: 17.8074 - cls1_output_loss: 3.8369 - cls2_output_loss: 2.7941 - cls1_output_mean_absolute_error: 0.2856 - cls1_output_accuracy: 0.4792 - cls2_output_mean_absolute_error: 0.0102 - cls2_output_accuracy: 0.9899 - val_loss: 637.6644 - val_cls1_output_loss: 0.9526 - val_cls2_output_loss: 127.3424 - val_cls1_output_mean_absolute_error: 0.2853 - val_cls1_output_accuracy: 0.4709 - val_cls2_output_mean_absolute_error: 0.2951 - val_cls2_output_accuracy: 0.7048 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1200/1200 [==============================] - 427s 355ms/step - loss: 8.2383 - cls1_output_loss: 1.2319 - cls2_output_loss: 1.4013 - cls1_output_mean_absolute_error: 0.2802 - cls1_output_accuracy: 0.4770 - cls2_output_mean_absolute_error: 0.0069 - cls2_output_accuracy: 0.9930 - val_loss: 522.2483 - val_cls1_output_loss: 0.8821 - val_cls2_output_loss: 104.2732 - val_cls1_output_mean_absolute_error: 0.2772 - val_cls1_output_accuracy: 0.4997 - val_cls2_output_mean_absolute_error: 0.2133 - val_cls2_output_accuracy: 0.7866 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1200/1200 [==============================] - 426s 355ms/step - loss: 6.1177 - cls1_output_loss: 0.9698 - cls2_output_loss: 1.0296 - cls1_output_mean_absolute_error: 0.2750 - cls1_output_accuracy: 0.4819 - cls2_output_mean_absolute_error: 0.0048 - cls2_output_accuracy: 0.9952 - val_loss: 761.3923 - val_cls1_output_loss: 0.8730 - val_cls2_output_loss: 152.1039 - val_cls1_output_mean_absolute_error: 0.2741 - val_cls1_output_accuracy: 0.4964 - val_cls2_output_mean_absolute_error: 0.2941 - val_cls2_output_accuracy: 0.7058 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1200/1200 [==============================] - 434s 361ms/step - loss: 4.3706 - cls1_output_loss: 0.9124 - cls2_output_loss: 0.6916 - cls1_output_mean_absolute_error: 0.2726 - cls1_output_accuracy: 0.4812 - cls2_output_mean_absolute_error: 0.0033 - cls2_output_accuracy: 0.9967 - val_loss: 747.4976 - val_cls1_output_loss: 0.8757 - val_cls2_output_loss: 149.3244 - val_cls1_output_mean_absolute_error: 0.2724 - val_cls1_output_accuracy: 0.4993 - val_cls2_output_mean_absolute_error: 0.3474 - val_cls2_output_accuracy: 0.6528 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1200/1200 [==============================] - 433s 361ms/step - loss: 3.3731 - cls1_output_loss: 0.8969 - cls2_output_loss: 0.4952 - cls1_output_mean_absolute_error: 0.2718 - cls1_output_accuracy: 0.4863 - cls2_output_mean_absolute_error: 0.0028 - cls2_output_accuracy: 0.9972 - val_loss: 488.2013 - val_cls1_output_loss: 0.8730 - val_cls2_output_loss: 97.4657 - val_cls1_output_mean_absolute_error: 0.2724 - val_cls1_output_accuracy: 0.4986 - val_cls2_output_mean_absolute_error: 0.2364 - val_cls2_output_accuracy: 0.7636 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1200/1200 [==============================] - 433s 360ms/step - loss: 2.6017 - cls1_output_loss: 0.8695 - cls2_output_loss: 0.3464 - cls1_output_mean_absolute_error: 0.2715 - cls1_output_accuracy: 0.4854 - cls2_output_mean_absolute_error: 0.0020 - cls2_output_accuracy: 0.9980 - val_loss: 806.1393 - val_cls1_output_loss: 0.8686 - val_cls2_output_loss: 161.0542 - val_cls1_output_mean_absolute_error: 0.2726 - val_cls1_output_accuracy: 0.4984 - val_cls2_output_mean_absolute_error: 0.3747 - val_cls2_output_accuracy: 0.6252 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 2.2169 - cls1_output_loss: 0.8994 - cls2_output_loss: 0.2635 - cls1_output_mean_absolute_error: 0.2715 - cls1_output_accuracy: 0.4843 - cls2_output_mean_absolute_error: 0.0016 - cls2_output_accuracy: 0.9984\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1200/1200 [==============================] - 426s 355ms/step - loss: 2.2169 - cls1_output_loss: 0.8994 - cls2_output_loss: 0.2635 - cls1_output_mean_absolute_error: 0.2715 - cls1_output_accuracy: 0.4843 - cls2_output_mean_absolute_error: 0.0016 - cls2_output_accuracy: 0.9984 - val_loss: 583.2375 - val_cls1_output_loss: 0.8681 - val_cls2_output_loss: 116.4739 - val_cls1_output_mean_absolute_error: 0.2724 - val_cls1_output_accuracy: 0.4510 - val_cls2_output_mean_absolute_error: 0.2721 - val_cls2_output_accuracy: 0.7281 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1200/1200 [==============================] - 426s 355ms/step - loss: 1.5026 - cls1_output_loss: 0.8670 - cls2_output_loss: 0.1271 - cls1_output_mean_absolute_error: 0.2715 - cls1_output_accuracy: 0.4784 - cls2_output_mean_absolute_error: 0.0011 - cls2_output_accuracy: 0.9989 - val_loss: 740.3084 - val_cls1_output_loss: 0.8676 - val_cls2_output_loss: 147.8882 - val_cls1_output_mean_absolute_error: 0.2723 - val_cls1_output_accuracy: 0.4996 - val_cls2_output_mean_absolute_error: 0.3287 - val_cls2_output_accuracy: 0.6713 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "1200/1200 [==============================] - 426s 355ms/step - loss: 1.4701 - cls1_output_loss: 0.8672 - cls2_output_loss: 0.1206 - cls1_output_mean_absolute_error: 0.2714 - cls1_output_accuracy: 0.4850 - cls2_output_mean_absolute_error: 8.3015e-04 - cls2_output_accuracy: 0.9992 - val_loss: 654.3804 - val_cls1_output_loss: 0.8673 - val_cls2_output_loss: 130.7026 - val_cls1_output_mean_absolute_error: 0.2723 - val_cls1_output_accuracy: 0.4997 - val_cls2_output_mean_absolute_error: 0.3005 - val_cls2_output_accuracy: 0.6994 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "1200/1200 [==============================] - 426s 355ms/step - loss: 1.3728 - cls1_output_loss: 0.8674 - cls2_output_loss: 0.1011 - cls1_output_mean_absolute_error: 0.2715 - cls1_output_accuracy: 0.4838 - cls2_output_mean_absolute_error: 9.2092e-04 - cls2_output_accuracy: 0.9991 - val_loss: 714.8120 - val_cls1_output_loss: 0.8672 - val_cls2_output_loss: 142.7890 - val_cls1_output_mean_absolute_error: 0.2722 - val_cls1_output_accuracy: 0.4997 - val_cls2_output_mean_absolute_error: 0.3294 - val_cls2_output_accuracy: 0.6708 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "1200/1200 [==============================] - 426s 355ms/step - loss: 1.5707 - cls1_output_loss: 0.8676 - cls2_output_loss: 0.1406 - cls1_output_mean_absolute_error: 0.2714 - cls1_output_accuracy: 0.4848 - cls2_output_mean_absolute_error: 0.0012 - cls2_output_accuracy: 0.9988 - val_loss: 642.6037 - val_cls1_output_loss: 0.8671 - val_cls2_output_loss: 128.3473 - val_cls1_output_mean_absolute_error: 0.2722 - val_cls1_output_accuracy: 0.4997 - val_cls2_output_mean_absolute_error: 0.3074 - val_cls2_output_accuracy: 0.6927 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "1200/1200 [==============================] - 426s 355ms/step - loss: 1.3151 - cls1_output_loss: 0.8674 - cls2_output_loss: 0.0895 - cls1_output_mean_absolute_error: 0.2714 - cls1_output_accuracy: 0.4846 - cls2_output_mean_absolute_error: 7.5545e-04 - cls2_output_accuracy: 0.9992 - val_loss: 637.3792 - val_cls1_output_loss: 0.8671 - val_cls2_output_loss: 127.3025 - val_cls1_output_mean_absolute_error: 0.2722 - val_cls1_output_accuracy: 0.4996 - val_cls2_output_mean_absolute_error: 0.3015 - val_cls2_output_accuracy: 0.6985 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "1200/1200 [==============================] - 426s 355ms/step - loss: 1.4282 - cls1_output_loss: 0.8677 - cls2_output_loss: 0.1121 - cls1_output_mean_absolute_error: 0.2714 - cls1_output_accuracy: 0.4830 - cls2_output_mean_absolute_error: 8.0555e-04 - cls2_output_accuracy: 0.9992 - val_loss: 689.2383 - val_cls1_output_loss: 0.8670 - val_cls2_output_loss: 137.6742 - val_cls1_output_mean_absolute_error: 0.2722 - val_cls1_output_accuracy: 0.4996 - val_cls2_output_mean_absolute_error: 0.3267 - val_cls2_output_accuracy: 0.6734 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 1.1944 - cls1_output_loss: 0.8641 - cls2_output_loss: 0.0661 - cls1_output_mean_absolute_error: 0.2713 - cls1_output_accuracy: 0.4851 - cls2_output_mean_absolute_error: 5.1445e-04 - cls2_output_accuracy: 0.9995\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1200/1200 [==============================] - 426s 355ms/step - loss: 1.1944 - cls1_output_loss: 0.8641 - cls2_output_loss: 0.0661 - cls1_output_mean_absolute_error: 0.2713 - cls1_output_accuracy: 0.4851 - cls2_output_mean_absolute_error: 5.1445e-04 - cls2_output_accuracy: 0.9995 - val_loss: 646.2129 - val_cls1_output_loss: 0.8670 - val_cls2_output_loss: 129.0692 - val_cls1_output_mean_absolute_error: 0.2722 - val_cls1_output_accuracy: 0.4996 - val_cls2_output_mean_absolute_error: 0.3213 - val_cls2_output_accuracy: 0.6788 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1200/1200 [==============================] - 426s 355ms/step - loss: 1.4099 - cls1_output_loss: 0.8648 - cls2_output_loss: 0.1090 - cls1_output_mean_absolute_error: 0.2713 - cls1_output_accuracy: 0.4863 - cls2_output_mean_absolute_error: 8.5802e-04 - cls2_output_accuracy: 0.9992 - val_loss: 636.6428 - val_cls1_output_loss: 0.8670 - val_cls2_output_loss: 127.1551 - val_cls1_output_mean_absolute_error: 0.2722 - val_cls1_output_accuracy: 0.4996 - val_cls2_output_mean_absolute_error: 0.3175 - val_cls2_output_accuracy: 0.6824 - lr: 1.0000e-05\n",
      "Epoch 18/50\n",
      "1200/1200 [==============================] - 426s 355ms/step - loss: 1.5114 - cls1_output_loss: 0.8645 - cls2_output_loss: 0.1294 - cls1_output_mean_absolute_error: 0.2713 - cls1_output_accuracy: 0.4859 - cls2_output_mean_absolute_error: 9.1490e-04 - cls2_output_accuracy: 0.9991 - val_loss: 628.5490 - val_cls1_output_loss: 0.8670 - val_cls2_output_loss: 125.5364 - val_cls1_output_mean_absolute_error: 0.2722 - val_cls1_output_accuracy: 0.4996 - val_cls2_output_mean_absolute_error: 0.3138 - val_cls2_output_accuracy: 0.6862 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history = xception_tl_DAiSEE.fit(\n",
    "    training_generator,\n",
    "    validation_data=validation_generator,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    #steps_per_epoch=100, # Set temporarily for frequent validation\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUL2wYS9uzQT"
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOXufI0XoTCHj+Nsq6ExRpc",
   "collapsed_sections": [],
   "name": "DAiSEE_train_engagement_only.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
