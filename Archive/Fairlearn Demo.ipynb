{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e280ef6",
   "metadata": {},
   "source": [
    "[section 1](#section1)<br />\n",
    "[section 2](#section2)<br />\n",
    "[section 3](#section3)<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5fa9df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from -r requirements.txt (line 1)) (2.10.0)\n",
      "Requirement already satisfied: keras in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from -r requirements.txt (line 2)) (2.10.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from -r requirements.txt (line 3)) (3.7.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from -r requirements.txt (line 4)) (4.6.0.66)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from -r requirements.txt (line 5)) (1.1.2)\n",
      "Requirement already satisfied: fairlearn in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from -r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from -r requirements.txt (line 7)) (0.10.0)\n",
      "Requirement already satisfied: Keras-Preprocessing in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from -r requirements.txt (line 8)) (1.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from -r requirements.txt (line 9)) (1.23.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from -r requirements.txt (line 10)) (1.5.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from -r requirements.txt (line 11)) (9.2.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from -r requirements.txt (line 12)) (0.12.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from -r requirements.txt (line 13)) (4.64.1)\n",
      "Requirement already satisfied: xlrd in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from -r requirements.txt (line 14)) (2.0.1)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from -r requirements.txt (line 15)) (3.3.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (1.14.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (63.4.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (1.49.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (4.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (22.9.24)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (3.19.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (21.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (0.27.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (14.0.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (2.10.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.9.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from huggingface-hub->-r requirements.txt (line 7)) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from huggingface-hub->-r requirements.txt (line 7)) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from huggingface-hub->-r requirements.txt (line 7)) (2.28.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from pandas->-r requirements.txt (line 10)) (2022.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from pandas->-r requirements.txt (line 10)) (2.8.2)\n",
      "Requirement already satisfied: matplotlib>=3.1 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from seaborn->-r requirements.txt (line 12)) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tqdm->-r requirements.txt (line 13)) (0.4.5)\n",
      "Requirement already satisfied: wheel in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from lightgbm->-r requirements.txt (line 15)) (0.37.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from matplotlib>=3.1->seaborn->-r requirements.txt (line 12)) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from matplotlib>=3.1->seaborn->-r requirements.txt (line 12)) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from matplotlib>=3.1->seaborn->-r requirements.txt (line 12)) (4.37.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from matplotlib>=3.1->seaborn->-r requirements.txt (line 12)) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from matplotlib>=3.1->seaborn->-r requirements.txt (line 12)) (0.11.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow->-r requirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow->-r requirements.txt (line 1)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow->-r requirements.txt (line 1)) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow->-r requirements.txt (line 1)) (2.12.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow->-r requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from requests->huggingface-hub->-r requirements.txt (line 7)) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from requests->huggingface-hub->-r requirements.txt (line 7)) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from requests->huggingface-hub->-r requirements.txt (line 7)) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from requests->huggingface-hub->-r requirements.txt (line 7)) (2022.9.14)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->-r requirements.txt (line 1)) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->-r requirements.txt (line 1)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->-r requirements.txt (line 1)) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow->-r requirements.txt (line 1)) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow->-r requirements.txt (line 1)) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->-r requirements.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\netwo\\anaconda3\\envs\\thesis-minimum\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow->-r requirements.txt (line 1)) (3.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a12c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Disable eager execution\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61f90084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Models\n",
    "import lightgbm as lgb\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Fairlearn algorithms and utils\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from fairlearn.reductions import GridSearch, EqualizedOdds\n",
    "\n",
    "# Metrics\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    selection_rate, demographic_parity_difference, demographic_parity_ratio,\n",
    "    false_positive_rate, false_negative_rate,\n",
    "    false_positive_rate_difference, false_negative_rate_difference,\n",
    "    equalized_odds_difference)\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3cccd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D #types of layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74b9e75",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"section1\"></a>\n",
    "# Section 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f128a214",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "0      20000    2          2         1   24      2      2     -1     -1   \n",
       "1     120000    2          2         2   26     -1      2      0      0   \n",
       "2      90000    2          2         2   34      0      0      0      0   \n",
       "3      50000    2          2         1   37      0      0      0      0   \n",
       "4      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0     -2  ...          0          0          0         0       689         0   \n",
       "1      0  ...       3272       3455       3261         0      1000      1000   \n",
       "2      0  ...      14331      14948      15549      1518      1500      1000   \n",
       "3      0  ...      28314      28959      29547      2000      2019      1200   \n",
       "4      0  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0         0         0         0                           1  \n",
       "1      1000         0      2000                           1  \n",
       "2      1000      1000      5000                           0  \n",
       "3      1100      1069      1000                           0  \n",
       "4      9000       689       679                           0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
    "dataset = pd.read_excel(io=data_url, header=1).drop(columns=['ID']).rename(columns={'PAY_0':'PAY_1'})\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee4a63d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the sensitive feature\n",
    "A = dataset[\"SEX\"]\n",
    "A_str = A.map({ 2:\"female\", 1:\"male\"})\n",
    "# Extract the target\n",
    "Y = dataset[\"default payment next month\"]\n",
    "categorical_features = ['EDUCATION', 'MARRIAGE','PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "for col in categorical_features:\n",
    "    dataset[col] = dataset[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994f4757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    30000.000000\n",
       "mean         1.603733\n",
       "std          0.489129\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          2.000000\n",
       "max          2.000000\n",
       "Name: SEX, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "349114b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    1\n",
       "Name: SEX, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e3c190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_feature = (A - 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ae4204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3df747f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "29995    0\n",
       "29996    0\n",
       "29997    1\n",
       "29998    1\n",
       "29999    1\n",
       "Name: default payment next month, Length: 30000, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e3714ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>220000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88004</td>\n",
       "      <td>31237</td>\n",
       "      <td>15980</td>\n",
       "      <td>8500</td>\n",
       "      <td>20000</td>\n",
       "      <td>5003</td>\n",
       "      <td>3047</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8979</td>\n",
       "      <td>5190</td>\n",
       "      <td>0</td>\n",
       "      <td>1837</td>\n",
       "      <td>3526</td>\n",
       "      <td>8998</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20878</td>\n",
       "      <td>20582</td>\n",
       "      <td>19357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22000</td>\n",
       "      <td>4200</td>\n",
       "      <td>2000</td>\n",
       "      <td>3100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52774</td>\n",
       "      <td>11855</td>\n",
       "      <td>48944</td>\n",
       "      <td>85900</td>\n",
       "      <td>3409</td>\n",
       "      <td>1178</td>\n",
       "      <td>1926</td>\n",
       "      <td>52964</td>\n",
       "      <td>1804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36535</td>\n",
       "      <td>32428</td>\n",
       "      <td>15313</td>\n",
       "      <td>2078</td>\n",
       "      <td>1800</td>\n",
       "      <td>1430</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX EDUCATION MARRIAGE  AGE PAY_1 PAY_2 PAY_3 PAY_4 PAY_5  \\\n",
       "0          20000    2         2        1   24     2     2    -1    -1    -2   \n",
       "1         120000    2         2        2   26    -1     2     0     0     0   \n",
       "2          90000    2         2        2   34     0     0     0     0     0   \n",
       "3          50000    2         2        1   37     0     0     0     0     0   \n",
       "4          50000    1         2        1   57    -1     0    -1     0     0   \n",
       "...          ...  ...       ...      ...  ...   ...   ...   ...   ...   ...   \n",
       "29995     220000    1         3        1   39     0     0     0     0     0   \n",
       "29996     150000    1         3        2   43    -1    -1    -1    -1     0   \n",
       "29997      30000    1         2        2   37     4     3     2    -1     0   \n",
       "29998      80000    1         3        1   41     1    -1     0     0     0   \n",
       "29999      50000    1         2        1   46     0     0     0     0     0   \n",
       "\n",
       "       ... BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0      ...         0          0          0         0       689         0   \n",
       "1      ...      3272       3455       3261         0      1000      1000   \n",
       "2      ...     14331      14948      15549      1518      1500      1000   \n",
       "3      ...     28314      28959      29547      2000      2019      1200   \n",
       "4      ...     20940      19146      19131      2000     36681     10000   \n",
       "...    ...       ...        ...        ...       ...       ...       ...   \n",
       "29995  ...     88004      31237      15980      8500     20000      5003   \n",
       "29996  ...      8979       5190          0      1837      3526      8998   \n",
       "29997  ...     20878      20582      19357         0         0     22000   \n",
       "29998  ...     52774      11855      48944     85900      3409      1178   \n",
       "29999  ...     36535      32428      15313      2078      1800      1430   \n",
       "\n",
       "       PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0             0         0         0                           1  \n",
       "1          1000         0      2000                           1  \n",
       "2          1000      1000      5000                           0  \n",
       "3          1100      1069      1000                           0  \n",
       "4          9000       689       679                           0  \n",
       "...         ...       ...       ...                         ...  \n",
       "29995      3047      5000      1000                           0  \n",
       "29996       129         0         0                           0  \n",
       "29997      4200      2000      3100                           1  \n",
       "29998      1926     52964      1804                           1  \n",
       "29999      1000      1000      1000                           1  \n",
       "\n",
       "[30000 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbfb97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataset.drop(columns=['SEX', 'default payment next month']).copy()\n",
    "\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f63a7c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "x_train, x_test, Y_train, Y_test, A_train, A_test, A_str_train, A_str_test, sex_train, sex_split = train_test_split(\n",
    "    features, \n",
    "    Y, \n",
    "    A, \n",
    "    A_str,\n",
    "    sex_feature,\n",
    "    test_size = 0.3, \n",
    "    random_state=12345,\n",
    "    stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99e44b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.75135032,  1.45111372, -1.05729503, -0.16115646,  0.90471219,\n",
       "        1.78234817,  0.1388648 ,  0.18874609,  0.23491652,  0.25313738,\n",
       "        0.33679354,  0.33768516,  0.30312013,  0.39388075, -0.16546117,\n",
       "        0.14258263, -0.34194162, -0.12678393, -0.12641128, -0.21180252,\n",
       "        0.99493138, -0.15275225])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caa31997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000, 22)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d6d97f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"section2\"></a>\n",
    "# Section 2\n",
    "\n",
    "### Build a simple NN model and view sex bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ac5b14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simple_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 22)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1472      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,097\n",
      "Trainable params: 4,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(22,))\n",
    "cls1a = Dense(64, kernel_regularizer=regularizers.L1(1e-5), activation='relu')(inputs)\n",
    "dropout1 = Dropout(0.1)(cls1a)\n",
    "cls1b = Dense(32, kernel_regularizer=regularizers.L1(1e-5), activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.1)(cls1b)\n",
    "cls1c = Dense(16, kernel_regularizer=regularizers.L1(1e-5), activation='relu')(dropout2)\n",
    "output = Dense(1, activation='sigmoid')(cls1c)\n",
    "model = keras.Model(inputs=inputs, outputs=output, name=\"simple_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66d40ae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16800 samples, validate on 4200 samples\n",
      "Epoch 1/250\n",
      "16800/16800 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.7908 - mean_absolute_error: 0.3287"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netwo\\anaconda3\\envs\\Thesis-minimum\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16800/16800 [==============================] - 3s 197us/sample - loss: 0.5080 - accuracy: 0.7908 - mean_absolute_error: 0.3287 - val_loss: 0.4637 - val_accuracy: 0.8100 - val_mean_absolute_error: 0.2899\n",
      "Epoch 2/250\n",
      "16800/16800 [==============================] - 2s 129us/sample - loss: 0.4627 - accuracy: 0.8132 - mean_absolute_error: 0.2897 - val_loss: 0.4537 - val_accuracy: 0.8126 - val_mean_absolute_error: 0.2804\n",
      "Epoch 3/250\n",
      "16800/16800 [==============================] - 2s 137us/sample - loss: 0.4526 - accuracy: 0.8146 - mean_absolute_error: 0.2830 - val_loss: 0.4460 - val_accuracy: 0.8183 - val_mean_absolute_error: 0.2715\n",
      "Epoch 4/250\n",
      "16800/16800 [==============================] - 2s 118us/sample - loss: 0.4469 - accuracy: 0.8153 - mean_absolute_error: 0.2781 - val_loss: 0.4436 - val_accuracy: 0.8169 - val_mean_absolute_error: 0.2767\n",
      "Epoch 5/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.4435 - accuracy: 0.8178 - mean_absolute_error: 0.2765 - val_loss: 0.4447 - val_accuracy: 0.8162 - val_mean_absolute_error: 0.2841\n",
      "Epoch 6/250\n",
      "16800/16800 [==============================] - 2s 125us/sample - loss: 0.4419 - accuracy: 0.8188 - mean_absolute_error: 0.2757 - val_loss: 0.4424 - val_accuracy: 0.8179 - val_mean_absolute_error: 0.2695\n",
      "Epoch 7/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.4389 - accuracy: 0.8180 - mean_absolute_error: 0.2728 - val_loss: 0.4453 - val_accuracy: 0.8157 - val_mean_absolute_error: 0.2834\n",
      "Epoch 8/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.4375 - accuracy: 0.8192 - mean_absolute_error: 0.2733 - val_loss: 0.4411 - val_accuracy: 0.8167 - val_mean_absolute_error: 0.2746\n",
      "Epoch 9/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.4362 - accuracy: 0.8195 - mean_absolute_error: 0.2708 - val_loss: 0.4419 - val_accuracy: 0.8193 - val_mean_absolute_error: 0.2844\n",
      "Epoch 10/250\n",
      "16800/16800 [==============================] - 2s 134us/sample - loss: 0.4371 - accuracy: 0.8207 - mean_absolute_error: 0.2725 - val_loss: 0.4402 - val_accuracy: 0.8183 - val_mean_absolute_error: 0.2729\n",
      "Epoch 11/250\n",
      "16800/16800 [==============================] - 2s 130us/sample - loss: 0.4335 - accuracy: 0.8214 - mean_absolute_error: 0.2696 - val_loss: 0.4403 - val_accuracy: 0.8157 - val_mean_absolute_error: 0.2726\n",
      "Epoch 12/250\n",
      "16800/16800 [==============================] - 2s 137us/sample - loss: 0.4330 - accuracy: 0.8196 - mean_absolute_error: 0.2697 - val_loss: 0.4412 - val_accuracy: 0.8181 - val_mean_absolute_error: 0.2700\n",
      "Epoch 13/250\n",
      "16800/16800 [==============================] - 2s 128us/sample - loss: 0.4332 - accuracy: 0.8209 - mean_absolute_error: 0.2693 - val_loss: 0.4424 - val_accuracy: 0.8174 - val_mean_absolute_error: 0.2747\n",
      "Epoch 14/250\n",
      "16800/16800 [==============================] - 2s 125us/sample - loss: 0.4320 - accuracy: 0.8195 - mean_absolute_error: 0.2690 - val_loss: 0.4413 - val_accuracy: 0.8183 - val_mean_absolute_error: 0.2641\n",
      "Epoch 15/250\n",
      "16800/16800 [==============================] - 2s 125us/sample - loss: 0.4316 - accuracy: 0.8200 - mean_absolute_error: 0.2691 - val_loss: 0.4423 - val_accuracy: 0.8160 - val_mean_absolute_error: 0.2683\n",
      "Epoch 16/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.4318 - accuracy: 0.8211 - mean_absolute_error: 0.2676 - val_loss: 0.4417 - val_accuracy: 0.8150 - val_mean_absolute_error: 0.2690\n",
      "Epoch 17/250\n",
      "16800/16800 [==============================] - 2s 130us/sample - loss: 0.4280 - accuracy: 0.8207 - mean_absolute_error: 0.2663 - val_loss: 0.4429 - val_accuracy: 0.8174 - val_mean_absolute_error: 0.2680\n",
      "Epoch 18/250\n",
      "16800/16800 [==============================] - 2s 130us/sample - loss: 0.4290 - accuracy: 0.8227 - mean_absolute_error: 0.2667 - val_loss: 0.4419 - val_accuracy: 0.8171 - val_mean_absolute_error: 0.2732\n",
      "Epoch 19/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.4283 - accuracy: 0.8212 - mean_absolute_error: 0.2670 - val_loss: 0.4432 - val_accuracy: 0.8188 - val_mean_absolute_error: 0.2655\n",
      "Epoch 20/250\n",
      "16800/16800 [==============================] - 2s 129us/sample - loss: 0.4281 - accuracy: 0.8226 - mean_absolute_error: 0.2651 - val_loss: 0.4424 - val_accuracy: 0.8190 - val_mean_absolute_error: 0.2708\n",
      "Epoch 21/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.4273 - accuracy: 0.8215 - mean_absolute_error: 0.2667 - val_loss: 0.4431 - val_accuracy: 0.8174 - val_mean_absolute_error: 0.2653\n",
      "Epoch 22/250\n",
      "16800/16800 [==============================] - 2s 125us/sample - loss: 0.4274 - accuracy: 0.8229 - mean_absolute_error: 0.2658 - val_loss: 0.4422 - val_accuracy: 0.8198 - val_mean_absolute_error: 0.2657\n",
      "Epoch 23/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.4258 - accuracy: 0.8203 - mean_absolute_error: 0.2651 - val_loss: 0.4456 - val_accuracy: 0.8140 - val_mean_absolute_error: 0.2678\n",
      "Epoch 24/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.4271 - accuracy: 0.8208 - mean_absolute_error: 0.2662 - val_loss: 0.4423 - val_accuracy: 0.8171 - val_mean_absolute_error: 0.2714\n",
      "Epoch 25/250\n",
      "16800/16800 [==============================] - 2s 135us/sample - loss: 0.4259 - accuracy: 0.8224 - mean_absolute_error: 0.2646 - val_loss: 0.4445 - val_accuracy: 0.8160 - val_mean_absolute_error: 0.2773\n",
      "Epoch 26/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.4246 - accuracy: 0.8239 - mean_absolute_error: 0.2637 - val_loss: 0.4428 - val_accuracy: 0.8188 - val_mean_absolute_error: 0.2766\n",
      "Epoch 27/250\n",
      "16800/16800 [==============================] - 2s 127us/sample - loss: 0.4243 - accuracy: 0.8229 - mean_absolute_error: 0.2634 - val_loss: 0.4424 - val_accuracy: 0.8179 - val_mean_absolute_error: 0.2802\n",
      "Epoch 28/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.4212 - accuracy: 0.8246 - mean_absolute_error: 0.2627 - val_loss: 0.4425 - val_accuracy: 0.8183 - val_mean_absolute_error: 0.2809\n",
      "Epoch 29/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.4223 - accuracy: 0.8228 - mean_absolute_error: 0.2621 - val_loss: 0.4434 - val_accuracy: 0.8157 - val_mean_absolute_error: 0.2761\n",
      "Epoch 30/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.4231 - accuracy: 0.8224 - mean_absolute_error: 0.2632 - val_loss: 0.4434 - val_accuracy: 0.8162 - val_mean_absolute_error: 0.2749\n",
      "Epoch 31/250\n",
      "16800/16800 [==============================] - 2s 125us/sample - loss: 0.4209 - accuracy: 0.8248 - mean_absolute_error: 0.2618 - val_loss: 0.4460 - val_accuracy: 0.8183 - val_mean_absolute_error: 0.2633\n",
      "Epoch 32/250\n",
      "16800/16800 [==============================] - 2s 130us/sample - loss: 0.4196 - accuracy: 0.8244 - mean_absolute_error: 0.2605 - val_loss: 0.4441 - val_accuracy: 0.8169 - val_mean_absolute_error: 0.2686\n",
      "Epoch 33/250\n",
      "16800/16800 [==============================] - 2s 128us/sample - loss: 0.4201 - accuracy: 0.8249 - mean_absolute_error: 0.2615 - val_loss: 0.4447 - val_accuracy: 0.8190 - val_mean_absolute_error: 0.2662\n",
      "Epoch 34/250\n",
      "16800/16800 [==============================] - 2s 127us/sample - loss: 0.4210 - accuracy: 0.8246 - mean_absolute_error: 0.2613 - val_loss: 0.4453 - val_accuracy: 0.8176 - val_mean_absolute_error: 0.2701\n",
      "Epoch 35/250\n",
      "16800/16800 [==============================] - 2s 127us/sample - loss: 0.4203 - accuracy: 0.8245 - mean_absolute_error: 0.2618 - val_loss: 0.4452 - val_accuracy: 0.8171 - val_mean_absolute_error: 0.2644\n",
      "Epoch 36/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.4195 - accuracy: 0.8251 - mean_absolute_error: 0.2601 - val_loss: 0.4476 - val_accuracy: 0.8169 - val_mean_absolute_error: 0.2595\n",
      "Epoch 37/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.4179 - accuracy: 0.8223 - mean_absolute_error: 0.2590 - val_loss: 0.4452 - val_accuracy: 0.8131 - val_mean_absolute_error: 0.2791\n",
      "Epoch 38/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.4176 - accuracy: 0.8252 - mean_absolute_error: 0.2601 - val_loss: 0.4464 - val_accuracy: 0.8143 - val_mean_absolute_error: 0.2689\n",
      "Epoch 39/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16800/16800 [==============================] - 2s 130us/sample - loss: 0.4167 - accuracy: 0.8251 - mean_absolute_error: 0.2582 - val_loss: 0.4472 - val_accuracy: 0.8152 - val_mean_absolute_error: 0.2779\n",
      "Epoch 40/250\n",
      "16800/16800 [==============================] - 2s 137us/sample - loss: 0.4189 - accuracy: 0.8251 - mean_absolute_error: 0.2608 - val_loss: 0.4462 - val_accuracy: 0.8124 - val_mean_absolute_error: 0.2748\n",
      "Epoch 41/250\n",
      "16800/16800 [==============================] - 2s 133us/sample - loss: 0.4182 - accuracy: 0.8264 - mean_absolute_error: 0.2591 - val_loss: 0.4480 - val_accuracy: 0.8126 - val_mean_absolute_error: 0.2770\n",
      "Epoch 42/250\n",
      "16800/16800 [==============================] - 2s 128us/sample - loss: 0.4163 - accuracy: 0.8270 - mean_absolute_error: 0.2581 - val_loss: 0.4480 - val_accuracy: 0.8107 - val_mean_absolute_error: 0.2761\n",
      "Epoch 43/250\n",
      "16800/16800 [==============================] - 2s 132us/sample - loss: 0.4158 - accuracy: 0.8258 - mean_absolute_error: 0.2583 - val_loss: 0.4481 - val_accuracy: 0.8131 - val_mean_absolute_error: 0.2728\n",
      "Epoch 44/250\n",
      "16800/16800 [==============================] - 2s 128us/sample - loss: 0.4153 - accuracy: 0.8271 - mean_absolute_error: 0.2578 - val_loss: 0.4479 - val_accuracy: 0.8152 - val_mean_absolute_error: 0.2726\n",
      "Epoch 45/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.4139 - accuracy: 0.8265 - mean_absolute_error: 0.2561 - val_loss: 0.4473 - val_accuracy: 0.8186 - val_mean_absolute_error: 0.2689\n",
      "Epoch 46/250\n",
      "16800/16800 [==============================] - 2s 127us/sample - loss: 0.4131 - accuracy: 0.8271 - mean_absolute_error: 0.2570 - val_loss: 0.4508 - val_accuracy: 0.8157 - val_mean_absolute_error: 0.2704\n",
      "Epoch 47/250\n",
      "16800/16800 [==============================] - 2s 135us/sample - loss: 0.4136 - accuracy: 0.8252 - mean_absolute_error: 0.2575 - val_loss: 0.4519 - val_accuracy: 0.8164 - val_mean_absolute_error: 0.2696\n",
      "Epoch 48/250\n",
      "16800/16800 [==============================] - 2s 132us/sample - loss: 0.4146 - accuracy: 0.8259 - mean_absolute_error: 0.2574 - val_loss: 0.4475 - val_accuracy: 0.8152 - val_mean_absolute_error: 0.2739\n",
      "Epoch 49/250\n",
      "16800/16800 [==============================] - 2s 129us/sample - loss: 0.4117 - accuracy: 0.8266 - mean_absolute_error: 0.2545 - val_loss: 0.4490 - val_accuracy: 0.8157 - val_mean_absolute_error: 0.2786\n",
      "Epoch 50/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.4120 - accuracy: 0.8261 - mean_absolute_error: 0.2562 - val_loss: 0.4507 - val_accuracy: 0.8140 - val_mean_absolute_error: 0.2699\n",
      "Epoch 51/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.4129 - accuracy: 0.8248 - mean_absolute_error: 0.2571 - val_loss: 0.4476 - val_accuracy: 0.8133 - val_mean_absolute_error: 0.2671\n",
      "Epoch 52/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.4121 - accuracy: 0.8260 - mean_absolute_error: 0.2563 - val_loss: 0.4497 - val_accuracy: 0.8148 - val_mean_absolute_error: 0.2633\n",
      "Epoch 53/250\n",
      "16800/16800 [==============================] - 2s 125us/sample - loss: 0.4112 - accuracy: 0.8277 - mean_absolute_error: 0.2559 - val_loss: 0.4508 - val_accuracy: 0.8145 - val_mean_absolute_error: 0.2600\n",
      "Epoch 54/250\n",
      "16800/16800 [==============================] - 2s 125us/sample - loss: 0.4136 - accuracy: 0.8250 - mean_absolute_error: 0.2560 - val_loss: 0.4489 - val_accuracy: 0.8133 - val_mean_absolute_error: 0.2741\n",
      "Epoch 55/250\n",
      "16800/16800 [==============================] - 2s 134us/sample - loss: 0.4106 - accuracy: 0.8295 - mean_absolute_error: 0.2537 - val_loss: 0.4511 - val_accuracy: 0.8143 - val_mean_absolute_error: 0.2707\n",
      "Epoch 56/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.4118 - accuracy: 0.8282 - mean_absolute_error: 0.2560 - val_loss: 0.4482 - val_accuracy: 0.8124 - val_mean_absolute_error: 0.2724\n",
      "Epoch 57/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.4093 - accuracy: 0.8290 - mean_absolute_error: 0.2543 - val_loss: 0.4517 - val_accuracy: 0.8174 - val_mean_absolute_error: 0.2638\n",
      "Epoch 58/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.4103 - accuracy: 0.8300 - mean_absolute_error: 0.2541 - val_loss: 0.4477 - val_accuracy: 0.8150 - val_mean_absolute_error: 0.2680\n",
      "Epoch 59/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.4095 - accuracy: 0.8286 - mean_absolute_error: 0.2544 - val_loss: 0.4515 - val_accuracy: 0.8117 - val_mean_absolute_error: 0.2678\n",
      "Epoch 60/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.4111 - accuracy: 0.8277 - mean_absolute_error: 0.2551 - val_loss: 0.4516 - val_accuracy: 0.8140 - val_mean_absolute_error: 0.2634\n",
      "Epoch 61/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.4088 - accuracy: 0.8267 - mean_absolute_error: 0.2530 - val_loss: 0.4564 - val_accuracy: 0.8124 - val_mean_absolute_error: 0.2621\n",
      "Epoch 62/250\n",
      "16800/16800 [==============================] - 2s 130us/sample - loss: 0.4105 - accuracy: 0.8263 - mean_absolute_error: 0.2550 - val_loss: 0.4533 - val_accuracy: 0.8164 - val_mean_absolute_error: 0.2600\n",
      "Epoch 63/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.4061 - accuracy: 0.8298 - mean_absolute_error: 0.2518 - val_loss: 0.4527 - val_accuracy: 0.8121 - val_mean_absolute_error: 0.2717\n",
      "Epoch 64/250\n",
      "16800/16800 [==============================] - 2s 125us/sample - loss: 0.4094 - accuracy: 0.8273 - mean_absolute_error: 0.2544 - val_loss: 0.4525 - val_accuracy: 0.8143 - val_mean_absolute_error: 0.2592\n",
      "Epoch 65/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.4088 - accuracy: 0.8291 - mean_absolute_error: 0.2528 - val_loss: 0.4534 - val_accuracy: 0.8140 - val_mean_absolute_error: 0.2625\n",
      "Epoch 66/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.4078 - accuracy: 0.8289 - mean_absolute_error: 0.2531 - val_loss: 0.4530 - val_accuracy: 0.8090 - val_mean_absolute_error: 0.2729\n",
      "Epoch 67/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.4087 - accuracy: 0.8276 - mean_absolute_error: 0.2533 - val_loss: 0.4518 - val_accuracy: 0.8119 - val_mean_absolute_error: 0.2673\n",
      "Epoch 68/250\n",
      "16800/16800 [==============================] - 2s 121us/sample - loss: 0.4077 - accuracy: 0.8292 - mean_absolute_error: 0.2524 - val_loss: 0.4539 - val_accuracy: 0.8083 - val_mean_absolute_error: 0.2774\n",
      "Epoch 69/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.4047 - accuracy: 0.8298 - mean_absolute_error: 0.2508 - val_loss: 0.4564 - val_accuracy: 0.8110 - val_mean_absolute_error: 0.2718\n",
      "Epoch 70/250\n",
      "16800/16800 [==============================] - 2s 130us/sample - loss: 0.4065 - accuracy: 0.8311 - mean_absolute_error: 0.2519 - val_loss: 0.4565 - val_accuracy: 0.8083 - val_mean_absolute_error: 0.2736\n",
      "Epoch 71/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.4063 - accuracy: 0.8293 - mean_absolute_error: 0.2525 - val_loss: 0.4562 - val_accuracy: 0.8140 - val_mean_absolute_error: 0.2653\n",
      "Epoch 72/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.4067 - accuracy: 0.8290 - mean_absolute_error: 0.2516 - val_loss: 0.4525 - val_accuracy: 0.8110 - val_mean_absolute_error: 0.2721\n",
      "Epoch 73/250\n",
      "16800/16800 [==============================] - 2s 121us/sample - loss: 0.4044 - accuracy: 0.8285 - mean_absolute_error: 0.2511 - val_loss: 0.4564 - val_accuracy: 0.8102 - val_mean_absolute_error: 0.2672\n",
      "Epoch 74/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.4057 - accuracy: 0.8292 - mean_absolute_error: 0.2502 - val_loss: 0.4538 - val_accuracy: 0.8114 - val_mean_absolute_error: 0.2644\n",
      "Epoch 75/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.4046 - accuracy: 0.8282 - mean_absolute_error: 0.2513 - val_loss: 0.4567 - val_accuracy: 0.8121 - val_mean_absolute_error: 0.2722\n",
      "Epoch 76/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.4031 - accuracy: 0.8299 - mean_absolute_error: 0.2493 - val_loss: 0.4560 - val_accuracy: 0.8105 - val_mean_absolute_error: 0.2732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/250\n",
      "16800/16800 [==============================] - 2s 128us/sample - loss: 0.4057 - accuracy: 0.8302 - mean_absolute_error: 0.2522 - val_loss: 0.4570 - val_accuracy: 0.8126 - val_mean_absolute_error: 0.2602\n",
      "Epoch 78/250\n",
      "16800/16800 [==============================] - 2s 129us/sample - loss: 0.4049 - accuracy: 0.8307 - mean_absolute_error: 0.2499 - val_loss: 0.4543 - val_accuracy: 0.8124 - val_mean_absolute_error: 0.2653\n",
      "Epoch 79/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.4062 - accuracy: 0.8286 - mean_absolute_error: 0.2516 - val_loss: 0.4576 - val_accuracy: 0.8129 - val_mean_absolute_error: 0.2664\n",
      "Epoch 80/250\n",
      "16800/16800 [==============================] - 2s 121us/sample - loss: 0.4073 - accuracy: 0.8290 - mean_absolute_error: 0.2526 - val_loss: 0.4568 - val_accuracy: 0.8145 - val_mean_absolute_error: 0.2662\n",
      "Epoch 81/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.4031 - accuracy: 0.8316 - mean_absolute_error: 0.2494 - val_loss: 0.4540 - val_accuracy: 0.8102 - val_mean_absolute_error: 0.2654\n",
      "Epoch 82/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.4015 - accuracy: 0.8311 - mean_absolute_error: 0.2490 - val_loss: 0.4578 - val_accuracy: 0.8110 - val_mean_absolute_error: 0.2702\n",
      "Epoch 83/250\n",
      "16800/16800 [==============================] - 2s 119us/sample - loss: 0.4004 - accuracy: 0.8303 - mean_absolute_error: 0.2480 - val_loss: 0.4564 - val_accuracy: 0.8124 - val_mean_absolute_error: 0.2662\n",
      "Epoch 84/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.4041 - accuracy: 0.8297 - mean_absolute_error: 0.2507 - val_loss: 0.4576 - val_accuracy: 0.8107 - val_mean_absolute_error: 0.2706\n",
      "Epoch 85/250\n",
      "16800/16800 [==============================] - 2s 127us/sample - loss: 0.4037 - accuracy: 0.8292 - mean_absolute_error: 0.2501 - val_loss: 0.4571 - val_accuracy: 0.8045 - val_mean_absolute_error: 0.2710\n",
      "Epoch 86/250\n",
      "16800/16800 [==============================] - 2s 127us/sample - loss: 0.3998 - accuracy: 0.8342 - mean_absolute_error: 0.2481 - val_loss: 0.4602 - val_accuracy: 0.8081 - val_mean_absolute_error: 0.2697\n",
      "Epoch 87/250\n",
      "16800/16800 [==============================] - 2s 121us/sample - loss: 0.4007 - accuracy: 0.8322 - mean_absolute_error: 0.2479 - val_loss: 0.4602 - val_accuracy: 0.8114 - val_mean_absolute_error: 0.2599\n",
      "Epoch 88/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.3987 - accuracy: 0.8342 - mean_absolute_error: 0.2455 - val_loss: 0.4579 - val_accuracy: 0.8093 - val_mean_absolute_error: 0.2761\n",
      "Epoch 89/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.4012 - accuracy: 0.8324 - mean_absolute_error: 0.2472 - val_loss: 0.4564 - val_accuracy: 0.8095 - val_mean_absolute_error: 0.2708\n",
      "Epoch 90/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.4012 - accuracy: 0.8301 - mean_absolute_error: 0.2495 - val_loss: 0.4615 - val_accuracy: 0.8119 - val_mean_absolute_error: 0.2634\n",
      "Epoch 91/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.3989 - accuracy: 0.8315 - mean_absolute_error: 0.2465 - val_loss: 0.4564 - val_accuracy: 0.8129 - val_mean_absolute_error: 0.2678\n",
      "Epoch 92/250\n",
      "16800/16800 [==============================] - 2s 121us/sample - loss: 0.4001 - accuracy: 0.8314 - mean_absolute_error: 0.2468 - val_loss: 0.4588 - val_accuracy: 0.8112 - val_mean_absolute_error: 0.2640\n",
      "Epoch 93/250\n",
      "16800/16800 [==============================] - 2s 132us/sample - loss: 0.3996 - accuracy: 0.8335 - mean_absolute_error: 0.2473 - val_loss: 0.4594 - val_accuracy: 0.8079 - val_mean_absolute_error: 0.2716\n",
      "Epoch 94/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.4014 - accuracy: 0.8315 - mean_absolute_error: 0.2485 - val_loss: 0.4657 - val_accuracy: 0.8121 - val_mean_absolute_error: 0.2549\n",
      "Epoch 95/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.4003 - accuracy: 0.8314 - mean_absolute_error: 0.2482 - val_loss: 0.4605 - val_accuracy: 0.8114 - val_mean_absolute_error: 0.2605\n",
      "Epoch 96/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.3990 - accuracy: 0.8304 - mean_absolute_error: 0.2473 - val_loss: 0.4594 - val_accuracy: 0.8095 - val_mean_absolute_error: 0.2695\n",
      "Epoch 97/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.3976 - accuracy: 0.8311 - mean_absolute_error: 0.2471 - val_loss: 0.4608 - val_accuracy: 0.8110 - val_mean_absolute_error: 0.2648\n",
      "Epoch 98/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.3992 - accuracy: 0.8317 - mean_absolute_error: 0.2467 - val_loss: 0.4616 - val_accuracy: 0.8069 - val_mean_absolute_error: 0.2641\n",
      "Epoch 99/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.3986 - accuracy: 0.8314 - mean_absolute_error: 0.2455 - val_loss: 0.4586 - val_accuracy: 0.8071 - val_mean_absolute_error: 0.2706\n",
      "Epoch 100/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.3993 - accuracy: 0.8314 - mean_absolute_error: 0.2463 - val_loss: 0.4583 - val_accuracy: 0.8114 - val_mean_absolute_error: 0.2589\n",
      "Epoch 101/250\n",
      "16800/16800 [==============================] - 2s 128us/sample - loss: 0.4016 - accuracy: 0.8299 - mean_absolute_error: 0.2479 - val_loss: 0.4580 - val_accuracy: 0.8117 - val_mean_absolute_error: 0.2669\n",
      "Epoch 102/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.4010 - accuracy: 0.8309 - mean_absolute_error: 0.2480 - val_loss: 0.4596 - val_accuracy: 0.8086 - val_mean_absolute_error: 0.2711\n",
      "Epoch 103/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.3982 - accuracy: 0.8324 - mean_absolute_error: 0.2464 - val_loss: 0.4643 - val_accuracy: 0.8079 - val_mean_absolute_error: 0.2645\n",
      "Epoch 104/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.3958 - accuracy: 0.8324 - mean_absolute_error: 0.2458 - val_loss: 0.4627 - val_accuracy: 0.8117 - val_mean_absolute_error: 0.2645\n",
      "Epoch 105/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.3985 - accuracy: 0.8307 - mean_absolute_error: 0.2467 - val_loss: 0.4639 - val_accuracy: 0.8102 - val_mean_absolute_error: 0.2602\n",
      "Epoch 106/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.3983 - accuracy: 0.8324 - mean_absolute_error: 0.2452 - val_loss: 0.4630 - val_accuracy: 0.8093 - val_mean_absolute_error: 0.2629\n",
      "Epoch 107/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.3966 - accuracy: 0.8342 - mean_absolute_error: 0.2452 - val_loss: 0.4592 - val_accuracy: 0.8102 - val_mean_absolute_error: 0.2716\n",
      "Epoch 108/250\n",
      "16800/16800 [==============================] - 2s 130us/sample - loss: 0.3980 - accuracy: 0.8325 - mean_absolute_error: 0.2458 - val_loss: 0.4610 - val_accuracy: 0.8126 - val_mean_absolute_error: 0.2601\n",
      "Epoch 109/250\n",
      "16800/16800 [==============================] - 2s 125us/sample - loss: 0.3976 - accuracy: 0.8315 - mean_absolute_error: 0.2454 - val_loss: 0.4612 - val_accuracy: 0.8102 - val_mean_absolute_error: 0.2659\n",
      "Epoch 110/250\n",
      "16800/16800 [==============================] - 2s 125us/sample - loss: 0.3954 - accuracy: 0.8333 - mean_absolute_error: 0.2457 - val_loss: 0.4634 - val_accuracy: 0.8105 - val_mean_absolute_error: 0.2610\n",
      "Epoch 111/250\n",
      "16800/16800 [==============================] - 2s 121us/sample - loss: 0.3965 - accuracy: 0.8325 - mean_absolute_error: 0.2445 - val_loss: 0.4644 - val_accuracy: 0.8105 - val_mean_absolute_error: 0.2600\n",
      "Epoch 112/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.3961 - accuracy: 0.8321 - mean_absolute_error: 0.2448 - val_loss: 0.4679 - val_accuracy: 0.8069 - val_mean_absolute_error: 0.2668\n",
      "Epoch 113/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.3965 - accuracy: 0.8338 - mean_absolute_error: 0.2457 - val_loss: 0.4645 - val_accuracy: 0.8157 - val_mean_absolute_error: 0.2573\n",
      "Epoch 114/250\n",
      "16800/16800 [==============================] - 2s 121us/sample - loss: 0.3933 - accuracy: 0.8336 - mean_absolute_error: 0.2422 - val_loss: 0.4665 - val_accuracy: 0.8102 - val_mean_absolute_error: 0.2706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.3961 - accuracy: 0.8330 - mean_absolute_error: 0.2446 - val_loss: 0.4660 - val_accuracy: 0.8114 - val_mean_absolute_error: 0.2633\n",
      "Epoch 116/250\n",
      "16800/16800 [==============================] - 2s 130us/sample - loss: 0.3960 - accuracy: 0.8323 - mean_absolute_error: 0.2436 - val_loss: 0.4667 - val_accuracy: 0.8048 - val_mean_absolute_error: 0.2783\n",
      "Epoch 117/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.3967 - accuracy: 0.8326 - mean_absolute_error: 0.2456 - val_loss: 0.4651 - val_accuracy: 0.8098 - val_mean_absolute_error: 0.2643\n",
      "Epoch 118/250\n",
      "16800/16800 [==============================] - 2s 121us/sample - loss: 0.3926 - accuracy: 0.8338 - mean_absolute_error: 0.2425 - val_loss: 0.4625 - val_accuracy: 0.8121 - val_mean_absolute_error: 0.2654\n",
      "Epoch 119/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.3963 - accuracy: 0.8325 - mean_absolute_error: 0.2448 - val_loss: 0.4662 - val_accuracy: 0.8086 - val_mean_absolute_error: 0.2676\n",
      "Epoch 120/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.3949 - accuracy: 0.8330 - mean_absolute_error: 0.2439 - val_loss: 0.4663 - val_accuracy: 0.8131 - val_mean_absolute_error: 0.2616\n",
      "Epoch 121/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.3938 - accuracy: 0.8335 - mean_absolute_error: 0.2425 - val_loss: 0.4662 - val_accuracy: 0.8100 - val_mean_absolute_error: 0.2706\n",
      "Epoch 122/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.3932 - accuracy: 0.8352 - mean_absolute_error: 0.2425 - val_loss: 0.4661 - val_accuracy: 0.8069 - val_mean_absolute_error: 0.2703\n",
      "Epoch 123/250\n",
      "16800/16800 [==============================] - 2s 127us/sample - loss: 0.3943 - accuracy: 0.8338 - mean_absolute_error: 0.2441 - val_loss: 0.4646 - val_accuracy: 0.8102 - val_mean_absolute_error: 0.2591\n",
      "Epoch 124/250\n",
      "16800/16800 [==============================] - 2s 129us/sample - loss: 0.3939 - accuracy: 0.8328 - mean_absolute_error: 0.2425 - val_loss: 0.4633 - val_accuracy: 0.8090 - val_mean_absolute_error: 0.2748\n",
      "Epoch 125/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.3910 - accuracy: 0.8337 - mean_absolute_error: 0.2425 - val_loss: 0.4638 - val_accuracy: 0.8117 - val_mean_absolute_error: 0.2678\n",
      "Epoch 126/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.3926 - accuracy: 0.8350 - mean_absolute_error: 0.2429 - val_loss: 0.4673 - val_accuracy: 0.8117 - val_mean_absolute_error: 0.2623\n",
      "Epoch 127/250\n",
      "16800/16800 [==============================] - 2s 125us/sample - loss: 0.3939 - accuracy: 0.8355 - mean_absolute_error: 0.2428 - val_loss: 0.4680 - val_accuracy: 0.8140 - val_mean_absolute_error: 0.2617\n",
      "Epoch 128/250\n",
      "16800/16800 [==============================] - 2s 121us/sample - loss: 0.3937 - accuracy: 0.8323 - mean_absolute_error: 0.2422 - val_loss: 0.4662 - val_accuracy: 0.8121 - val_mean_absolute_error: 0.2631\n",
      "Epoch 129/250\n",
      "16800/16800 [==============================] - 2s 121us/sample - loss: 0.3948 - accuracy: 0.8346 - mean_absolute_error: 0.2430 - val_loss: 0.4669 - val_accuracy: 0.8126 - val_mean_absolute_error: 0.2577\n",
      "Epoch 130/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.3922 - accuracy: 0.8329 - mean_absolute_error: 0.2421 - val_loss: 0.4646 - val_accuracy: 0.8062 - val_mean_absolute_error: 0.2733\n",
      "Epoch 131/250\n",
      "16800/16800 [==============================] - 2s 131us/sample - loss: 0.3929 - accuracy: 0.8339 - mean_absolute_error: 0.2424 - val_loss: 0.4662 - val_accuracy: 0.8107 - val_mean_absolute_error: 0.2615\n",
      "Epoch 132/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.3907 - accuracy: 0.8342 - mean_absolute_error: 0.2420 - val_loss: 0.4685 - val_accuracy: 0.8067 - val_mean_absolute_error: 0.2649\n",
      "Epoch 133/250\n",
      "16800/16800 [==============================] - 2s 121us/sample - loss: 0.3901 - accuracy: 0.8358 - mean_absolute_error: 0.2409 - val_loss: 0.4686 - val_accuracy: 0.8067 - val_mean_absolute_error: 0.2658\n",
      "Epoch 134/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.3946 - accuracy: 0.8333 - mean_absolute_error: 0.2424 - val_loss: 0.4766 - val_accuracy: 0.8088 - val_mean_absolute_error: 0.2536\n",
      "Epoch 135/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.3912 - accuracy: 0.8340 - mean_absolute_error: 0.2404 - val_loss: 0.4679 - val_accuracy: 0.8110 - val_mean_absolute_error: 0.2668\n",
      "Epoch 136/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.3936 - accuracy: 0.8332 - mean_absolute_error: 0.2435 - val_loss: 0.4705 - val_accuracy: 0.8071 - val_mean_absolute_error: 0.2707\n",
      "Epoch 137/250\n",
      "16800/16800 [==============================] - 2s 121us/sample - loss: 0.3918 - accuracy: 0.8343 - mean_absolute_error: 0.2420 - val_loss: 0.4675 - val_accuracy: 0.8052 - val_mean_absolute_error: 0.2743\n",
      "Epoch 138/250\n",
      "16800/16800 [==============================] - 2s 120us/sample - loss: 0.3908 - accuracy: 0.8346 - mean_absolute_error: 0.2422 - val_loss: 0.4684 - val_accuracy: 0.8095 - val_mean_absolute_error: 0.2579\n",
      "Epoch 139/250\n",
      "16800/16800 [==============================] - 2s 133us/sample - loss: 0.3910 - accuracy: 0.8339 - mean_absolute_error: 0.2413 - val_loss: 0.4731 - val_accuracy: 0.8129 - val_mean_absolute_error: 0.2604\n",
      "Epoch 140/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.3902 - accuracy: 0.8348 - mean_absolute_error: 0.2411 - val_loss: 0.4769 - val_accuracy: 0.8093 - val_mean_absolute_error: 0.2630\n",
      "Epoch 141/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.3917 - accuracy: 0.8351 - mean_absolute_error: 0.2420 - val_loss: 0.4738 - val_accuracy: 0.8102 - val_mean_absolute_error: 0.2611\n",
      "Epoch 142/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.3911 - accuracy: 0.8361 - mean_absolute_error: 0.2401 - val_loss: 0.4675 - val_accuracy: 0.8083 - val_mean_absolute_error: 0.2655\n",
      "Epoch 143/250\n",
      "16800/16800 [==============================] - 2s 121us/sample - loss: 0.3895 - accuracy: 0.8365 - mean_absolute_error: 0.2403 - val_loss: 0.4717 - val_accuracy: 0.8064 - val_mean_absolute_error: 0.2645\n",
      "Epoch 144/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.3892 - accuracy: 0.8349 - mean_absolute_error: 0.2395 - val_loss: 0.4697 - val_accuracy: 0.8000 - val_mean_absolute_error: 0.2753\n",
      "Epoch 145/250\n",
      "16800/16800 [==============================] - 2s 121us/sample - loss: 0.3923 - accuracy: 0.8355 - mean_absolute_error: 0.2428 - val_loss: 0.4710 - val_accuracy: 0.8100 - val_mean_absolute_error: 0.2622\n",
      "Epoch 146/250\n",
      "16800/16800 [==============================] - 2s 128us/sample - loss: 0.3923 - accuracy: 0.8339 - mean_absolute_error: 0.2403 - val_loss: 0.4671 - val_accuracy: 0.8081 - val_mean_absolute_error: 0.2620\n",
      "Epoch 147/250\n",
      "16800/16800 [==============================] - 2s 127us/sample - loss: 0.3881 - accuracy: 0.8372 - mean_absolute_error: 0.2393 - val_loss: 0.4666 - val_accuracy: 0.8098 - val_mean_absolute_error: 0.2747\n",
      "Epoch 148/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.3906 - accuracy: 0.8330 - mean_absolute_error: 0.2420 - val_loss: 0.4692 - val_accuracy: 0.8093 - val_mean_absolute_error: 0.2611\n",
      "Epoch 149/250\n",
      "16800/16800 [==============================] - 3s 154us/sample - loss: 0.3878 - accuracy: 0.8368 - mean_absolute_error: 0.2387 - val_loss: 0.4711 - val_accuracy: 0.8107 - val_mean_absolute_error: 0.2681\n",
      "Epoch 150/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.3908 - accuracy: 0.8359 - mean_absolute_error: 0.2411 - val_loss: 0.4718 - val_accuracy: 0.8079 - val_mean_absolute_error: 0.2593\n",
      "Epoch 151/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.3919 - accuracy: 0.8342 - mean_absolute_error: 0.2414 - val_loss: 0.4669 - val_accuracy: 0.8071 - val_mean_absolute_error: 0.2641\n",
      "Epoch 152/250\n",
      "16800/16800 [==============================] - 2s 117us/sample - loss: 0.3871 - accuracy: 0.8348 - mean_absolute_error: 0.2399 - val_loss: 0.4743 - val_accuracy: 0.8074 - val_mean_absolute_error: 0.2612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/250\n",
      "16800/16800 [==============================] - 2s 118us/sample - loss: 0.3889 - accuracy: 0.8347 - mean_absolute_error: 0.2389 - val_loss: 0.4652 - val_accuracy: 0.8071 - val_mean_absolute_error: 0.2688\n",
      "Epoch 154/250\n",
      "16800/16800 [==============================] - 2s 125us/sample - loss: 0.3879 - accuracy: 0.8355 - mean_absolute_error: 0.2391 - val_loss: 0.4700 - val_accuracy: 0.8076 - val_mean_absolute_error: 0.2614\n",
      "Epoch 155/250\n",
      "16800/16800 [==============================] - 2s 119us/sample - loss: 0.3882 - accuracy: 0.8354 - mean_absolute_error: 0.2394 - val_loss: 0.4714 - val_accuracy: 0.8069 - val_mean_absolute_error: 0.2616\n",
      "Epoch 156/250\n",
      "16800/16800 [==============================] - 2s 115us/sample - loss: 0.3895 - accuracy: 0.8337 - mean_absolute_error: 0.2402 - val_loss: 0.4683 - val_accuracy: 0.8074 - val_mean_absolute_error: 0.2670\n",
      "Epoch 157/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3869 - accuracy: 0.8350 - mean_absolute_error: 0.2380 - val_loss: 0.4722 - val_accuracy: 0.8040 - val_mean_absolute_error: 0.2634\n",
      "Epoch 158/250\n",
      "16800/16800 [==============================] - 2s 120us/sample - loss: 0.3855 - accuracy: 0.8371 - mean_absolute_error: 0.2382 - val_loss: 0.4688 - val_accuracy: 0.8114 - val_mean_absolute_error: 0.2662\n",
      "Epoch 159/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3860 - accuracy: 0.8390 - mean_absolute_error: 0.2380 - val_loss: 0.4716 - val_accuracy: 0.8079 - val_mean_absolute_error: 0.2635\n",
      "Epoch 160/250\n",
      "16800/16800 [==============================] - 2s 125us/sample - loss: 0.3889 - accuracy: 0.8376 - mean_absolute_error: 0.2381 - val_loss: 0.4682 - val_accuracy: 0.8112 - val_mean_absolute_error: 0.2609\n",
      "Epoch 161/250\n",
      "16800/16800 [==============================] - 2s 125us/sample - loss: 0.3877 - accuracy: 0.8363 - mean_absolute_error: 0.2386 - val_loss: 0.4698 - val_accuracy: 0.8081 - val_mean_absolute_error: 0.2633\n",
      "Epoch 162/250\n",
      "16800/16800 [==============================] - 2s 131us/sample - loss: 0.3876 - accuracy: 0.8362 - mean_absolute_error: 0.2395 - val_loss: 0.4726 - val_accuracy: 0.8110 - val_mean_absolute_error: 0.2607\n",
      "Epoch 163/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.3860 - accuracy: 0.8351 - mean_absolute_error: 0.2383 - val_loss: 0.4791 - val_accuracy: 0.8081 - val_mean_absolute_error: 0.2574\n",
      "Epoch 164/250\n",
      "16800/16800 [==============================] - 2s 127us/sample - loss: 0.3847 - accuracy: 0.8376 - mean_absolute_error: 0.2367 - val_loss: 0.4674 - val_accuracy: 0.8076 - val_mean_absolute_error: 0.2616\n",
      "Epoch 165/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.3880 - accuracy: 0.8351 - mean_absolute_error: 0.2391 - val_loss: 0.4672 - val_accuracy: 0.8081 - val_mean_absolute_error: 0.2640\n",
      "Epoch 166/250\n",
      "16800/16800 [==============================] - 2s 128us/sample - loss: 0.3836 - accuracy: 0.8377 - mean_absolute_error: 0.2368 - val_loss: 0.4755 - val_accuracy: 0.7995 - val_mean_absolute_error: 0.2675\n",
      "Epoch 167/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.3874 - accuracy: 0.8380 - mean_absolute_error: 0.2371 - val_loss: 0.4710 - val_accuracy: 0.8090 - val_mean_absolute_error: 0.2687\n",
      "Epoch 168/250\n",
      "16800/16800 [==============================] - 2s 117us/sample - loss: 0.3851 - accuracy: 0.8379 - mean_absolute_error: 0.2376 - val_loss: 0.4732 - val_accuracy: 0.8064 - val_mean_absolute_error: 0.2676\n",
      "Epoch 169/250\n",
      "16800/16800 [==============================] - 2s 119us/sample - loss: 0.3893 - accuracy: 0.8357 - mean_absolute_error: 0.2389 - val_loss: 0.4738 - val_accuracy: 0.8010 - val_mean_absolute_error: 0.2753\n",
      "Epoch 170/250\n",
      "16800/16800 [==============================] - 2s 127us/sample - loss: 0.3854 - accuracy: 0.8370 - mean_absolute_error: 0.2385 - val_loss: 0.4765 - val_accuracy: 0.8067 - val_mean_absolute_error: 0.2673\n",
      "Epoch 171/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3881 - accuracy: 0.8369 - mean_absolute_error: 0.2377 - val_loss: 0.4662 - val_accuracy: 0.8079 - val_mean_absolute_error: 0.2723\n",
      "Epoch 172/250\n",
      "16800/16800 [==============================] - 2s 117us/sample - loss: 0.3848 - accuracy: 0.8361 - mean_absolute_error: 0.2376 - val_loss: 0.4740 - val_accuracy: 0.8062 - val_mean_absolute_error: 0.2634\n",
      "Epoch 173/250\n",
      "16800/16800 [==============================] - 2s 118us/sample - loss: 0.3832 - accuracy: 0.8384 - mean_absolute_error: 0.2361 - val_loss: 0.4710 - val_accuracy: 0.8026 - val_mean_absolute_error: 0.2717\n",
      "Epoch 174/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3856 - accuracy: 0.8385 - mean_absolute_error: 0.2376 - val_loss: 0.4769 - val_accuracy: 0.8055 - val_mean_absolute_error: 0.2627\n",
      "Epoch 175/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3854 - accuracy: 0.8373 - mean_absolute_error: 0.2364 - val_loss: 0.4751 - val_accuracy: 0.8052 - val_mean_absolute_error: 0.2687\n",
      "Epoch 176/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3831 - accuracy: 0.8399 - mean_absolute_error: 0.2353 - val_loss: 0.4759 - val_accuracy: 0.8064 - val_mean_absolute_error: 0.2653\n",
      "Epoch 177/250\n",
      "16800/16800 [==============================] - 2s 115us/sample - loss: 0.3850 - accuracy: 0.8367 - mean_absolute_error: 0.2371 - val_loss: 0.4779 - val_accuracy: 0.8012 - val_mean_absolute_error: 0.2668\n",
      "Epoch 178/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.3859 - accuracy: 0.8370 - mean_absolute_error: 0.2364 - val_loss: 0.4769 - val_accuracy: 0.8036 - val_mean_absolute_error: 0.2718\n",
      "Epoch 179/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3841 - accuracy: 0.8399 - mean_absolute_error: 0.2372 - val_loss: 0.4774 - val_accuracy: 0.8062 - val_mean_absolute_error: 0.2613\n",
      "Epoch 180/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3879 - accuracy: 0.8365 - mean_absolute_error: 0.2382 - val_loss: 0.4786 - val_accuracy: 0.8052 - val_mean_absolute_error: 0.2616\n",
      "Epoch 181/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3854 - accuracy: 0.8370 - mean_absolute_error: 0.2369 - val_loss: 0.4848 - val_accuracy: 0.8014 - val_mean_absolute_error: 0.2647\n",
      "Epoch 182/250\n",
      "16800/16800 [==============================] - 2s 115us/sample - loss: 0.3819 - accuracy: 0.8394 - mean_absolute_error: 0.2351 - val_loss: 0.4822 - val_accuracy: 0.8052 - val_mean_absolute_error: 0.2620\n",
      "Epoch 183/250\n",
      "16800/16800 [==============================] - 2s 119us/sample - loss: 0.3863 - accuracy: 0.8365 - mean_absolute_error: 0.2373 - val_loss: 0.4787 - val_accuracy: 0.8067 - val_mean_absolute_error: 0.2702\n",
      "Epoch 184/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.3886 - accuracy: 0.8361 - mean_absolute_error: 0.2389 - val_loss: 0.4758 - val_accuracy: 0.8088 - val_mean_absolute_error: 0.2628\n",
      "Epoch 185/250\n",
      "16800/16800 [==============================] - 2s 132us/sample - loss: 0.3826 - accuracy: 0.8386 - mean_absolute_error: 0.2369 - val_loss: 0.4870 - val_accuracy: 0.8095 - val_mean_absolute_error: 0.2576\n",
      "Epoch 186/250\n",
      "16800/16800 [==============================] - 2s 135us/sample - loss: 0.3822 - accuracy: 0.8392 - mean_absolute_error: 0.2354 - val_loss: 0.4861 - val_accuracy: 0.8038 - val_mean_absolute_error: 0.2641\n",
      "Epoch 187/250\n",
      "16800/16800 [==============================] - 2s 127us/sample - loss: 0.3847 - accuracy: 0.8365 - mean_absolute_error: 0.2356 - val_loss: 0.4810 - val_accuracy: 0.8057 - val_mean_absolute_error: 0.2690\n",
      "Epoch 188/250\n",
      "16800/16800 [==============================] - 2s 125us/sample - loss: 0.3828 - accuracy: 0.8380 - mean_absolute_error: 0.2356 - val_loss: 0.4829 - val_accuracy: 0.8086 - val_mean_absolute_error: 0.2598\n",
      "Epoch 189/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.3847 - accuracy: 0.8388 - mean_absolute_error: 0.2371 - val_loss: 0.4772 - val_accuracy: 0.8093 - val_mean_absolute_error: 0.2620\n",
      "Epoch 190/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.3824 - accuracy: 0.8394 - mean_absolute_error: 0.2346 - val_loss: 0.4806 - val_accuracy: 0.8083 - val_mean_absolute_error: 0.2678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/250\n",
      "16800/16800 [==============================] - 2s 123us/sample - loss: 0.3827 - accuracy: 0.8415 - mean_absolute_error: 0.2356 - val_loss: 0.4775 - val_accuracy: 0.8036 - val_mean_absolute_error: 0.2724\n",
      "Epoch 192/250\n",
      "16800/16800 [==============================] - 2s 117us/sample - loss: 0.3818 - accuracy: 0.8371 - mean_absolute_error: 0.2348 - val_loss: 0.4807 - val_accuracy: 0.8067 - val_mean_absolute_error: 0.2675\n",
      "Epoch 193/250\n",
      "16800/16800 [==============================] - 2s 122us/sample - loss: 0.3824 - accuracy: 0.8381 - mean_absolute_error: 0.2356 - val_loss: 0.4864 - val_accuracy: 0.8055 - val_mean_absolute_error: 0.2569\n",
      "Epoch 194/250\n",
      "16800/16800 [==============================] - 2s 119us/sample - loss: 0.3838 - accuracy: 0.8376 - mean_absolute_error: 0.2357 - val_loss: 0.4812 - val_accuracy: 0.8040 - val_mean_absolute_error: 0.2652\n",
      "Epoch 195/250\n",
      "16800/16800 [==============================] - 2s 117us/sample - loss: 0.3844 - accuracy: 0.8380 - mean_absolute_error: 0.2364 - val_loss: 0.4884 - val_accuracy: 0.8069 - val_mean_absolute_error: 0.2592\n",
      "Epoch 196/250\n",
      "16800/16800 [==============================] - 2s 113us/sample - loss: 0.3820 - accuracy: 0.8368 - mean_absolute_error: 0.2345 - val_loss: 0.4800 - val_accuracy: 0.8055 - val_mean_absolute_error: 0.2638\n",
      "Epoch 197/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3824 - accuracy: 0.8369 - mean_absolute_error: 0.2353 - val_loss: 0.4815 - val_accuracy: 0.8071 - val_mean_absolute_error: 0.2680\n",
      "Epoch 198/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3817 - accuracy: 0.8376 - mean_absolute_error: 0.2351 - val_loss: 0.4842 - val_accuracy: 0.8079 - val_mean_absolute_error: 0.2636\n",
      "Epoch 199/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3830 - accuracy: 0.8387 - mean_absolute_error: 0.2350 - val_loss: 0.4795 - val_accuracy: 0.8088 - val_mean_absolute_error: 0.2657\n",
      "Epoch 200/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3833 - accuracy: 0.8390 - mean_absolute_error: 0.2348 - val_loss: 0.4803 - val_accuracy: 0.8036 - val_mean_absolute_error: 0.2667\n",
      "Epoch 201/250\n",
      "16800/16800 [==============================] - 2s 119us/sample - loss: 0.3829 - accuracy: 0.8370 - mean_absolute_error: 0.2358 - val_loss: 0.4827 - val_accuracy: 0.8079 - val_mean_absolute_error: 0.2626\n",
      "Epoch 202/250\n",
      "16800/16800 [==============================] - 2s 126us/sample - loss: 0.3838 - accuracy: 0.8386 - mean_absolute_error: 0.2354 - val_loss: 0.4817 - val_accuracy: 0.8107 - val_mean_absolute_error: 0.2592\n",
      "Epoch 203/250\n",
      "16800/16800 [==============================] - 2s 115us/sample - loss: 0.3816 - accuracy: 0.8400 - mean_absolute_error: 0.2341 - val_loss: 0.4782 - val_accuracy: 0.8045 - val_mean_absolute_error: 0.2705\n",
      "Epoch 204/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3812 - accuracy: 0.8392 - mean_absolute_error: 0.2348 - val_loss: 0.4851 - val_accuracy: 0.8067 - val_mean_absolute_error: 0.2603\n",
      "Epoch 205/250\n",
      "16800/16800 [==============================] - 2s 119us/sample - loss: 0.3829 - accuracy: 0.8407 - mean_absolute_error: 0.2348 - val_loss: 0.4845 - val_accuracy: 0.8081 - val_mean_absolute_error: 0.2601\n",
      "Epoch 206/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3803 - accuracy: 0.8405 - mean_absolute_error: 0.2338 - val_loss: 0.4845 - val_accuracy: 0.8052 - val_mean_absolute_error: 0.2657\n",
      "Epoch 207/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3840 - accuracy: 0.8386 - mean_absolute_error: 0.2345 - val_loss: 0.4802 - val_accuracy: 0.8060 - val_mean_absolute_error: 0.2634\n",
      "Epoch 208/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3792 - accuracy: 0.8410 - mean_absolute_error: 0.2339 - val_loss: 0.4888 - val_accuracy: 0.8048 - val_mean_absolute_error: 0.2618\n",
      "Epoch 209/250\n",
      "16800/16800 [==============================] - 2s 117us/sample - loss: 0.3841 - accuracy: 0.8392 - mean_absolute_error: 0.2348 - val_loss: 0.4768 - val_accuracy: 0.8057 - val_mean_absolute_error: 0.2709\n",
      "Epoch 210/250\n",
      "16800/16800 [==============================] - 2s 127us/sample - loss: 0.3818 - accuracy: 0.8398 - mean_absolute_error: 0.2342 - val_loss: 0.4817 - val_accuracy: 0.8069 - val_mean_absolute_error: 0.2642\n",
      "Epoch 211/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3816 - accuracy: 0.8383 - mean_absolute_error: 0.2355 - val_loss: 0.4915 - val_accuracy: 0.8036 - val_mean_absolute_error: 0.2650\n",
      "Epoch 212/250\n",
      "16800/16800 [==============================] - 2s 115us/sample - loss: 0.3824 - accuracy: 0.8392 - mean_absolute_error: 0.2342 - val_loss: 0.4858 - val_accuracy: 0.8019 - val_mean_absolute_error: 0.2690\n",
      "Epoch 213/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3801 - accuracy: 0.8392 - mean_absolute_error: 0.2337 - val_loss: 0.4823 - val_accuracy: 0.8074 - val_mean_absolute_error: 0.2659\n",
      "Epoch 214/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3810 - accuracy: 0.8375 - mean_absolute_error: 0.2347 - val_loss: 0.4829 - val_accuracy: 0.8086 - val_mean_absolute_error: 0.2616\n",
      "Epoch 215/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3803 - accuracy: 0.8410 - mean_absolute_error: 0.2333 - val_loss: 0.4847 - val_accuracy: 0.8050 - val_mean_absolute_error: 0.2628\n",
      "Epoch 216/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3820 - accuracy: 0.8398 - mean_absolute_error: 0.2340 - val_loss: 0.4852 - val_accuracy: 0.8086 - val_mean_absolute_error: 0.2657\n",
      "Epoch 217/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3793 - accuracy: 0.8395 - mean_absolute_error: 0.2343 - val_loss: 0.4896 - val_accuracy: 0.8110 - val_mean_absolute_error: 0.2566\n",
      "Epoch 218/250\n",
      "16800/16800 [==============================] - 2s 127us/sample - loss: 0.3793 - accuracy: 0.8405 - mean_absolute_error: 0.2313 - val_loss: 0.4825 - val_accuracy: 0.8062 - val_mean_absolute_error: 0.2624\n",
      "Epoch 219/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3830 - accuracy: 0.8389 - mean_absolute_error: 0.2347 - val_loss: 0.4852 - val_accuracy: 0.8050 - val_mean_absolute_error: 0.2639\n",
      "Epoch 220/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3798 - accuracy: 0.8393 - mean_absolute_error: 0.2347 - val_loss: 0.4851 - val_accuracy: 0.8110 - val_mean_absolute_error: 0.2589\n",
      "Epoch 221/250\n",
      "16800/16800 [==============================] - 2s 121us/sample - loss: 0.3821 - accuracy: 0.8389 - mean_absolute_error: 0.2339 - val_loss: 0.4864 - val_accuracy: 0.8081 - val_mean_absolute_error: 0.2639\n",
      "Epoch 222/250\n",
      "16800/16800 [==============================] - 2s 132us/sample - loss: 0.3798 - accuracy: 0.8401 - mean_absolute_error: 0.2325 - val_loss: 0.4836 - val_accuracy: 0.8057 - val_mean_absolute_error: 0.2672\n",
      "Epoch 223/250\n",
      "16800/16800 [==============================] - 2s 117us/sample - loss: 0.3797 - accuracy: 0.8392 - mean_absolute_error: 0.2341 - val_loss: 0.4884 - val_accuracy: 0.8079 - val_mean_absolute_error: 0.2636\n",
      "Epoch 224/250\n",
      "16800/16800 [==============================] - 2s 117us/sample - loss: 0.3801 - accuracy: 0.8379 - mean_absolute_error: 0.2328 - val_loss: 0.4913 - val_accuracy: 0.8031 - val_mean_absolute_error: 0.2693\n",
      "Epoch 225/250\n",
      "16800/16800 [==============================] - 2s 119us/sample - loss: 0.3774 - accuracy: 0.8405 - mean_absolute_error: 0.2319 - val_loss: 0.4919 - val_accuracy: 0.8069 - val_mean_absolute_error: 0.2585\n",
      "Epoch 226/250\n",
      "16800/16800 [==============================] - 2s 125us/sample - loss: 0.3794 - accuracy: 0.8417 - mean_absolute_error: 0.2326 - val_loss: 0.4890 - val_accuracy: 0.8036 - val_mean_absolute_error: 0.2684\n",
      "Epoch 227/250\n",
      "16800/16800 [==============================] - 2s 118us/sample - loss: 0.3782 - accuracy: 0.8405 - mean_absolute_error: 0.2307 - val_loss: 0.4829 - val_accuracy: 0.8038 - val_mean_absolute_error: 0.2715\n",
      "Epoch 228/250\n",
      "16800/16800 [==============================] - 2s 117us/sample - loss: 0.3795 - accuracy: 0.8393 - mean_absolute_error: 0.2337 - val_loss: 0.4868 - val_accuracy: 0.8043 - val_mean_absolute_error: 0.2709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3820 - accuracy: 0.8407 - mean_absolute_error: 0.2346 - val_loss: 0.4838 - val_accuracy: 0.8052 - val_mean_absolute_error: 0.2642\n",
      "Epoch 230/250\n",
      "16800/16800 [==============================] - 2s 115us/sample - loss: 0.3794 - accuracy: 0.8403 - mean_absolute_error: 0.2330 - val_loss: 0.4883 - val_accuracy: 0.8024 - val_mean_absolute_error: 0.2668\n",
      "Epoch 231/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3767 - accuracy: 0.8414 - mean_absolute_error: 0.2320 - val_loss: 0.4970 - val_accuracy: 0.8067 - val_mean_absolute_error: 0.2578\n",
      "Epoch 232/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3798 - accuracy: 0.8413 - mean_absolute_error: 0.2330 - val_loss: 0.4901 - val_accuracy: 0.8043 - val_mean_absolute_error: 0.2634\n",
      "Epoch 233/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3769 - accuracy: 0.8417 - mean_absolute_error: 0.2315 - val_loss: 0.4864 - val_accuracy: 0.8029 - val_mean_absolute_error: 0.2654\n",
      "Epoch 234/250\n",
      "16800/16800 [==============================] - 2s 127us/sample - loss: 0.3791 - accuracy: 0.8402 - mean_absolute_error: 0.2325 - val_loss: 0.4855 - val_accuracy: 0.8071 - val_mean_absolute_error: 0.2652\n",
      "Epoch 235/250\n",
      "16800/16800 [==============================] - 2s 115us/sample - loss: 0.3837 - accuracy: 0.8383 - mean_absolute_error: 0.2351 - val_loss: 0.4881 - val_accuracy: 0.8088 - val_mean_absolute_error: 0.2621\n",
      "Epoch 236/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3788 - accuracy: 0.8408 - mean_absolute_error: 0.2328 - val_loss: 0.4959 - val_accuracy: 0.8019 - val_mean_absolute_error: 0.2687\n",
      "Epoch 237/250\n",
      "16800/16800 [==============================] - 2s 113us/sample - loss: 0.3794 - accuracy: 0.8404 - mean_absolute_error: 0.2316 - val_loss: 0.4895 - val_accuracy: 0.8043 - val_mean_absolute_error: 0.2690\n",
      "Epoch 238/250\n",
      "16800/16800 [==============================] - 2s 117us/sample - loss: 0.3767 - accuracy: 0.8412 - mean_absolute_error: 0.2313 - val_loss: 0.4905 - val_accuracy: 0.8024 - val_mean_absolute_error: 0.2644\n",
      "Epoch 239/250\n",
      "16800/16800 [==============================] - 2s 115us/sample - loss: 0.3786 - accuracy: 0.8389 - mean_absolute_error: 0.2319 - val_loss: 0.4893 - val_accuracy: 0.8007 - val_mean_absolute_error: 0.2713\n",
      "Epoch 240/250\n",
      "16800/16800 [==============================] - 2s 118us/sample - loss: 0.3811 - accuracy: 0.8405 - mean_absolute_error: 0.2334 - val_loss: 0.4891 - val_accuracy: 0.8050 - val_mean_absolute_error: 0.2625\n",
      "Epoch 241/250\n",
      "16800/16800 [==============================] - 2s 115us/sample - loss: 0.3752 - accuracy: 0.8429 - mean_absolute_error: 0.2307 - val_loss: 0.4934 - val_accuracy: 0.8100 - val_mean_absolute_error: 0.2554\n",
      "Epoch 242/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.3776 - accuracy: 0.8401 - mean_absolute_error: 0.2314 - val_loss: 0.4863 - val_accuracy: 0.8060 - val_mean_absolute_error: 0.2667\n",
      "Epoch 243/250\n",
      "16800/16800 [==============================] - 2s 119us/sample - loss: 0.3772 - accuracy: 0.8414 - mean_absolute_error: 0.2322 - val_loss: 0.4921 - val_accuracy: 0.8079 - val_mean_absolute_error: 0.2613\n",
      "Epoch 244/250\n",
      "16800/16800 [==============================] - 2s 113us/sample - loss: 0.3753 - accuracy: 0.8424 - mean_absolute_error: 0.2296 - val_loss: 0.4911 - val_accuracy: 0.8060 - val_mean_absolute_error: 0.2589\n",
      "Epoch 245/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3732 - accuracy: 0.8418 - mean_absolute_error: 0.2299 - val_loss: 0.4963 - val_accuracy: 0.8069 - val_mean_absolute_error: 0.2560\n",
      "Epoch 246/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3782 - accuracy: 0.8404 - mean_absolute_error: 0.2307 - val_loss: 0.4855 - val_accuracy: 0.8064 - val_mean_absolute_error: 0.2568\n",
      "Epoch 247/250\n",
      "16800/16800 [==============================] - 2s 114us/sample - loss: 0.3816 - accuracy: 0.8391 - mean_absolute_error: 0.2326 - val_loss: 0.4920 - val_accuracy: 0.8033 - val_mean_absolute_error: 0.2663\n",
      "Epoch 248/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3766 - accuracy: 0.8408 - mean_absolute_error: 0.2308 - val_loss: 0.4846 - val_accuracy: 0.8000 - val_mean_absolute_error: 0.2676\n",
      "Epoch 249/250\n",
      "16800/16800 [==============================] - 2s 116us/sample - loss: 0.3780 - accuracy: 0.8423 - mean_absolute_error: 0.2323 - val_loss: 0.4861 - val_accuracy: 0.8074 - val_mean_absolute_error: 0.2685\n",
      "Epoch 250/250\n",
      "16800/16800 [==============================] - 2s 124us/sample - loss: 0.3781 - accuracy: 0.8413 - mean_absolute_error: 0.2317 - val_loss: 0.4865 - val_accuracy: 0.8029 - val_mean_absolute_error: 0.2661\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=[\"accuracy\", \"mean_absolute_error\"]\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, Y_train, batch_size=64, epochs=250, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03a7dc7",
   "metadata": {},
   "source": [
    "### Get statistics on simple nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d02d6a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netwo\\anaconda3\\envs\\Thesis-minimum\\lib\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "# Scores on test set\n",
    "test_scores = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd3c995d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02858746],\n",
       "       [0.3252348 ],\n",
       "       [0.37272477],\n",
       "       ...,\n",
       "       [0.16782422],\n",
       "       [0.07963651],\n",
       "       [0.06422914]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7aff516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8599222577374512"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train AUC\n",
    "roc_auc_score(Y_train, model.predict(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43486bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions (0 or 1) on test set\n",
    "test_preds = (test_scores >= np.mean(Y_train)) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "751f5d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netwo\\anaconda3\\envs\\Thesis-minimum\\lib\\site-packages\\fairlearn\\metrics\\_metric_frame.py:63: FutureWarning: You have provided 'metrics', 'y_true', 'y_pred' as positional arguments. Please pass them as keyword arguments. From version 0.10.0 passing them as positional arguments will result in an error.\n",
      "  warnings.warn(f\"You have provided {args_msg} as positional arguments. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.20902</td>\n",
       "      <td>0.395105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.241954</td>\n",
       "      <td>0.381346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             FPR       FNR\n",
       "SEX                       \n",
       "female   0.20902  0.395105\n",
       "male    0.241954  0.381346"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf = MetricFrame({\n",
    "    'FPR': false_positive_rate,\n",
    "    'FNR': false_negative_rate},\n",
    "    Y_test, test_preds, sensitive_features=A_str_test)\n",
    "\n",
    "mf.by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09842aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def get_metrics_df(models_dict, y_true, group):\n",
    "    metrics_dict = {\n",
    "        \"Overall selection rate\": (\n",
    "            lambda x: selection_rate(y_true, x), True),\n",
    "        \"Demographic parity difference\": (\n",
    "            lambda x: demographic_parity_difference(y_true, x, sensitive_features=group), True),\n",
    "        \"Demographic parity ratio\": (\n",
    "            lambda x: demographic_parity_ratio(y_true, x, sensitive_features=group), True),\n",
    "        \"------\": (lambda x: \"\", True),\n",
    "        \"Overall balanced error rate\": (\n",
    "            lambda x: 1-balanced_accuracy_score(y_true, x), True),\n",
    "        \"Balanced error rate difference\": (\n",
    "            lambda x: MetricFrame(metrics=balanced_accuracy_score, y_true=y_true, y_pred=x, sensitive_features=group).difference(method='between_groups'), True),\n",
    "        \" ------\": (lambda x: \"\", True),\n",
    "        \"False positive rate difference\": (\n",
    "            lambda x: false_positive_rate_difference(y_true, x, sensitive_features=group), True),\n",
    "        \"False negative rate difference\": (\n",
    "            lambda x: false_negative_rate_difference(y_true, x, sensitive_features=group), True),\n",
    "        \"Equalized odds difference\": (\n",
    "            lambda x: equalized_odds_difference(y_true, x, sensitive_features=group), True),\n",
    "        \"  ------\": (lambda x: \"\", True),\n",
    "        \"Overall AUC\": (\n",
    "            lambda x: roc_auc_score(y_true, x), False),\n",
    "        \"AUC difference\": (\n",
    "            lambda x: MetricFrame(metrics=roc_auc_score, y_true=y_true, y_pred=x, sensitive_features=group).difference(method='between_groups'), False),\n",
    "    }\n",
    "    df_dict = {}\n",
    "    for metric_name, (metric_func, use_preds) in metrics_dict.items():\n",
    "        df_dict[metric_name] = [metric_func(preds) if use_preds else metric_func(scores) \n",
    "                                for model_name, (preds, scores) in models_dict.items()]\n",
    "    return pd.DataFrame.from_dict(df_dict, orient=\"index\", columns=models_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd52eba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unmitigated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overall selection rate</th>\n",
       "      <td>0.307556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic parity difference</th>\n",
       "      <td>0.042246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic parity ratio</th>\n",
       "      <td>0.873298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>------</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall balanced error rate</th>\n",
       "      <td>0.305341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced error rate difference</th>\n",
       "      <td>0.009587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>------</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False positive rate difference</th>\n",
       "      <td>0.032934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False negative rate difference</th>\n",
       "      <td>0.013759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalized odds difference</th>\n",
       "      <td>0.032934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>------</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall AUC</th>\n",
       "      <td>0.75646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC difference</th>\n",
       "      <td>0.002612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Unmitigated\n",
       "Overall selection rate            0.307556\n",
       "Demographic parity difference     0.042246\n",
       "Demographic parity ratio          0.873298\n",
       "------                                    \n",
       "Overall balanced error rate       0.305341\n",
       "Balanced error rate difference    0.009587\n",
       " ------                                   \n",
       "False positive rate difference    0.032934\n",
       "False negative rate difference    0.013759\n",
       "Equalized odds difference         0.032934\n",
       "  ------                                  \n",
       "Overall AUC                        0.75646\n",
       "AUC difference                    0.002612"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrics\n",
    "models_dict = {\"Unmitigated\": (test_preds, test_scores)}\n",
    "get_metrics_df(models_dict, Y_test, A_str_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761d60ae",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"section3\"></a>\n",
    "\n",
    "# SECTION 3: Use a split-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b192f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simple_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " cls1a (Dense)                  (None, 64)           1472        ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " cls2a (Dense)                  (None, 64)           1472        ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout1a (Dropout)            (None, 64)           0           ['cls1a[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout2a (Dropout)            (None, 64)           0           ['cls2a[0][0]']                  \n",
      "                                                                                                  \n",
      " cls1b (Dense)                  (None, 32)           2080        ['dropout1a[0][0]']              \n",
      "                                                                                                  \n",
      " cls2b (Dense)                  (None, 32)           2080        ['dropout2a[0][0]']              \n",
      "                                                                                                  \n",
      " dropout1b (Dropout)            (None, 32)           0           ['cls1b[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout2b (Dropout)            (None, 32)           0           ['cls2b[0][0]']                  \n",
      "                                                                                                  \n",
      " cls1c (Dense)                  (None, 16)           528         ['dropout1b[0][0]']              \n",
      "                                                                                                  \n",
      " cls2c (Dense)                  (None, 16)           528         ['dropout2b[0][0]']              \n",
      "                                                                                                  \n",
      " output1 (Dense)                (None, 1)            17          ['cls1c[0][0]']                  \n",
      "                                                                                                  \n",
      " output2 (Dense)                (None, 1)            17          ['cls2c[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,194\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(22,), name='inputs')\n",
    "\n",
    "cls1a = Dense(64, name='cls1a', kernel_regularizer=regularizers.L1(1e-5), activation='relu')(inputs)\n",
    "dropout1a = Dropout(0.1, name='dropout1a')(cls1a)\n",
    "cls1b = Dense(32, name='cls1b', kernel_regularizer=regularizers.L1(1e-5), activation='relu')(dropout1a)\n",
    "dropout1b = Dropout(0.1, name='dropout1b')(cls1b)\n",
    "cls1c = Dense(16, name='cls1c', kernel_regularizer=regularizers.L1(1e-5), activation='relu')(dropout1b)\n",
    "output1 = Dense(1, name='output1', activation='sigmoid')(cls1c)\n",
    "\n",
    "cls2a = Dense(64, name='cls2a', kernel_regularizer=regularizers.L1(1e-5), activation='relu')(inputs)\n",
    "dropout2a = Dropout(0.1, name='dropout2a')(cls2a)\n",
    "cls2b = Dense(32, name='cls2b', kernel_regularizer=regularizers.L1(1e-5), activation='relu')(dropout2a)\n",
    "dropout2b = Dropout(0.1, name='dropout2b')(cls2b)\n",
    "cls2c = Dense(16, name='cls2c', kernel_regularizer=regularizers.L1(1e-5), activation='relu')(dropout2b)\n",
    "output2 = Dense(1, name='output2', activation='sigmoid')(cls2c)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=[output1, output2], name=\"simple_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cdd15d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthogonal_loss(y_true, y_pred):\n",
    "    # requires cls1, cls2 layers to be defined through functional API\n",
    "    _cls1 = cls1a\n",
    "    _cls2 = cls2a\n",
    "    cls1_cls2 = tf.linalg.matmul(_cls1, _cls2, transpose_b=True)\n",
    "    numerator = tf.norm(cls1_cls2, ord=1)\n",
    "    cls1_norm = tf.norm(_cls1, ord=2)\n",
    "    cls2_norm = tf.norm(_cls2, ord=2)\n",
    "    denominator = tf.math.multiply(cls1_norm, cls2_norm)\n",
    "    loss_ortho = tf.math.divide_no_nan(numerator, denominator)\n",
    "    \n",
    "    loss_categorical = keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    return loss_categorical + loss_ortho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "215425ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16800 samples, validate on 4200 samples\n",
      "Epoch 1/250\n",
      "16768/16800 [============================>.] - ETA: 0s - loss: 10.3647 - output1_loss: 5.1059 - output2_loss: 5.2486 - output1_accuracy: 0.7773 - output1_mean_absolute_error: 0.3620 - output2_accuracy: 0.5943 - output2_mean_absolute_error: 0.4818"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netwo\\anaconda3\\envs\\Thesis-minimum\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16800/16800 [==============================] - 5s 273us/sample - loss: 10.3480 - output1_loss: 5.0891 - output2_loss: 5.2320 - output1_accuracy: 0.7774 - output1_mean_absolute_error: 0.3620 - output2_accuracy: 0.5943 - output2_mean_absolute_error: 0.4818 - val_loss: 2.1961 - val_output1_loss: 0.9961 - val_output2_loss: 1.1865 - val_output1_accuracy: 0.8000 - val_output1_mean_absolute_error: 0.3238 - val_output2_accuracy: 0.5952 - val_output2_mean_absolute_error: 0.4794\n",
      "Epoch 2/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.5210 - output1_loss: 0.6604 - output2_loss: 0.8503 - output1_accuracy: 0.7987 - output1_mean_absolute_error: 0.3116 - output2_accuracy: 0.5999 - output2_mean_absolute_error: 0.4772 - val_loss: 1.2559 - val_output1_loss: 0.5203 - val_output2_loss: 0.7267 - val_output1_accuracy: 0.8033 - val_output1_mean_absolute_error: 0.3024 - val_output2_accuracy: 0.5948 - val_output2_mean_absolute_error: 0.4789\n",
      "Epoch 3/250\n",
      "16800/16800 [==============================] - 4s 249us/sample - loss: 1.2081 - output1_loss: 0.4984 - output2_loss: 0.7005 - output1_accuracy: 0.8044 - output1_mean_absolute_error: 0.2970 - output2_accuracy: 0.6002 - output2_mean_absolute_error: 0.4766 - val_loss: 1.1765 - val_output1_loss: 0.4760 - val_output2_loss: 0.6915 - val_output1_accuracy: 0.8043 - val_output1_mean_absolute_error: 0.2904 - val_output2_accuracy: 0.5938 - val_output2_mean_absolute_error: 0.4788\n",
      "Epoch 4/250\n",
      "16800/16800 [==============================] - 4s 246us/sample - loss: 1.1618 - output1_loss: 0.4724 - output2_loss: 0.6804 - output1_accuracy: 0.8066 - output1_mean_absolute_error: 0.2915 - output2_accuracy: 0.6018 - output2_mean_absolute_error: 0.4764 - val_loss: 1.1505 - val_output1_loss: 0.4623 - val_output2_loss: 0.6790 - val_output1_accuracy: 0.8081 - val_output1_mean_absolute_error: 0.2982 - val_output2_accuracy: 0.5948 - val_output2_mean_absolute_error: 0.4772\n",
      "Epoch 5/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.1410 - output1_loss: 0.4582 - output2_loss: 0.6738 - output1_accuracy: 0.8108 - output1_mean_absolute_error: 0.2859 - output2_accuracy: 0.6009 - output2_mean_absolute_error: 0.4761 - val_loss: 1.1401 - val_output1_loss: 0.4546 - val_output2_loss: 0.6773 - val_output1_accuracy: 0.8100 - val_output1_mean_absolute_error: 0.2859 - val_output2_accuracy: 0.5964 - val_output2_mean_absolute_error: 0.4725\n",
      "Epoch 6/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.1339 - output1_loss: 0.4544 - output2_loss: 0.6704 - output1_accuracy: 0.8106 - output1_mean_absolute_error: 0.2849 - output2_accuracy: 0.6026 - output2_mean_absolute_error: 0.4745 - val_loss: 1.1319 - val_output1_loss: 0.4505 - val_output2_loss: 0.6725 - val_output1_accuracy: 0.8131 - val_output1_mean_absolute_error: 0.2813 - val_output2_accuracy: 0.5974 - val_output2_mean_absolute_error: 0.4776\n",
      "Epoch 7/250\n",
      "16800/16800 [==============================] - 4s 251us/sample - loss: 1.1284 - output1_loss: 0.4511 - output2_loss: 0.6689 - output1_accuracy: 0.8126 - output1_mean_absolute_error: 0.2834 - output2_accuracy: 0.6020 - output2_mean_absolute_error: 0.4749 - val_loss: 1.1283 - val_output1_loss: 0.4491 - val_output2_loss: 0.6706 - val_output1_accuracy: 0.8138 - val_output1_mean_absolute_error: 0.2748 - val_output2_accuracy: 0.5936 - val_output2_mean_absolute_error: 0.4714\n",
      "Epoch 8/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.1227 - output1_loss: 0.4478 - output2_loss: 0.6665 - output1_accuracy: 0.8126 - output1_mean_absolute_error: 0.2816 - output2_accuracy: 0.6029 - output2_mean_absolute_error: 0.4733 - val_loss: 1.1238 - val_output1_loss: 0.4462 - val_output2_loss: 0.6687 - val_output1_accuracy: 0.8126 - val_output1_mean_absolute_error: 0.2810 - val_output2_accuracy: 0.5952 - val_output2_mean_absolute_error: 0.4729\n",
      "Epoch 9/250\n",
      "16800/16800 [==============================] - 4s 247us/sample - loss: 1.1167 - output1_loss: 0.4438 - output2_loss: 0.6646 - output1_accuracy: 0.8141 - output1_mean_absolute_error: 0.2803 - output2_accuracy: 0.6042 - output2_mean_absolute_error: 0.4716 - val_loss: 1.1226 - val_output1_loss: 0.4495 - val_output2_loss: 0.6653 - val_output1_accuracy: 0.8124 - val_output1_mean_absolute_error: 0.2686 - val_output2_accuracy: 0.5964 - val_output2_mean_absolute_error: 0.4708\n",
      "Epoch 10/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.1149 - output1_loss: 0.4439 - output2_loss: 0.6627 - output1_accuracy: 0.8158 - output1_mean_absolute_error: 0.2794 - output2_accuracy: 0.6095 - output2_mean_absolute_error: 0.4699 - val_loss: 1.1126 - val_output1_loss: 0.4438 - val_output2_loss: 0.6614 - val_output1_accuracy: 0.8140 - val_output1_mean_absolute_error: 0.2785 - val_output2_accuracy: 0.6012 - val_output2_mean_absolute_error: 0.4710\n",
      "Epoch 11/250\n",
      "16800/16800 [==============================] - 4s 248us/sample - loss: 1.1125 - output1_loss: 0.4432 - output2_loss: 0.6614 - output1_accuracy: 0.8153 - output1_mean_absolute_error: 0.2786 - output2_accuracy: 0.6078 - output2_mean_absolute_error: 0.4689 - val_loss: 1.1113 - val_output1_loss: 0.4447 - val_output2_loss: 0.6603 - val_output1_accuracy: 0.8133 - val_output1_mean_absolute_error: 0.2851 - val_output2_accuracy: 0.6050 - val_output2_mean_absolute_error: 0.4699\n",
      "Epoch 12/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.1076 - output1_loss: 0.4409 - output2_loss: 0.6588 - output1_accuracy: 0.8162 - output1_mean_absolute_error: 0.2779 - output2_accuracy: 0.6107 - output2_mean_absolute_error: 0.4666 - val_loss: 1.1092 - val_output1_loss: 0.4431 - val_output2_loss: 0.6586 - val_output1_accuracy: 0.8131 - val_output1_mean_absolute_error: 0.2820 - val_output2_accuracy: 0.6043 - val_output2_mean_absolute_error: 0.4648\n",
      "Epoch 13/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.1046 - output1_loss: 0.4399 - output2_loss: 0.6573 - output1_accuracy: 0.8155 - output1_mean_absolute_error: 0.2766 - output2_accuracy: 0.6120 - output2_mean_absolute_error: 0.4656 - val_loss: 1.1092 - val_output1_loss: 0.4437 - val_output2_loss: 0.6574 - val_output1_accuracy: 0.8148 - val_output1_mean_absolute_error: 0.2795 - val_output2_accuracy: 0.6062 - val_output2_mean_absolute_error: 0.4619\n",
      "Epoch 14/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.1006 - output1_loss: 0.4375 - output2_loss: 0.6558 - output1_accuracy: 0.8165 - output1_mean_absolute_error: 0.2749 - output2_accuracy: 0.6100 - output2_mean_absolute_error: 0.4639 - val_loss: 1.1046 - val_output1_loss: 0.4412 - val_output2_loss: 0.6567 - val_output1_accuracy: 0.8136 - val_output1_mean_absolute_error: 0.2758 - val_output2_accuracy: 0.6093 - val_output2_mean_absolute_error: 0.4604\n",
      "Epoch 15/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0984 - output1_loss: 0.4364 - output2_loss: 0.6546 - output1_accuracy: 0.8160 - output1_mean_absolute_error: 0.2762 - output2_accuracy: 0.6146 - output2_mean_absolute_error: 0.4625 - val_loss: 1.1096 - val_output1_loss: 0.4485 - val_output2_loss: 0.6536 - val_output1_accuracy: 0.8150 - val_output1_mean_absolute_error: 0.2649 - val_output2_accuracy: 0.6110 - val_output2_mean_absolute_error: 0.4617\n",
      "Epoch 16/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0951 - output1_loss: 0.4363 - output2_loss: 0.6517 - output1_accuracy: 0.8186 - output1_mean_absolute_error: 0.2734 - output2_accuracy: 0.6186 - output2_mean_absolute_error: 0.4608 - val_loss: 1.1027 - val_output1_loss: 0.4425 - val_output2_loss: 0.6526 - val_output1_accuracy: 0.8162 - val_output1_mean_absolute_error: 0.2714 - val_output2_accuracy: 0.6202 - val_output2_mean_absolute_error: 0.4599\n",
      "Epoch 17/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0932 - output1_loss: 0.4350 - output2_loss: 0.6510 - output1_accuracy: 0.8188 - output1_mean_absolute_error: 0.2732 - output2_accuracy: 0.6210 - output2_mean_absolute_error: 0.4593 - val_loss: 1.1007 - val_output1_loss: 0.4429 - val_output2_loss: 0.6509 - val_output1_accuracy: 0.8162 - val_output1_mean_absolute_error: 0.2698 - val_output2_accuracy: 0.6193 - val_output2_mean_absolute_error: 0.4616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0889 - output1_loss: 0.4326 - output2_loss: 0.6494 - output1_accuracy: 0.8188 - output1_mean_absolute_error: 0.2722 - output2_accuracy: 0.6232 - output2_mean_absolute_error: 0.4583 - val_loss: 1.0971 - val_output1_loss: 0.4389 - val_output2_loss: 0.6503 - val_output1_accuracy: 0.8160 - val_output1_mean_absolute_error: 0.2704 - val_output2_accuracy: 0.6202 - val_output2_mean_absolute_error: 0.4572\n",
      "Epoch 19/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0883 - output1_loss: 0.4329 - output2_loss: 0.6485 - output1_accuracy: 0.8173 - output1_mean_absolute_error: 0.2717 - output2_accuracy: 0.6256 - output2_mean_absolute_error: 0.4571 - val_loss: 1.0951 - val_output1_loss: 0.4393 - val_output2_loss: 0.6493 - val_output1_accuracy: 0.8167 - val_output1_mean_absolute_error: 0.2755 - val_output2_accuracy: 0.6238 - val_output2_mean_absolute_error: 0.4568\n",
      "Epoch 20/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0853 - output1_loss: 0.4326 - output2_loss: 0.6459 - output1_accuracy: 0.8201 - output1_mean_absolute_error: 0.2728 - output2_accuracy: 0.6288 - output2_mean_absolute_error: 0.4542 - val_loss: 1.0928 - val_output1_loss: 0.4388 - val_output2_loss: 0.6474 - val_output1_accuracy: 0.8150 - val_output1_mean_absolute_error: 0.2781 - val_output2_accuracy: 0.6240 - val_output2_mean_absolute_error: 0.4587\n",
      "Epoch 21/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0819 - output1_loss: 0.4295 - output2_loss: 0.6459 - output1_accuracy: 0.8180 - output1_mean_absolute_error: 0.2698 - output2_accuracy: 0.6323 - output2_mean_absolute_error: 0.4548 - val_loss: 1.0919 - val_output1_loss: 0.4398 - val_output2_loss: 0.6460 - val_output1_accuracy: 0.8126 - val_output1_mean_absolute_error: 0.2822 - val_output2_accuracy: 0.6274 - val_output2_mean_absolute_error: 0.4564\n",
      "Epoch 22/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0824 - output1_loss: 0.4311 - output2_loss: 0.6444 - output1_accuracy: 0.8181 - output1_mean_absolute_error: 0.2714 - output2_accuracy: 0.6318 - output2_mean_absolute_error: 0.4531 - val_loss: 1.0942 - val_output1_loss: 0.4406 - val_output2_loss: 0.6461 - val_output1_accuracy: 0.8162 - val_output1_mean_absolute_error: 0.2692 - val_output2_accuracy: 0.6221 - val_output2_mean_absolute_error: 0.4553\n",
      "Epoch 23/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0798 - output1_loss: 0.4303 - output2_loss: 0.6429 - output1_accuracy: 0.8196 - output1_mean_absolute_error: 0.2707 - output2_accuracy: 0.6327 - output2_mean_absolute_error: 0.4517 - val_loss: 1.0904 - val_output1_loss: 0.4386 - val_output2_loss: 0.6453 - val_output1_accuracy: 0.8162 - val_output1_mean_absolute_error: 0.2702 - val_output2_accuracy: 0.6255 - val_output2_mean_absolute_error: 0.4566\n",
      "Epoch 24/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0790 - output1_loss: 0.4296 - output2_loss: 0.6427 - output1_accuracy: 0.8201 - output1_mean_absolute_error: 0.2696 - output2_accuracy: 0.6307 - output2_mean_absolute_error: 0.4516 - val_loss: 1.0900 - val_output1_loss: 0.4387 - val_output2_loss: 0.6452 - val_output1_accuracy: 0.8143 - val_output1_mean_absolute_error: 0.2817 - val_output2_accuracy: 0.6250 - val_output2_mean_absolute_error: 0.4542\n",
      "Epoch 25/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0770 - output1_loss: 0.4280 - output2_loss: 0.6425 - output1_accuracy: 0.8194 - output1_mean_absolute_error: 0.2699 - output2_accuracy: 0.6329 - output2_mean_absolute_error: 0.4516 - val_loss: 1.0906 - val_output1_loss: 0.4397 - val_output2_loss: 0.6449 - val_output1_accuracy: 0.8152 - val_output1_mean_absolute_error: 0.2699 - val_output2_accuracy: 0.6257 - val_output2_mean_absolute_error: 0.4522\n",
      "Epoch 26/250\n",
      "16800/16800 [==============================] - 4s 246us/sample - loss: 1.0770 - output1_loss: 0.4290 - output2_loss: 0.6418 - output1_accuracy: 0.8208 - output1_mean_absolute_error: 0.2703 - output2_accuracy: 0.6323 - output2_mean_absolute_error: 0.4508 - val_loss: 1.0922 - val_output1_loss: 0.4395 - val_output2_loss: 0.6454 - val_output1_accuracy: 0.8150 - val_output1_mean_absolute_error: 0.2620 - val_output2_accuracy: 0.6255 - val_output2_mean_absolute_error: 0.4530\n",
      "Epoch 27/250\n",
      "16800/16800 [==============================] - 4s 246us/sample - loss: 1.0744 - output1_loss: 0.4273 - output2_loss: 0.6406 - output1_accuracy: 0.8180 - output1_mean_absolute_error: 0.2678 - output2_accuracy: 0.6349 - output2_mean_absolute_error: 0.4501 - val_loss: 1.0911 - val_output1_loss: 0.4390 - val_output2_loss: 0.6452 - val_output1_accuracy: 0.8110 - val_output1_mean_absolute_error: 0.2800 - val_output2_accuracy: 0.6240 - val_output2_mean_absolute_error: 0.4516\n",
      "Epoch 28/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0719 - output1_loss: 0.4256 - output2_loss: 0.6398 - output1_accuracy: 0.8220 - output1_mean_absolute_error: 0.2686 - output2_accuracy: 0.6361 - output2_mean_absolute_error: 0.4495 - val_loss: 1.0880 - val_output1_loss: 0.4372 - val_output2_loss: 0.6442 - val_output1_accuracy: 0.8145 - val_output1_mean_absolute_error: 0.2742 - val_output2_accuracy: 0.6252 - val_output2_mean_absolute_error: 0.4517\n",
      "Epoch 29/250\n",
      "16800/16800 [==============================] - 4s 251us/sample - loss: 1.0718 - output1_loss: 0.4263 - output2_loss: 0.6391 - output1_accuracy: 0.8196 - output1_mean_absolute_error: 0.2685 - output2_accuracy: 0.6358 - output2_mean_absolute_error: 0.4484 - val_loss: 1.0907 - val_output1_loss: 0.4389 - val_output2_loss: 0.6450 - val_output1_accuracy: 0.8110 - val_output1_mean_absolute_error: 0.2796 - val_output2_accuracy: 0.6221 - val_output2_mean_absolute_error: 0.4488\n",
      "Epoch 30/250\n",
      "16800/16800 [==============================] - 4s 258us/sample - loss: 1.0706 - output1_loss: 0.4252 - output2_loss: 0.6389 - output1_accuracy: 0.8196 - output1_mean_absolute_error: 0.2678 - output2_accuracy: 0.6380 - output2_mean_absolute_error: 0.4482 - val_loss: 1.0926 - val_output1_loss: 0.4415 - val_output2_loss: 0.6455 - val_output1_accuracy: 0.8152 - val_output1_mean_absolute_error: 0.2647 - val_output2_accuracy: 0.6245 - val_output2_mean_absolute_error: 0.4500\n",
      "Epoch 31/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0703 - output1_loss: 0.4251 - output2_loss: 0.6381 - output1_accuracy: 0.8212 - output1_mean_absolute_error: 0.2678 - output2_accuracy: 0.6364 - output2_mean_absolute_error: 0.4482 - val_loss: 1.0897 - val_output1_loss: 0.4388 - val_output2_loss: 0.6448 - val_output1_accuracy: 0.8133 - val_output1_mean_absolute_error: 0.2742 - val_output2_accuracy: 0.6290 - val_output2_mean_absolute_error: 0.4475\n",
      "Epoch 32/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0703 - output1_loss: 0.4263 - output2_loss: 0.6377 - output1_accuracy: 0.8208 - output1_mean_absolute_error: 0.2669 - output2_accuracy: 0.6374 - output2_mean_absolute_error: 0.4471 - val_loss: 1.0885 - val_output1_loss: 0.4390 - val_output2_loss: 0.6426 - val_output1_accuracy: 0.8152 - val_output1_mean_absolute_error: 0.2703 - val_output2_accuracy: 0.6283 - val_output2_mean_absolute_error: 0.4489\n",
      "Epoch 33/250\n",
      "16800/16800 [==============================] - 4s 246us/sample - loss: 1.0690 - output1_loss: 0.4250 - output2_loss: 0.6378 - output1_accuracy: 0.8199 - output1_mean_absolute_error: 0.2687 - output2_accuracy: 0.6333 - output2_mean_absolute_error: 0.4469 - val_loss: 1.0894 - val_output1_loss: 0.4390 - val_output2_loss: 0.6438 - val_output1_accuracy: 0.8133 - val_output1_mean_absolute_error: 0.2681 - val_output2_accuracy: 0.6279 - val_output2_mean_absolute_error: 0.4521\n",
      "Epoch 34/250\n",
      "16800/16800 [==============================] - 4s 251us/sample - loss: 1.0669 - output1_loss: 0.4238 - output2_loss: 0.6367 - output1_accuracy: 0.8204 - output1_mean_absolute_error: 0.2664 - output2_accuracy: 0.6396 - output2_mean_absolute_error: 0.4467 - val_loss: 1.0920 - val_output1_loss: 0.4413 - val_output2_loss: 0.6442 - val_output1_accuracy: 0.8129 - val_output1_mean_absolute_error: 0.2670 - val_output2_accuracy: 0.6274 - val_output2_mean_absolute_error: 0.4491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/250\n",
      "16800/16800 [==============================] - 4s 246us/sample - loss: 1.0657 - output1_loss: 0.4230 - output2_loss: 0.6359 - output1_accuracy: 0.8207 - output1_mean_absolute_error: 0.2664 - output2_accuracy: 0.6364 - output2_mean_absolute_error: 0.4460 - val_loss: 1.0908 - val_output1_loss: 0.4400 - val_output2_loss: 0.6445 - val_output1_accuracy: 0.8107 - val_output1_mean_absolute_error: 0.2801 - val_output2_accuracy: 0.6300 - val_output2_mean_absolute_error: 0.4504\n",
      "Epoch 36/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0656 - output1_loss: 0.4226 - output2_loss: 0.6360 - output1_accuracy: 0.8206 - output1_mean_absolute_error: 0.2661 - output2_accuracy: 0.6407 - output2_mean_absolute_error: 0.4458 - val_loss: 1.0932 - val_output1_loss: 0.4389 - val_output2_loss: 0.6472 - val_output1_accuracy: 0.8133 - val_output1_mean_absolute_error: 0.2688 - val_output2_accuracy: 0.6248 - val_output2_mean_absolute_error: 0.4439\n",
      "Epoch 37/250\n",
      "16800/16800 [==============================] - 4s 245us/sample - loss: 1.0635 - output1_loss: 0.4221 - output2_loss: 0.6350 - output1_accuracy: 0.8210 - output1_mean_absolute_error: 0.2649 - output2_accuracy: 0.6410 - output2_mean_absolute_error: 0.4443 - val_loss: 1.0880 - val_output1_loss: 0.4381 - val_output2_loss: 0.6430 - val_output1_accuracy: 0.8126 - val_output1_mean_absolute_error: 0.2671 - val_output2_accuracy: 0.6295 - val_output2_mean_absolute_error: 0.4491\n",
      "Epoch 38/250\n",
      "16800/16800 [==============================] - 4s 252us/sample - loss: 1.0626 - output1_loss: 0.4213 - output2_loss: 0.6346 - output1_accuracy: 0.8233 - output1_mean_absolute_error: 0.2653 - output2_accuracy: 0.6408 - output2_mean_absolute_error: 0.4453 - val_loss: 1.0935 - val_output1_loss: 0.4383 - val_output2_loss: 0.6474 - val_output1_accuracy: 0.8148 - val_output1_mean_absolute_error: 0.2673 - val_output2_accuracy: 0.6257 - val_output2_mean_absolute_error: 0.4443\n",
      "Epoch 39/250\n",
      "16800/16800 [==============================] - 4s 240us/sample - loss: 1.0612 - output1_loss: 0.4215 - output2_loss: 0.6328 - output1_accuracy: 0.8217 - output1_mean_absolute_error: 0.2643 - output2_accuracy: 0.6446 - output2_mean_absolute_error: 0.4434 - val_loss: 1.0947 - val_output1_loss: 0.4387 - val_output2_loss: 0.6480 - val_output1_accuracy: 0.8143 - val_output1_mean_absolute_error: 0.2690 - val_output2_accuracy: 0.6233 - val_output2_mean_absolute_error: 0.4447\n",
      "Epoch 40/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0603 - output1_loss: 0.4206 - output2_loss: 0.6331 - output1_accuracy: 0.8212 - output1_mean_absolute_error: 0.2645 - output2_accuracy: 0.6436 - output2_mean_absolute_error: 0.4428 - val_loss: 1.0888 - val_output1_loss: 0.4383 - val_output2_loss: 0.6440 - val_output1_accuracy: 0.8138 - val_output1_mean_absolute_error: 0.2745 - val_output2_accuracy: 0.6310 - val_output2_mean_absolute_error: 0.4502\n",
      "Epoch 41/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0599 - output1_loss: 0.4216 - output2_loss: 0.6316 - output1_accuracy: 0.8212 - output1_mean_absolute_error: 0.2656 - output2_accuracy: 0.6468 - output2_mean_absolute_error: 0.4421 - val_loss: 1.0884 - val_output1_loss: 0.4383 - val_output2_loss: 0.6434 - val_output1_accuracy: 0.8126 - val_output1_mean_absolute_error: 0.2684 - val_output2_accuracy: 0.6279 - val_output2_mean_absolute_error: 0.4482\n",
      "Epoch 42/250\n",
      "16800/16800 [==============================] - 4s 249us/sample - loss: 1.0611 - output1_loss: 0.4213 - output2_loss: 0.6332 - output1_accuracy: 0.8204 - output1_mean_absolute_error: 0.2640 - output2_accuracy: 0.6391 - output2_mean_absolute_error: 0.4439 - val_loss: 1.0892 - val_output1_loss: 0.4400 - val_output2_loss: 0.6427 - val_output1_accuracy: 0.8148 - val_output1_mean_absolute_error: 0.2767 - val_output2_accuracy: 0.6260 - val_output2_mean_absolute_error: 0.4475\n",
      "Epoch 43/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0585 - output1_loss: 0.4201 - output2_loss: 0.6317 - output1_accuracy: 0.8210 - output1_mean_absolute_error: 0.2658 - output2_accuracy: 0.6461 - output2_mean_absolute_error: 0.4414 - val_loss: 1.0913 - val_output1_loss: 0.4394 - val_output2_loss: 0.6448 - val_output1_accuracy: 0.8138 - val_output1_mean_absolute_error: 0.2649 - val_output2_accuracy: 0.6295 - val_output2_mean_absolute_error: 0.4465\n",
      "Epoch 44/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0585 - output1_loss: 0.4207 - output2_loss: 0.6310 - output1_accuracy: 0.8225 - output1_mean_absolute_error: 0.2659 - output2_accuracy: 0.6436 - output2_mean_absolute_error: 0.4419 - val_loss: 1.0898 - val_output1_loss: 0.4389 - val_output2_loss: 0.6438 - val_output1_accuracy: 0.8150 - val_output1_mean_absolute_error: 0.2647 - val_output2_accuracy: 0.6302 - val_output2_mean_absolute_error: 0.4462\n",
      "Epoch 45/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0584 - output1_loss: 0.4201 - output2_loss: 0.6318 - output1_accuracy: 0.8205 - output1_mean_absolute_error: 0.2635 - output2_accuracy: 0.6414 - output2_mean_absolute_error: 0.4415 - val_loss: 1.0889 - val_output1_loss: 0.4379 - val_output2_loss: 0.6436 - val_output1_accuracy: 0.8124 - val_output1_mean_absolute_error: 0.2729 - val_output2_accuracy: 0.6329 - val_output2_mean_absolute_error: 0.4493\n",
      "Epoch 46/250\n",
      "16800/16800 [==============================] - 4s 251us/sample - loss: 1.0564 - output1_loss: 0.4193 - output2_loss: 0.6307 - output1_accuracy: 0.8208 - output1_mean_absolute_error: 0.2640 - output2_accuracy: 0.6428 - output2_mean_absolute_error: 0.4420 - val_loss: 1.0912 - val_output1_loss: 0.4399 - val_output2_loss: 0.6446 - val_output1_accuracy: 0.8119 - val_output1_mean_absolute_error: 0.2673 - val_output2_accuracy: 0.6310 - val_output2_mean_absolute_error: 0.4452\n",
      "Epoch 47/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0566 - output1_loss: 0.4191 - output2_loss: 0.6306 - output1_accuracy: 0.8201 - output1_mean_absolute_error: 0.2635 - output2_accuracy: 0.6435 - output2_mean_absolute_error: 0.4408 - val_loss: 1.0886 - val_output1_loss: 0.4380 - val_output2_loss: 0.6447 - val_output1_accuracy: 0.8157 - val_output1_mean_absolute_error: 0.2720 - val_output2_accuracy: 0.6293 - val_output2_mean_absolute_error: 0.4462\n",
      "Epoch 48/250\n",
      "16800/16800 [==============================] - 4s 245us/sample - loss: 1.0560 - output1_loss: 0.4206 - output2_loss: 0.6291 - output1_accuracy: 0.8201 - output1_mean_absolute_error: 0.2637 - output2_accuracy: 0.6444 - output2_mean_absolute_error: 0.4397 - val_loss: 1.0881 - val_output1_loss: 0.4384 - val_output2_loss: 0.6433 - val_output1_accuracy: 0.8152 - val_output1_mean_absolute_error: 0.2717 - val_output2_accuracy: 0.6298 - val_output2_mean_absolute_error: 0.4485\n",
      "Epoch 49/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0554 - output1_loss: 0.4196 - output2_loss: 0.6294 - output1_accuracy: 0.8228 - output1_mean_absolute_error: 0.2635 - output2_accuracy: 0.6485 - output2_mean_absolute_error: 0.4400 - val_loss: 1.0901 - val_output1_loss: 0.4399 - val_output2_loss: 0.6430 - val_output1_accuracy: 0.8140 - val_output1_mean_absolute_error: 0.2788 - val_output2_accuracy: 0.6298 - val_output2_mean_absolute_error: 0.4458\n",
      "Epoch 50/250\n",
      "16800/16800 [==============================] - 4s 249us/sample - loss: 1.0539 - output1_loss: 0.4194 - output2_loss: 0.6278 - output1_accuracy: 0.8208 - output1_mean_absolute_error: 0.2643 - output2_accuracy: 0.6486 - output2_mean_absolute_error: 0.4388 - val_loss: 1.0920 - val_output1_loss: 0.4396 - val_output2_loss: 0.6453 - val_output1_accuracy: 0.8133 - val_output1_mean_absolute_error: 0.2715 - val_output2_accuracy: 0.6281 - val_output2_mean_absolute_error: 0.4470\n",
      "Epoch 51/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0536 - output1_loss: 0.4179 - output2_loss: 0.6290 - output1_accuracy: 0.8225 - output1_mean_absolute_error: 0.2624 - output2_accuracy: 0.6496 - output2_mean_absolute_error: 0.4394 - val_loss: 1.0884 - val_output1_loss: 0.4385 - val_output2_loss: 0.6428 - val_output1_accuracy: 0.8133 - val_output1_mean_absolute_error: 0.2709 - val_output2_accuracy: 0.6295 - val_output2_mean_absolute_error: 0.4492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0542 - output1_loss: 0.4196 - output2_loss: 0.6281 - output1_accuracy: 0.8215 - output1_mean_absolute_error: 0.2641 - output2_accuracy: 0.6470 - output2_mean_absolute_error: 0.4398 - val_loss: 1.0936 - val_output1_loss: 0.4419 - val_output2_loss: 0.6450 - val_output1_accuracy: 0.8136 - val_output1_mean_absolute_error: 0.2663 - val_output2_accuracy: 0.6267 - val_output2_mean_absolute_error: 0.4431\n",
      "Epoch 53/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0523 - output1_loss: 0.4176 - output2_loss: 0.6275 - output1_accuracy: 0.8202 - output1_mean_absolute_error: 0.2624 - output2_accuracy: 0.6465 - output2_mean_absolute_error: 0.4380 - val_loss: 1.0900 - val_output1_loss: 0.4367 - val_output2_loss: 0.6457 - val_output1_accuracy: 0.8136 - val_output1_mean_absolute_error: 0.2781 - val_output2_accuracy: 0.6288 - val_output2_mean_absolute_error: 0.4454\n",
      "Epoch 54/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0511 - output1_loss: 0.4175 - output2_loss: 0.6268 - output1_accuracy: 0.8215 - output1_mean_absolute_error: 0.2635 - output2_accuracy: 0.6477 - output2_mean_absolute_error: 0.4380 - val_loss: 1.0900 - val_output1_loss: 0.4389 - val_output2_loss: 0.6440 - val_output1_accuracy: 0.8136 - val_output1_mean_absolute_error: 0.2675 - val_output2_accuracy: 0.6302 - val_output2_mean_absolute_error: 0.4486\n",
      "Epoch 55/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0535 - output1_loss: 0.4189 - output2_loss: 0.6281 - output1_accuracy: 0.8217 - output1_mean_absolute_error: 0.2629 - output2_accuracy: 0.6440 - output2_mean_absolute_error: 0.4386 - val_loss: 1.0940 - val_output1_loss: 0.4395 - val_output2_loss: 0.6480 - val_output1_accuracy: 0.8095 - val_output1_mean_absolute_error: 0.2778 - val_output2_accuracy: 0.6276 - val_output2_mean_absolute_error: 0.4444\n",
      "Epoch 56/250\n",
      "16800/16800 [==============================] - 4s 239us/sample - loss: 1.0516 - output1_loss: 0.4168 - output2_loss: 0.6279 - output1_accuracy: 0.8217 - output1_mean_absolute_error: 0.2631 - output2_accuracy: 0.6471 - output2_mean_absolute_error: 0.4390 - val_loss: 1.0915 - val_output1_loss: 0.4402 - val_output2_loss: 0.6448 - val_output1_accuracy: 0.8140 - val_output1_mean_absolute_error: 0.2647 - val_output2_accuracy: 0.6319 - val_output2_mean_absolute_error: 0.4445\n",
      "Epoch 57/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0513 - output1_loss: 0.4169 - output2_loss: 0.6276 - output1_accuracy: 0.8221 - output1_mean_absolute_error: 0.2623 - output2_accuracy: 0.6515 - output2_mean_absolute_error: 0.4379 - val_loss: 1.0926 - val_output1_loss: 0.4401 - val_output2_loss: 0.6463 - val_output1_accuracy: 0.8148 - val_output1_mean_absolute_error: 0.2649 - val_output2_accuracy: 0.6326 - val_output2_mean_absolute_error: 0.4489\n",
      "Epoch 58/250\n",
      "16800/16800 [==============================] - 4s 252us/sample - loss: 1.0516 - output1_loss: 0.4170 - output2_loss: 0.6277 - output1_accuracy: 0.8235 - output1_mean_absolute_error: 0.2610 - output2_accuracy: 0.6510 - output2_mean_absolute_error: 0.4387 - val_loss: 1.0942 - val_output1_loss: 0.4411 - val_output2_loss: 0.6459 - val_output1_accuracy: 0.8117 - val_output1_mean_absolute_error: 0.2705 - val_output2_accuracy: 0.6314 - val_output2_mean_absolute_error: 0.4469\n",
      "Epoch 59/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0499 - output1_loss: 0.4163 - output2_loss: 0.6266 - output1_accuracy: 0.8226 - output1_mean_absolute_error: 0.2620 - output2_accuracy: 0.6500 - output2_mean_absolute_error: 0.4373 - val_loss: 1.0941 - val_output1_loss: 0.4421 - val_output2_loss: 0.6447 - val_output1_accuracy: 0.8129 - val_output1_mean_absolute_error: 0.2649 - val_output2_accuracy: 0.6319 - val_output2_mean_absolute_error: 0.4460\n",
      "Epoch 60/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0471 - output1_loss: 0.4157 - output2_loss: 0.6245 - output1_accuracy: 0.8229 - output1_mean_absolute_error: 0.2614 - output2_accuracy: 0.6496 - output2_mean_absolute_error: 0.4360 - val_loss: 1.0938 - val_output1_loss: 0.4419 - val_output2_loss: 0.6448 - val_output1_accuracy: 0.8140 - val_output1_mean_absolute_error: 0.2648 - val_output2_accuracy: 0.6317 - val_output2_mean_absolute_error: 0.4503\n",
      "Epoch 61/250\n",
      "16800/16800 [==============================] - 4s 245us/sample - loss: 1.0510 - output1_loss: 0.4166 - output2_loss: 0.6274 - output1_accuracy: 0.8242 - output1_mean_absolute_error: 0.2618 - output2_accuracy: 0.6486 - output2_mean_absolute_error: 0.4383 - val_loss: 1.0991 - val_output1_loss: 0.4432 - val_output2_loss: 0.6499 - val_output1_accuracy: 0.8136 - val_output1_mean_absolute_error: 0.2587 - val_output2_accuracy: 0.6255 - val_output2_mean_absolute_error: 0.4454\n",
      "Epoch 62/250\n",
      "16800/16800 [==============================] - 4s 249us/sample - loss: 1.0481 - output1_loss: 0.4147 - output2_loss: 0.6264 - output1_accuracy: 0.8235 - output1_mean_absolute_error: 0.2610 - output2_accuracy: 0.6504 - output2_mean_absolute_error: 0.4378 - val_loss: 1.0928 - val_output1_loss: 0.4413 - val_output2_loss: 0.6440 - val_output1_accuracy: 0.8131 - val_output1_mean_absolute_error: 0.2694 - val_output2_accuracy: 0.6340 - val_output2_mean_absolute_error: 0.4480\n",
      "Epoch 63/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0486 - output1_loss: 0.4159 - output2_loss: 0.6256 - output1_accuracy: 0.8230 - output1_mean_absolute_error: 0.2617 - output2_accuracy: 0.6495 - output2_mean_absolute_error: 0.4366 - val_loss: 1.0929 - val_output1_loss: 0.4412 - val_output2_loss: 0.6453 - val_output1_accuracy: 0.8138 - val_output1_mean_absolute_error: 0.2695 - val_output2_accuracy: 0.6355 - val_output2_mean_absolute_error: 0.4463\n",
      "Epoch 64/250\n",
      "16800/16800 [==============================] - 4s 240us/sample - loss: 1.0460 - output1_loss: 0.4149 - output2_loss: 0.6241 - output1_accuracy: 0.8227 - output1_mean_absolute_error: 0.2615 - output2_accuracy: 0.6510 - output2_mean_absolute_error: 0.4350 - val_loss: 1.0962 - val_output1_loss: 0.4437 - val_output2_loss: 0.6456 - val_output1_accuracy: 0.8124 - val_output1_mean_absolute_error: 0.2627 - val_output2_accuracy: 0.6371 - val_output2_mean_absolute_error: 0.4461\n",
      "Epoch 65/250\n",
      "16800/16800 [==============================] - 4s 249us/sample - loss: 1.0480 - output1_loss: 0.4156 - output2_loss: 0.6258 - output1_accuracy: 0.8245 - output1_mean_absolute_error: 0.2614 - output2_accuracy: 0.6519 - output2_mean_absolute_error: 0.4367 - val_loss: 1.0943 - val_output1_loss: 0.4413 - val_output2_loss: 0.6463 - val_output1_accuracy: 0.8138 - val_output1_mean_absolute_error: 0.2658 - val_output2_accuracy: 0.6345 - val_output2_mean_absolute_error: 0.4473\n",
      "Epoch 66/250\n",
      "16800/16800 [==============================] - 4s 245us/sample - loss: 1.0481 - output1_loss: 0.4158 - output2_loss: 0.6251 - output1_accuracy: 0.8218 - output1_mean_absolute_error: 0.2612 - output2_accuracy: 0.6503 - output2_mean_absolute_error: 0.4368 - val_loss: 1.0927 - val_output1_loss: 0.4399 - val_output2_loss: 0.6464 - val_output1_accuracy: 0.8143 - val_output1_mean_absolute_error: 0.2759 - val_output2_accuracy: 0.6252 - val_output2_mean_absolute_error: 0.4463\n",
      "Epoch 67/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0495 - output1_loss: 0.4151 - output2_loss: 0.6272 - output1_accuracy: 0.8235 - output1_mean_absolute_error: 0.2614 - output2_accuracy: 0.6473 - output2_mean_absolute_error: 0.4370 - val_loss: 1.0928 - val_output1_loss: 0.4416 - val_output2_loss: 0.6451 - val_output1_accuracy: 0.8112 - val_output1_mean_absolute_error: 0.2676 - val_output2_accuracy: 0.6293 - val_output2_mean_absolute_error: 0.4495\n",
      "Epoch 68/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0453 - output1_loss: 0.4138 - output2_loss: 0.6243 - output1_accuracy: 0.8243 - output1_mean_absolute_error: 0.2607 - output2_accuracy: 0.6521 - output2_mean_absolute_error: 0.4353 - val_loss: 1.0994 - val_output1_loss: 0.4459 - val_output2_loss: 0.6466 - val_output1_accuracy: 0.8152 - val_output1_mean_absolute_error: 0.2619 - val_output2_accuracy: 0.6281 - val_output2_mean_absolute_error: 0.4484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/250\n",
      "16800/16800 [==============================] - 4s 252us/sample - loss: 1.0452 - output1_loss: 0.4141 - output2_loss: 0.6237 - output1_accuracy: 0.8226 - output1_mean_absolute_error: 0.2600 - output2_accuracy: 0.6518 - output2_mean_absolute_error: 0.4358 - val_loss: 1.0948 - val_output1_loss: 0.4402 - val_output2_loss: 0.6475 - val_output1_accuracy: 0.8133 - val_output1_mean_absolute_error: 0.2686 - val_output2_accuracy: 0.6310 - val_output2_mean_absolute_error: 0.4462\n",
      "Epoch 70/250\n",
      "16800/16800 [==============================] - 4s 247us/sample - loss: 1.0456 - output1_loss: 0.4144 - output2_loss: 0.6244 - output1_accuracy: 0.8237 - output1_mean_absolute_error: 0.2608 - output2_accuracy: 0.6510 - output2_mean_absolute_error: 0.4350 - val_loss: 1.0986 - val_output1_loss: 0.4423 - val_output2_loss: 0.6477 - val_output1_accuracy: 0.8138 - val_output1_mean_absolute_error: 0.2658 - val_output2_accuracy: 0.6286 - val_output2_mean_absolute_error: 0.4446\n",
      "Epoch 71/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0451 - output1_loss: 0.4152 - output2_loss: 0.6229 - output1_accuracy: 0.8235 - output1_mean_absolute_error: 0.2616 - output2_accuracy: 0.6498 - output2_mean_absolute_error: 0.4347 - val_loss: 1.0956 - val_output1_loss: 0.4420 - val_output2_loss: 0.6460 - val_output1_accuracy: 0.8131 - val_output1_mean_absolute_error: 0.2687 - val_output2_accuracy: 0.6288 - val_output2_mean_absolute_error: 0.4461\n",
      "Epoch 72/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0437 - output1_loss: 0.4133 - output2_loss: 0.6232 - output1_accuracy: 0.8222 - output1_mean_absolute_error: 0.2606 - output2_accuracy: 0.6520 - output2_mean_absolute_error: 0.4346 - val_loss: 1.0938 - val_output1_loss: 0.4400 - val_output2_loss: 0.6465 - val_output1_accuracy: 0.8138 - val_output1_mean_absolute_error: 0.2646 - val_output2_accuracy: 0.6302 - val_output2_mean_absolute_error: 0.4451\n",
      "Epoch 73/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0452 - output1_loss: 0.4133 - output2_loss: 0.6248 - output1_accuracy: 0.8240 - output1_mean_absolute_error: 0.2602 - output2_accuracy: 0.6512 - output2_mean_absolute_error: 0.4353 - val_loss: 1.0941 - val_output1_loss: 0.4387 - val_output2_loss: 0.6481 - val_output1_accuracy: 0.8121 - val_output1_mean_absolute_error: 0.2767 - val_output2_accuracy: 0.6295 - val_output2_mean_absolute_error: 0.4440\n",
      "Epoch 74/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0428 - output1_loss: 0.4129 - output2_loss: 0.6227 - output1_accuracy: 0.8233 - output1_mean_absolute_error: 0.2591 - output2_accuracy: 0.6547 - output2_mean_absolute_error: 0.4342 - val_loss: 1.0962 - val_output1_loss: 0.4409 - val_output2_loss: 0.6487 - val_output1_accuracy: 0.8136 - val_output1_mean_absolute_error: 0.2689 - val_output2_accuracy: 0.6317 - val_output2_mean_absolute_error: 0.4433\n",
      "Epoch 75/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0431 - output1_loss: 0.4133 - output2_loss: 0.6224 - output1_accuracy: 0.8233 - output1_mean_absolute_error: 0.2608 - output2_accuracy: 0.6533 - output2_mean_absolute_error: 0.4338 - val_loss: 1.0970 - val_output1_loss: 0.4433 - val_output2_loss: 0.6465 - val_output1_accuracy: 0.8126 - val_output1_mean_absolute_error: 0.2628 - val_output2_accuracy: 0.6274 - val_output2_mean_absolute_error: 0.4485\n",
      "Epoch 76/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0440 - output1_loss: 0.4136 - output2_loss: 0.6231 - output1_accuracy: 0.8229 - output1_mean_absolute_error: 0.2603 - output2_accuracy: 0.6512 - output2_mean_absolute_error: 0.4355 - val_loss: 1.0980 - val_output1_loss: 0.4419 - val_output2_loss: 0.6502 - val_output1_accuracy: 0.8110 - val_output1_mean_absolute_error: 0.2700 - val_output2_accuracy: 0.6264 - val_output2_mean_absolute_error: 0.4434\n",
      "Epoch 77/250\n",
      "16800/16800 [==============================] - 4s 253us/sample - loss: 1.0419 - output1_loss: 0.4115 - output2_loss: 0.6232 - output1_accuracy: 0.8246 - output1_mean_absolute_error: 0.2590 - output2_accuracy: 0.6535 - output2_mean_absolute_error: 0.4338 - val_loss: 1.0989 - val_output1_loss: 0.4449 - val_output2_loss: 0.6471 - val_output1_accuracy: 0.8131 - val_output1_mean_absolute_error: 0.2662 - val_output2_accuracy: 0.6260 - val_output2_mean_absolute_error: 0.4467\n",
      "Epoch 78/250\n",
      "16800/16800 [==============================] - 4s 239us/sample - loss: 1.0426 - output1_loss: 0.4116 - output2_loss: 0.6238 - output1_accuracy: 0.8245 - output1_mean_absolute_error: 0.2587 - output2_accuracy: 0.6488 - output2_mean_absolute_error: 0.4355 - val_loss: 1.0984 - val_output1_loss: 0.4420 - val_output2_loss: 0.6486 - val_output1_accuracy: 0.8126 - val_output1_mean_absolute_error: 0.2731 - val_output2_accuracy: 0.6271 - val_output2_mean_absolute_error: 0.4436\n",
      "Epoch 79/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0439 - output1_loss: 0.4110 - output2_loss: 0.6254 - output1_accuracy: 0.8243 - output1_mean_absolute_error: 0.2592 - output2_accuracy: 0.6518 - output2_mean_absolute_error: 0.4353 - val_loss: 1.0937 - val_output1_loss: 0.4403 - val_output2_loss: 0.6449 - val_output1_accuracy: 0.8117 - val_output1_mean_absolute_error: 0.2677 - val_output2_accuracy: 0.6317 - val_output2_mean_absolute_error: 0.4472\n",
      "Epoch 80/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0421 - output1_loss: 0.4125 - output2_loss: 0.6221 - output1_accuracy: 0.8237 - output1_mean_absolute_error: 0.2605 - output2_accuracy: 0.6502 - output2_mean_absolute_error: 0.4343 - val_loss: 1.0995 - val_output1_loss: 0.4450 - val_output2_loss: 0.6477 - val_output1_accuracy: 0.8131 - val_output1_mean_absolute_error: 0.2643 - val_output2_accuracy: 0.6288 - val_output2_mean_absolute_error: 0.4471\n",
      "Epoch 81/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0404 - output1_loss: 0.4115 - output2_loss: 0.6216 - output1_accuracy: 0.8255 - output1_mean_absolute_error: 0.2582 - output2_accuracy: 0.6554 - output2_mean_absolute_error: 0.4335 - val_loss: 1.0974 - val_output1_loss: 0.4416 - val_output2_loss: 0.6480 - val_output1_accuracy: 0.8126 - val_output1_mean_absolute_error: 0.2654 - val_output2_accuracy: 0.6319 - val_output2_mean_absolute_error: 0.4439\n",
      "Epoch 82/250\n",
      "16800/16800 [==============================] - 4s 245us/sample - loss: 1.0394 - output1_loss: 0.4109 - output2_loss: 0.6207 - output1_accuracy: 0.8258 - output1_mean_absolute_error: 0.2584 - output2_accuracy: 0.6551 - output2_mean_absolute_error: 0.4321 - val_loss: 1.0983 - val_output1_loss: 0.4419 - val_output2_loss: 0.6486 - val_output1_accuracy: 0.8131 - val_output1_mean_absolute_error: 0.2642 - val_output2_accuracy: 0.6317 - val_output2_mean_absolute_error: 0.4492\n",
      "Epoch 83/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0404 - output1_loss: 0.4108 - output2_loss: 0.6221 - output1_accuracy: 0.8240 - output1_mean_absolute_error: 0.2578 - output2_accuracy: 0.6495 - output2_mean_absolute_error: 0.4339 - val_loss: 1.0967 - val_output1_loss: 0.4402 - val_output2_loss: 0.6474 - val_output1_accuracy: 0.8095 - val_output1_mean_absolute_error: 0.2752 - val_output2_accuracy: 0.6264 - val_output2_mean_absolute_error: 0.4474\n",
      "Epoch 84/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0438 - output1_loss: 0.4132 - output2_loss: 0.6232 - output1_accuracy: 0.8231 - output1_mean_absolute_error: 0.2605 - output2_accuracy: 0.6527 - output2_mean_absolute_error: 0.4342 - val_loss: 1.1008 - val_output1_loss: 0.4454 - val_output2_loss: 0.6481 - val_output1_accuracy: 0.8143 - val_output1_mean_absolute_error: 0.2665 - val_output2_accuracy: 0.6317 - val_output2_mean_absolute_error: 0.4465\n",
      "Epoch 85/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0371 - output1_loss: 0.4092 - output2_loss: 0.6202 - output1_accuracy: 0.8243 - output1_mean_absolute_error: 0.2590 - output2_accuracy: 0.6558 - output2_mean_absolute_error: 0.4323 - val_loss: 1.1013 - val_output1_loss: 0.4437 - val_output2_loss: 0.6503 - val_output1_accuracy: 0.8119 - val_output1_mean_absolute_error: 0.2658 - val_output2_accuracy: 0.6314 - val_output2_mean_absolute_error: 0.4416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0389 - output1_loss: 0.4095 - output2_loss: 0.6221 - output1_accuracy: 0.8245 - output1_mean_absolute_error: 0.2570 - output2_accuracy: 0.6564 - output2_mean_absolute_error: 0.4330 - val_loss: 1.0976 - val_output1_loss: 0.4433 - val_output2_loss: 0.6470 - val_output1_accuracy: 0.8119 - val_output1_mean_absolute_error: 0.2746 - val_output2_accuracy: 0.6310 - val_output2_mean_absolute_error: 0.4486\n",
      "Epoch 87/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0393 - output1_loss: 0.4120 - output2_loss: 0.6200 - output1_accuracy: 0.8238 - output1_mean_absolute_error: 0.2594 - output2_accuracy: 0.6558 - output2_mean_absolute_error: 0.4318 - val_loss: 1.0998 - val_output1_loss: 0.4450 - val_output2_loss: 0.6467 - val_output1_accuracy: 0.8088 - val_output1_mean_absolute_error: 0.2711 - val_output2_accuracy: 0.6312 - val_output2_mean_absolute_error: 0.4475\n",
      "Epoch 88/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0392 - output1_loss: 0.4116 - output2_loss: 0.6203 - output1_accuracy: 0.8246 - output1_mean_absolute_error: 0.2593 - output2_accuracy: 0.6583 - output2_mean_absolute_error: 0.4322 - val_loss: 1.1012 - val_output1_loss: 0.4455 - val_output2_loss: 0.6476 - val_output1_accuracy: 0.8143 - val_output1_mean_absolute_error: 0.2606 - val_output2_accuracy: 0.6255 - val_output2_mean_absolute_error: 0.4449\n",
      "Epoch 89/250\n",
      "16800/16800 [==============================] - 4s 249us/sample - loss: 1.0366 - output1_loss: 0.4088 - output2_loss: 0.6203 - output1_accuracy: 0.8258 - output1_mean_absolute_error: 0.2574 - output2_accuracy: 0.6536 - output2_mean_absolute_error: 0.4323 - val_loss: 1.1026 - val_output1_loss: 0.4430 - val_output2_loss: 0.6525 - val_output1_accuracy: 0.8136 - val_output1_mean_absolute_error: 0.2655 - val_output2_accuracy: 0.6248 - val_output2_mean_absolute_error: 0.4412\n",
      "Epoch 90/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0376 - output1_loss: 0.4091 - output2_loss: 0.6212 - output1_accuracy: 0.8265 - output1_mean_absolute_error: 0.2576 - output2_accuracy: 0.6553 - output2_mean_absolute_error: 0.4314 - val_loss: 1.1010 - val_output1_loss: 0.4432 - val_output2_loss: 0.6502 - val_output1_accuracy: 0.8117 - val_output1_mean_absolute_error: 0.2675 - val_output2_accuracy: 0.6288 - val_output2_mean_absolute_error: 0.4442\n",
      "Epoch 91/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0352 - output1_loss: 0.4081 - output2_loss: 0.6191 - output1_accuracy: 0.8255 - output1_mean_absolute_error: 0.2569 - output2_accuracy: 0.6538 - output2_mean_absolute_error: 0.4314 - val_loss: 1.0998 - val_output1_loss: 0.4453 - val_output2_loss: 0.6467 - val_output1_accuracy: 0.8124 - val_output1_mean_absolute_error: 0.2725 - val_output2_accuracy: 0.6302 - val_output2_mean_absolute_error: 0.4446\n",
      "Epoch 92/250\n",
      "16800/16800 [==============================] - 4s 246us/sample - loss: 1.0381 - output1_loss: 0.4096 - output2_loss: 0.6206 - output1_accuracy: 0.8230 - output1_mean_absolute_error: 0.2584 - output2_accuracy: 0.6536 - output2_mean_absolute_error: 0.4323 - val_loss: 1.1005 - val_output1_loss: 0.4444 - val_output2_loss: 0.6482 - val_output1_accuracy: 0.8098 - val_output1_mean_absolute_error: 0.2680 - val_output2_accuracy: 0.6317 - val_output2_mean_absolute_error: 0.4449\n",
      "Epoch 93/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0372 - output1_loss: 0.4093 - output2_loss: 0.6201 - output1_accuracy: 0.8239 - output1_mean_absolute_error: 0.2586 - output2_accuracy: 0.6553 - output2_mean_absolute_error: 0.4320 - val_loss: 1.1016 - val_output1_loss: 0.4463 - val_output2_loss: 0.6479 - val_output1_accuracy: 0.8129 - val_output1_mean_absolute_error: 0.2586 - val_output2_accuracy: 0.6305 - val_output2_mean_absolute_error: 0.4467\n",
      "Epoch 94/250\n",
      "16800/16800 [==============================] - 4s 245us/sample - loss: 1.0370 - output1_loss: 0.4088 - output2_loss: 0.6206 - output1_accuracy: 0.8254 - output1_mean_absolute_error: 0.2567 - output2_accuracy: 0.6543 - output2_mean_absolute_error: 0.4317 - val_loss: 1.1024 - val_output1_loss: 0.4460 - val_output2_loss: 0.6497 - val_output1_accuracy: 0.8093 - val_output1_mean_absolute_error: 0.2698 - val_output2_accuracy: 0.6221 - val_output2_mean_absolute_error: 0.4484\n",
      "Epoch 95/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0361 - output1_loss: 0.4094 - output2_loss: 0.6190 - output1_accuracy: 0.8241 - output1_mean_absolute_error: 0.2575 - output2_accuracy: 0.6555 - output2_mean_absolute_error: 0.4314 - val_loss: 1.1009 - val_output1_loss: 0.4446 - val_output2_loss: 0.6481 - val_output1_accuracy: 0.8126 - val_output1_mean_absolute_error: 0.2600 - val_output2_accuracy: 0.6269 - val_output2_mean_absolute_error: 0.4449\n",
      "Epoch 96/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0350 - output1_loss: 0.4085 - output2_loss: 0.6188 - output1_accuracy: 0.8253 - output1_mean_absolute_error: 0.2566 - output2_accuracy: 0.6567 - output2_mean_absolute_error: 0.4306 - val_loss: 1.1022 - val_output1_loss: 0.4431 - val_output2_loss: 0.6504 - val_output1_accuracy: 0.8157 - val_output1_mean_absolute_error: 0.2688 - val_output2_accuracy: 0.6243 - val_output2_mean_absolute_error: 0.4444\n",
      "Epoch 97/250\n",
      "16800/16800 [==============================] - 4s 249us/sample - loss: 1.0334 - output1_loss: 0.4087 - output2_loss: 0.6166 - output1_accuracy: 0.8249 - output1_mean_absolute_error: 0.2579 - output2_accuracy: 0.6590 - output2_mean_absolute_error: 0.4294 - val_loss: 1.1091 - val_output1_loss: 0.4474 - val_output2_loss: 0.6536 - val_output1_accuracy: 0.8126 - val_output1_mean_absolute_error: 0.2620 - val_output2_accuracy: 0.6279 - val_output2_mean_absolute_error: 0.4418\n",
      "Epoch 98/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0351 - output1_loss: 0.4077 - output2_loss: 0.6193 - output1_accuracy: 0.8274 - output1_mean_absolute_error: 0.2561 - output2_accuracy: 0.6569 - output2_mean_absolute_error: 0.4306 - val_loss: 1.1012 - val_output1_loss: 0.4432 - val_output2_loss: 0.6499 - val_output1_accuracy: 0.8119 - val_output1_mean_absolute_error: 0.2672 - val_output2_accuracy: 0.6290 - val_output2_mean_absolute_error: 0.4460\n",
      "Epoch 99/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0355 - output1_loss: 0.4095 - output2_loss: 0.6180 - output1_accuracy: 0.8244 - output1_mean_absolute_error: 0.2572 - output2_accuracy: 0.6541 - output2_mean_absolute_error: 0.4305 - val_loss: 1.1006 - val_output1_loss: 0.4402 - val_output2_loss: 0.6523 - val_output1_accuracy: 0.8140 - val_output1_mean_absolute_error: 0.2678 - val_output2_accuracy: 0.6250 - val_output2_mean_absolute_error: 0.4430\n",
      "Epoch 100/250\n",
      "16800/16800 [==============================] - 4s 247us/sample - loss: 1.0337 - output1_loss: 0.4070 - output2_loss: 0.6188 - output1_accuracy: 0.8275 - output1_mean_absolute_error: 0.2563 - output2_accuracy: 0.6563 - output2_mean_absolute_error: 0.4299 - val_loss: 1.1003 - val_output1_loss: 0.4421 - val_output2_loss: 0.6498 - val_output1_accuracy: 0.8131 - val_output1_mean_absolute_error: 0.2724 - val_output2_accuracy: 0.6231 - val_output2_mean_absolute_error: 0.4491\n",
      "Epoch 101/250\n",
      "16800/16800 [==============================] - 4s 245us/sample - loss: 1.0379 - output1_loss: 0.4107 - output2_loss: 0.6190 - output1_accuracy: 0.8237 - output1_mean_absolute_error: 0.2583 - output2_accuracy: 0.6571 - output2_mean_absolute_error: 0.4311 - val_loss: 1.1006 - val_output1_loss: 0.4435 - val_output2_loss: 0.6493 - val_output1_accuracy: 0.8131 - val_output1_mean_absolute_error: 0.2634 - val_output2_accuracy: 0.6252 - val_output2_mean_absolute_error: 0.4472\n",
      "Epoch 102/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0295 - output1_loss: 0.4059 - output2_loss: 0.6159 - output1_accuracy: 0.8274 - output1_mean_absolute_error: 0.2557 - output2_accuracy: 0.6575 - output2_mean_absolute_error: 0.4292 - val_loss: 1.1019 - val_output1_loss: 0.4425 - val_output2_loss: 0.6514 - val_output1_accuracy: 0.8131 - val_output1_mean_absolute_error: 0.2703 - val_output2_accuracy: 0.6264 - val_output2_mean_absolute_error: 0.4419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/250\n",
      "16800/16800 [==============================] - 4s 245us/sample - loss: 1.0325 - output1_loss: 0.4068 - output2_loss: 0.6177 - output1_accuracy: 0.8250 - output1_mean_absolute_error: 0.2563 - output2_accuracy: 0.6555 - output2_mean_absolute_error: 0.4289 - val_loss: 1.1032 - val_output1_loss: 0.4443 - val_output2_loss: 0.6509 - val_output1_accuracy: 0.8112 - val_output1_mean_absolute_error: 0.2650 - val_output2_accuracy: 0.6283 - val_output2_mean_absolute_error: 0.4467\n",
      "Epoch 104/250\n",
      "16800/16800 [==============================] - 4s 252us/sample - loss: 1.0326 - output1_loss: 0.4067 - output2_loss: 0.6179 - output1_accuracy: 0.8271 - output1_mean_absolute_error: 0.2559 - output2_accuracy: 0.6580 - output2_mean_absolute_error: 0.4299 - val_loss: 1.1049 - val_output1_loss: 0.4444 - val_output2_loss: 0.6523 - val_output1_accuracy: 0.8129 - val_output1_mean_absolute_error: 0.2652 - val_output2_accuracy: 0.6290 - val_output2_mean_absolute_error: 0.4434\n",
      "Epoch 105/250\n",
      "16800/16800 [==============================] - 4s 246us/sample - loss: 1.0332 - output1_loss: 0.4083 - output2_loss: 0.6175 - output1_accuracy: 0.8263 - output1_mean_absolute_error: 0.2569 - output2_accuracy: 0.6571 - output2_mean_absolute_error: 0.4296 - val_loss: 1.1056 - val_output1_loss: 0.4456 - val_output2_loss: 0.6514 - val_output1_accuracy: 0.8114 - val_output1_mean_absolute_error: 0.2601 - val_output2_accuracy: 0.6283 - val_output2_mean_absolute_error: 0.4430\n",
      "Epoch 106/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0340 - output1_loss: 0.4085 - output2_loss: 0.6180 - output1_accuracy: 0.8240 - output1_mean_absolute_error: 0.2570 - output2_accuracy: 0.6562 - output2_mean_absolute_error: 0.4293 - val_loss: 1.1090 - val_output1_loss: 0.4464 - val_output2_loss: 0.6545 - val_output1_accuracy: 0.8093 - val_output1_mean_absolute_error: 0.2668 - val_output2_accuracy: 0.6252 - val_output2_mean_absolute_error: 0.4417\n",
      "Epoch 107/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0311 - output1_loss: 0.4076 - output2_loss: 0.6152 - output1_accuracy: 0.8257 - output1_mean_absolute_error: 0.2563 - output2_accuracy: 0.6602 - output2_mean_absolute_error: 0.4279 - val_loss: 1.1047 - val_output1_loss: 0.4442 - val_output2_loss: 0.6520 - val_output1_accuracy: 0.8124 - val_output1_mean_absolute_error: 0.2706 - val_output2_accuracy: 0.6290 - val_output2_mean_absolute_error: 0.4436\n",
      "Epoch 108/250\n",
      "16800/16800 [==============================] - 4s 249us/sample - loss: 1.0311 - output1_loss: 0.4057 - output2_loss: 0.6172 - output1_accuracy: 0.8248 - output1_mean_absolute_error: 0.2554 - output2_accuracy: 0.6557 - output2_mean_absolute_error: 0.4285 - val_loss: 1.1042 - val_output1_loss: 0.4442 - val_output2_loss: 0.6520 - val_output1_accuracy: 0.8131 - val_output1_mean_absolute_error: 0.2708 - val_output2_accuracy: 0.6262 - val_output2_mean_absolute_error: 0.4481\n",
      "Epoch 109/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0325 - output1_loss: 0.4078 - output2_loss: 0.6165 - output1_accuracy: 0.8278 - output1_mean_absolute_error: 0.2566 - output2_accuracy: 0.6560 - output2_mean_absolute_error: 0.4296 - val_loss: 1.1060 - val_output1_loss: 0.4465 - val_output2_loss: 0.6506 - val_output1_accuracy: 0.8114 - val_output1_mean_absolute_error: 0.2672 - val_output2_accuracy: 0.6255 - val_output2_mean_absolute_error: 0.4436\n",
      "Epoch 110/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0313 - output1_loss: 0.4078 - output2_loss: 0.6153 - output1_accuracy: 0.8262 - output1_mean_absolute_error: 0.2565 - output2_accuracy: 0.6607 - output2_mean_absolute_error: 0.4277 - val_loss: 1.1036 - val_output1_loss: 0.4449 - val_output2_loss: 0.6511 - val_output1_accuracy: 0.8136 - val_output1_mean_absolute_error: 0.2663 - val_output2_accuracy: 0.6312 - val_output2_mean_absolute_error: 0.4459\n",
      "Epoch 111/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0300 - output1_loss: 0.4058 - output2_loss: 0.6158 - output1_accuracy: 0.8260 - output1_mean_absolute_error: 0.2542 - output2_accuracy: 0.6609 - output2_mean_absolute_error: 0.4278 - val_loss: 1.1077 - val_output1_loss: 0.4457 - val_output2_loss: 0.6543 - val_output1_accuracy: 0.8090 - val_output1_mean_absolute_error: 0.2760 - val_output2_accuracy: 0.6262 - val_output2_mean_absolute_error: 0.4438\n",
      "Epoch 112/250\n",
      "16800/16800 [==============================] - 4s 251us/sample - loss: 1.0321 - output1_loss: 0.4063 - output2_loss: 0.6176 - output1_accuracy: 0.8243 - output1_mean_absolute_error: 0.2563 - output2_accuracy: 0.6560 - output2_mean_absolute_error: 0.4302 - val_loss: 1.1076 - val_output1_loss: 0.4461 - val_output2_loss: 0.6524 - val_output1_accuracy: 0.8136 - val_output1_mean_absolute_error: 0.2643 - val_output2_accuracy: 0.6288 - val_output2_mean_absolute_error: 0.4426\n",
      "Epoch 113/250\n",
      "16800/16800 [==============================] - 4s 253us/sample - loss: 1.0292 - output1_loss: 0.4060 - output2_loss: 0.6153 - output1_accuracy: 0.8259 - output1_mean_absolute_error: 0.2557 - output2_accuracy: 0.6604 - output2_mean_absolute_error: 0.4267 - val_loss: 1.1043 - val_output1_loss: 0.4453 - val_output2_loss: 0.6500 - val_output1_accuracy: 0.8138 - val_output1_mean_absolute_error: 0.2641 - val_output2_accuracy: 0.6236 - val_output2_mean_absolute_error: 0.4448\n",
      "Epoch 114/250\n",
      "16800/16800 [==============================] - 4s 261us/sample - loss: 1.0297 - output1_loss: 0.4046 - output2_loss: 0.6170 - output1_accuracy: 0.8267 - output1_mean_absolute_error: 0.2538 - output2_accuracy: 0.6568 - output2_mean_absolute_error: 0.4296 - val_loss: 1.1059 - val_output1_loss: 0.4454 - val_output2_loss: 0.6524 - val_output1_accuracy: 0.8119 - val_output1_mean_absolute_error: 0.2730 - val_output2_accuracy: 0.6190 - val_output2_mean_absolute_error: 0.4444\n",
      "Epoch 115/250\n",
      "16800/16800 [==============================] - 4s 262us/sample - loss: 1.0277 - output1_loss: 0.4051 - output2_loss: 0.6146 - output1_accuracy: 0.8258 - output1_mean_absolute_error: 0.2556 - output2_accuracy: 0.6560 - output2_mean_absolute_error: 0.4272 - val_loss: 1.1073 - val_output1_loss: 0.4452 - val_output2_loss: 0.6541 - val_output1_accuracy: 0.8152 - val_output1_mean_absolute_error: 0.2621 - val_output2_accuracy: 0.6221 - val_output2_mean_absolute_error: 0.4453\n",
      "Epoch 116/250\n",
      "16800/16800 [==============================] - 4s 264us/sample - loss: 1.0281 - output1_loss: 0.4048 - output2_loss: 0.6151 - output1_accuracy: 0.8274 - output1_mean_absolute_error: 0.2548 - output2_accuracy: 0.6601 - output2_mean_absolute_error: 0.4279 - val_loss: 1.1068 - val_output1_loss: 0.4452 - val_output2_loss: 0.6525 - val_output1_accuracy: 0.8143 - val_output1_mean_absolute_error: 0.2603 - val_output2_accuracy: 0.6221 - val_output2_mean_absolute_error: 0.4462\n",
      "Epoch 117/250\n",
      "16800/16800 [==============================] - 4s 247us/sample - loss: 1.0293 - output1_loss: 0.4047 - output2_loss: 0.6163 - output1_accuracy: 0.8252 - output1_mean_absolute_error: 0.2552 - output2_accuracy: 0.6595 - output2_mean_absolute_error: 0.4279 - val_loss: 1.1095 - val_output1_loss: 0.4504 - val_output2_loss: 0.6508 - val_output1_accuracy: 0.8093 - val_output1_mean_absolute_error: 0.2612 - val_output2_accuracy: 0.6245 - val_output2_mean_absolute_error: 0.4444\n",
      "Epoch 118/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0266 - output1_loss: 0.4051 - output2_loss: 0.6130 - output1_accuracy: 0.8272 - output1_mean_absolute_error: 0.2537 - output2_accuracy: 0.6631 - output2_mean_absolute_error: 0.4263 - val_loss: 1.1036 - val_output1_loss: 0.4432 - val_output2_loss: 0.6515 - val_output1_accuracy: 0.8119 - val_output1_mean_absolute_error: 0.2700 - val_output2_accuracy: 0.6183 - val_output2_mean_absolute_error: 0.4461\n",
      "Epoch 119/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0254 - output1_loss: 0.4041 - output2_loss: 0.6131 - output1_accuracy: 0.8256 - output1_mean_absolute_error: 0.2544 - output2_accuracy: 0.6604 - output2_mean_absolute_error: 0.4257 - val_loss: 1.1082 - val_output1_loss: 0.4471 - val_output2_loss: 0.6531 - val_output1_accuracy: 0.8102 - val_output1_mean_absolute_error: 0.2719 - val_output2_accuracy: 0.6240 - val_output2_mean_absolute_error: 0.4408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/250\n",
      "16800/16800 [==============================] - 4s 248us/sample - loss: 1.0263 - output1_loss: 0.4051 - output2_loss: 0.6127 - output1_accuracy: 0.8264 - output1_mean_absolute_error: 0.2555 - output2_accuracy: 0.6629 - output2_mean_absolute_error: 0.4253 - val_loss: 1.1067 - val_output1_loss: 0.4483 - val_output2_loss: 0.6495 - val_output1_accuracy: 0.8110 - val_output1_mean_absolute_error: 0.2610 - val_output2_accuracy: 0.6210 - val_output2_mean_absolute_error: 0.4459\n",
      "Epoch 121/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0260 - output1_loss: 0.4040 - output2_loss: 0.6133 - output1_accuracy: 0.8271 - output1_mean_absolute_error: 0.2534 - output2_accuracy: 0.6607 - output2_mean_absolute_error: 0.4257 - val_loss: 1.1061 - val_output1_loss: 0.4477 - val_output2_loss: 0.6510 - val_output1_accuracy: 0.8100 - val_output1_mean_absolute_error: 0.2673 - val_output2_accuracy: 0.6257 - val_output2_mean_absolute_error: 0.4450\n",
      "Epoch 122/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0268 - output1_loss: 0.4042 - output2_loss: 0.6143 - output1_accuracy: 0.8292 - output1_mean_absolute_error: 0.2529 - output2_accuracy: 0.6589 - output2_mean_absolute_error: 0.4270 - val_loss: 1.1044 - val_output1_loss: 0.4434 - val_output2_loss: 0.6524 - val_output1_accuracy: 0.8121 - val_output1_mean_absolute_error: 0.2700 - val_output2_accuracy: 0.6224 - val_output2_mean_absolute_error: 0.4459\n",
      "Epoch 123/250\n",
      "16800/16800 [==============================] - 4s 249us/sample - loss: 1.0284 - output1_loss: 0.4075 - output2_loss: 0.6125 - output1_accuracy: 0.8257 - output1_mean_absolute_error: 0.2557 - output2_accuracy: 0.6601 - output2_mean_absolute_error: 0.4246 - val_loss: 1.1040 - val_output1_loss: 0.4456 - val_output2_loss: 0.6505 - val_output1_accuracy: 0.8105 - val_output1_mean_absolute_error: 0.2734 - val_output2_accuracy: 0.6276 - val_output2_mean_absolute_error: 0.4458\n",
      "Epoch 124/250\n",
      "16800/16800 [==============================] - 4s 245us/sample - loss: 1.0261 - output1_loss: 0.4026 - output2_loss: 0.6148 - output1_accuracy: 0.8277 - output1_mean_absolute_error: 0.2542 - output2_accuracy: 0.6592 - output2_mean_absolute_error: 0.4279 - val_loss: 1.1070 - val_output1_loss: 0.4472 - val_output2_loss: 0.6534 - val_output1_accuracy: 0.8095 - val_output1_mean_absolute_error: 0.2687 - val_output2_accuracy: 0.6221 - val_output2_mean_absolute_error: 0.4459\n",
      "Epoch 125/250\n",
      "16800/16800 [==============================] - 4s 246us/sample - loss: 1.0276 - output1_loss: 0.4056 - output2_loss: 0.6137 - output1_accuracy: 0.8261 - output1_mean_absolute_error: 0.2549 - output2_accuracy: 0.6600 - output2_mean_absolute_error: 0.4258 - val_loss: 1.1089 - val_output1_loss: 0.4451 - val_output2_loss: 0.6553 - val_output1_accuracy: 0.8119 - val_output1_mean_absolute_error: 0.2655 - val_output2_accuracy: 0.6190 - val_output2_mean_absolute_error: 0.4434\n",
      "Epoch 126/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0275 - output1_loss: 0.4035 - output2_loss: 0.6153 - output1_accuracy: 0.8253 - output1_mean_absolute_error: 0.2542 - output2_accuracy: 0.6611 - output2_mean_absolute_error: 0.4274 - val_loss: 1.1054 - val_output1_loss: 0.4467 - val_output2_loss: 0.6506 - val_output1_accuracy: 0.8121 - val_output1_mean_absolute_error: 0.2667 - val_output2_accuracy: 0.6226 - val_output2_mean_absolute_error: 0.4471\n",
      "Epoch 127/250\n",
      "16800/16800 [==============================] - 4s 251us/sample - loss: 1.0241 - output1_loss: 0.4014 - output2_loss: 0.6143 - output1_accuracy: 0.8260 - output1_mean_absolute_error: 0.2525 - output2_accuracy: 0.6612 - output2_mean_absolute_error: 0.4274 - val_loss: 1.1085 - val_output1_loss: 0.4480 - val_output2_loss: 0.6523 - val_output1_accuracy: 0.8090 - val_output1_mean_absolute_error: 0.2651 - val_output2_accuracy: 0.6214 - val_output2_mean_absolute_error: 0.4443\n",
      "Epoch 128/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0270 - output1_loss: 0.4026 - output2_loss: 0.6154 - output1_accuracy: 0.8281 - output1_mean_absolute_error: 0.2528 - output2_accuracy: 0.6583 - output2_mean_absolute_error: 0.4272 - val_loss: 1.1061 - val_output1_loss: 0.4477 - val_output2_loss: 0.6492 - val_output1_accuracy: 0.8060 - val_output1_mean_absolute_error: 0.2800 - val_output2_accuracy: 0.6245 - val_output2_mean_absolute_error: 0.4446\n",
      "Epoch 129/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0210 - output1_loss: 0.4017 - output2_loss: 0.6109 - output1_accuracy: 0.8257 - output1_mean_absolute_error: 0.2534 - output2_accuracy: 0.6636 - output2_mean_absolute_error: 0.4249 - val_loss: 1.1100 - val_output1_loss: 0.4471 - val_output2_loss: 0.6540 - val_output1_accuracy: 0.8126 - val_output1_mean_absolute_error: 0.2646 - val_output2_accuracy: 0.6219 - val_output2_mean_absolute_error: 0.4430\n",
      "Epoch 130/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0230 - output1_loss: 0.4037 - output2_loss: 0.6104 - output1_accuracy: 0.8270 - output1_mean_absolute_error: 0.2545 - output2_accuracy: 0.6638 - output2_mean_absolute_error: 0.4238 - val_loss: 1.1152 - val_output1_loss: 0.4525 - val_output2_loss: 0.6537 - val_output1_accuracy: 0.8152 - val_output1_mean_absolute_error: 0.2618 - val_output2_accuracy: 0.6219 - val_output2_mean_absolute_error: 0.4434\n",
      "Epoch 131/250\n",
      "16800/16800 [==============================] - 4s 251us/sample - loss: 1.0256 - output1_loss: 0.4035 - output2_loss: 0.6137 - output1_accuracy: 0.8273 - output1_mean_absolute_error: 0.2536 - output2_accuracy: 0.6639 - output2_mean_absolute_error: 0.4258 - val_loss: 1.1136 - val_output1_loss: 0.4523 - val_output2_loss: 0.6528 - val_output1_accuracy: 0.8121 - val_output1_mean_absolute_error: 0.2631 - val_output2_accuracy: 0.6274 - val_output2_mean_absolute_error: 0.4429\n",
      "Epoch 132/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0244 - output1_loss: 0.4028 - output2_loss: 0.6127 - output1_accuracy: 0.8265 - output1_mean_absolute_error: 0.2536 - output2_accuracy: 0.6615 - output2_mean_absolute_error: 0.4246 - val_loss: 1.1123 - val_output1_loss: 0.4511 - val_output2_loss: 0.6522 - val_output1_accuracy: 0.8100 - val_output1_mean_absolute_error: 0.2647 - val_output2_accuracy: 0.6229 - val_output2_mean_absolute_error: 0.4462\n",
      "Epoch 133/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0228 - output1_loss: 0.4018 - output2_loss: 0.6126 - output1_accuracy: 0.8276 - output1_mean_absolute_error: 0.2528 - output2_accuracy: 0.6616 - output2_mean_absolute_error: 0.4260 - val_loss: 1.1104 - val_output1_loss: 0.4478 - val_output2_loss: 0.6539 - val_output1_accuracy: 0.8081 - val_output1_mean_absolute_error: 0.2670 - val_output2_accuracy: 0.6205 - val_output2_mean_absolute_error: 0.4431\n",
      "Epoch 134/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0254 - output1_loss: 0.4034 - output2_loss: 0.6136 - output1_accuracy: 0.8273 - output1_mean_absolute_error: 0.2534 - output2_accuracy: 0.6610 - output2_mean_absolute_error: 0.4260 - val_loss: 1.1111 - val_output1_loss: 0.4486 - val_output2_loss: 0.6532 - val_output1_accuracy: 0.8083 - val_output1_mean_absolute_error: 0.2753 - val_output2_accuracy: 0.6231 - val_output2_mean_absolute_error: 0.4462\n",
      "Epoch 135/250\n",
      "16800/16800 [==============================] - 4s 252us/sample - loss: 1.0256 - output1_loss: 0.4009 - output2_loss: 0.6155 - output1_accuracy: 0.8282 - output1_mean_absolute_error: 0.2532 - output2_accuracy: 0.6597 - output2_mean_absolute_error: 0.4279 - val_loss: 1.1117 - val_output1_loss: 0.4501 - val_output2_loss: 0.6521 - val_output1_accuracy: 0.8095 - val_output1_mean_absolute_error: 0.2646 - val_output2_accuracy: 0.6224 - val_output2_mean_absolute_error: 0.4435\n",
      "Epoch 136/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0231 - output1_loss: 0.4018 - output2_loss: 0.6123 - output1_accuracy: 0.8263 - output1_mean_absolute_error: 0.2529 - output2_accuracy: 0.6646 - output2_mean_absolute_error: 0.4243 - val_loss: 1.1135 - val_output1_loss: 0.4506 - val_output2_loss: 0.6539 - val_output1_accuracy: 0.8100 - val_output1_mean_absolute_error: 0.2648 - val_output2_accuracy: 0.6288 - val_output2_mean_absolute_error: 0.4422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0201 - output1_loss: 0.4007 - output2_loss: 0.6104 - output1_accuracy: 0.8284 - output1_mean_absolute_error: 0.2523 - output2_accuracy: 0.6641 - output2_mean_absolute_error: 0.4239 - val_loss: 1.1139 - val_output1_loss: 0.4508 - val_output2_loss: 0.6544 - val_output1_accuracy: 0.8083 - val_output1_mean_absolute_error: 0.2671 - val_output2_accuracy: 0.6236 - val_output2_mean_absolute_error: 0.4409\n",
      "Epoch 138/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0214 - output1_loss: 0.4010 - output2_loss: 0.6115 - output1_accuracy: 0.8281 - output1_mean_absolute_error: 0.2529 - output2_accuracy: 0.6609 - output2_mean_absolute_error: 0.4244 - val_loss: 1.1148 - val_output1_loss: 0.4528 - val_output2_loss: 0.6536 - val_output1_accuracy: 0.8121 - val_output1_mean_absolute_error: 0.2593 - val_output2_accuracy: 0.6224 - val_output2_mean_absolute_error: 0.4439\n",
      "Epoch 139/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0227 - output1_loss: 0.4016 - output2_loss: 0.6119 - output1_accuracy: 0.8279 - output1_mean_absolute_error: 0.2521 - output2_accuracy: 0.6594 - output2_mean_absolute_error: 0.4246 - val_loss: 1.1117 - val_output1_loss: 0.4496 - val_output2_loss: 0.6520 - val_output1_accuracy: 0.8119 - val_output1_mean_absolute_error: 0.2656 - val_output2_accuracy: 0.6233 - val_output2_mean_absolute_error: 0.4445\n",
      "Epoch 140/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0211 - output1_loss: 0.4001 - output2_loss: 0.6122 - output1_accuracy: 0.8289 - output1_mean_absolute_error: 0.2509 - output2_accuracy: 0.6650 - output2_mean_absolute_error: 0.4248 - val_loss: 1.1143 - val_output1_loss: 0.4476 - val_output2_loss: 0.6578 - val_output1_accuracy: 0.8100 - val_output1_mean_absolute_error: 0.2677 - val_output2_accuracy: 0.6240 - val_output2_mean_absolute_error: 0.4397\n",
      "Epoch 141/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0252 - output1_loss: 0.4033 - output2_loss: 0.6127 - output1_accuracy: 0.8267 - output1_mean_absolute_error: 0.2535 - output2_accuracy: 0.6608 - output2_mean_absolute_error: 0.4252 - val_loss: 1.1111 - val_output1_loss: 0.4469 - val_output2_loss: 0.6552 - val_output1_accuracy: 0.8119 - val_output1_mean_absolute_error: 0.2676 - val_output2_accuracy: 0.6212 - val_output2_mean_absolute_error: 0.4443\n",
      "Epoch 142/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0205 - output1_loss: 0.4002 - output2_loss: 0.6113 - output1_accuracy: 0.8287 - output1_mean_absolute_error: 0.2529 - output2_accuracy: 0.6642 - output2_mean_absolute_error: 0.4246 - val_loss: 1.1141 - val_output1_loss: 0.4504 - val_output2_loss: 0.6542 - val_output1_accuracy: 0.8088 - val_output1_mean_absolute_error: 0.2700 - val_output2_accuracy: 0.6214 - val_output2_mean_absolute_error: 0.4453\n",
      "Epoch 143/250\n",
      "16800/16800 [==============================] - 4s 248us/sample - loss: 1.0204 - output1_loss: 0.3998 - output2_loss: 0.6114 - output1_accuracy: 0.8276 - output1_mean_absolute_error: 0.2517 - output2_accuracy: 0.6632 - output2_mean_absolute_error: 0.4238 - val_loss: 1.1129 - val_output1_loss: 0.4511 - val_output2_loss: 0.6539 - val_output1_accuracy: 0.8133 - val_output1_mean_absolute_error: 0.2597 - val_output2_accuracy: 0.6212 - val_output2_mean_absolute_error: 0.4438\n",
      "Epoch 144/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0267 - output1_loss: 0.4038 - output2_loss: 0.6140 - output1_accuracy: 0.8257 - output1_mean_absolute_error: 0.2536 - output2_accuracy: 0.6589 - output2_mean_absolute_error: 0.4259 - val_loss: 1.1152 - val_output1_loss: 0.4537 - val_output2_loss: 0.6534 - val_output1_accuracy: 0.8112 - val_output1_mean_absolute_error: 0.2616 - val_output2_accuracy: 0.6229 - val_output2_mean_absolute_error: 0.4442\n",
      "Epoch 145/250\n",
      "16800/16800 [==============================] - 4s 245us/sample - loss: 1.0227 - output1_loss: 0.4015 - output2_loss: 0.6123 - output1_accuracy: 0.8285 - output1_mean_absolute_error: 0.2519 - output2_accuracy: 0.6631 - output2_mean_absolute_error: 0.4255 - val_loss: 1.1129 - val_output1_loss: 0.4458 - val_output2_loss: 0.6565 - val_output1_accuracy: 0.8117 - val_output1_mean_absolute_error: 0.2681 - val_output2_accuracy: 0.6186 - val_output2_mean_absolute_error: 0.4425\n",
      "Epoch 146/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0235 - output1_loss: 0.4023 - output2_loss: 0.6119 - output1_accuracy: 0.8273 - output1_mean_absolute_error: 0.2525 - output2_accuracy: 0.6665 - output2_mean_absolute_error: 0.4246 - val_loss: 1.1156 - val_output1_loss: 0.4521 - val_output2_loss: 0.6536 - val_output1_accuracy: 0.8079 - val_output1_mean_absolute_error: 0.2619 - val_output2_accuracy: 0.6238 - val_output2_mean_absolute_error: 0.4415\n",
      "Epoch 147/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0228 - output1_loss: 0.4011 - output2_loss: 0.6130 - output1_accuracy: 0.8271 - output1_mean_absolute_error: 0.2518 - output2_accuracy: 0.6570 - output2_mean_absolute_error: 0.4262 - val_loss: 1.1190 - val_output1_loss: 0.4548 - val_output2_loss: 0.6546 - val_output1_accuracy: 0.8121 - val_output1_mean_absolute_error: 0.2676 - val_output2_accuracy: 0.6271 - val_output2_mean_absolute_error: 0.4409\n",
      "Epoch 148/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0208 - output1_loss: 0.4008 - output2_loss: 0.6111 - output1_accuracy: 0.8286 - output1_mean_absolute_error: 0.2525 - output2_accuracy: 0.6624 - output2_mean_absolute_error: 0.4240 - val_loss: 1.1148 - val_output1_loss: 0.4490 - val_output2_loss: 0.6567 - val_output1_accuracy: 0.8133 - val_output1_mean_absolute_error: 0.2625 - val_output2_accuracy: 0.6202 - val_output2_mean_absolute_error: 0.4452\n",
      "Epoch 149/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0207 - output1_loss: 0.3995 - output2_loss: 0.6119 - output1_accuracy: 0.8285 - output1_mean_absolute_error: 0.2509 - output2_accuracy: 0.6655 - output2_mean_absolute_error: 0.4247 - val_loss: 1.1158 - val_output1_loss: 0.4500 - val_output2_loss: 0.6562 - val_output1_accuracy: 0.8064 - val_output1_mean_absolute_error: 0.2760 - val_output2_accuracy: 0.6248 - val_output2_mean_absolute_error: 0.4427\n",
      "Epoch 150/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0215 - output1_loss: 0.4004 - output2_loss: 0.6121 - output1_accuracy: 0.8289 - output1_mean_absolute_error: 0.2516 - output2_accuracy: 0.6637 - output2_mean_absolute_error: 0.4248 - val_loss: 1.1131 - val_output1_loss: 0.4503 - val_output2_loss: 0.6530 - val_output1_accuracy: 0.8136 - val_output1_mean_absolute_error: 0.2626 - val_output2_accuracy: 0.6198 - val_output2_mean_absolute_error: 0.4456\n",
      "Epoch 151/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0206 - output1_loss: 0.4004 - output2_loss: 0.6110 - output1_accuracy: 0.8285 - output1_mean_absolute_error: 0.2516 - output2_accuracy: 0.6666 - output2_mean_absolute_error: 0.4238 - val_loss: 1.1152 - val_output1_loss: 0.4522 - val_output2_loss: 0.6543 - val_output1_accuracy: 0.8102 - val_output1_mean_absolute_error: 0.2647 - val_output2_accuracy: 0.6229 - val_output2_mean_absolute_error: 0.4445\n",
      "Epoch 152/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0185 - output1_loss: 0.3999 - output2_loss: 0.6096 - output1_accuracy: 0.8287 - output1_mean_absolute_error: 0.2510 - output2_accuracy: 0.6640 - output2_mean_absolute_error: 0.4235 - val_loss: 1.1137 - val_output1_loss: 0.4517 - val_output2_loss: 0.6519 - val_output1_accuracy: 0.8083 - val_output1_mean_absolute_error: 0.2690 - val_output2_accuracy: 0.6243 - val_output2_mean_absolute_error: 0.4421\n",
      "Epoch 153/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0202 - output1_loss: 0.3995 - output2_loss: 0.6113 - output1_accuracy: 0.8278 - output1_mean_absolute_error: 0.2510 - output2_accuracy: 0.6628 - output2_mean_absolute_error: 0.4239 - val_loss: 1.1119 - val_output1_loss: 0.4483 - val_output2_loss: 0.6549 - val_output1_accuracy: 0.8112 - val_output1_mean_absolute_error: 0.2695 - val_output2_accuracy: 0.6219 - val_output2_mean_absolute_error: 0.4433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/250\n",
      "16800/16800 [==============================] - 4s 246us/sample - loss: 1.0192 - output1_loss: 0.3995 - output2_loss: 0.6103 - output1_accuracy: 0.8268 - output1_mean_absolute_error: 0.2515 - output2_accuracy: 0.6662 - output2_mean_absolute_error: 0.4240 - val_loss: 1.1123 - val_output1_loss: 0.4495 - val_output2_loss: 0.6526 - val_output1_accuracy: 0.8145 - val_output1_mean_absolute_error: 0.2654 - val_output2_accuracy: 0.6269 - val_output2_mean_absolute_error: 0.4426\n",
      "Epoch 155/250\n",
      "16800/16800 [==============================] - 4s 248us/sample - loss: 1.0242 - output1_loss: 0.4024 - output2_loss: 0.6127 - output1_accuracy: 0.8263 - output1_mean_absolute_error: 0.2519 - output2_accuracy: 0.6624 - output2_mean_absolute_error: 0.4246 - val_loss: 1.1099 - val_output1_loss: 0.4478 - val_output2_loss: 0.6524 - val_output1_accuracy: 0.8129 - val_output1_mean_absolute_error: 0.2670 - val_output2_accuracy: 0.6190 - val_output2_mean_absolute_error: 0.4438\n",
      "Epoch 156/250\n",
      "16800/16800 [==============================] - 4s 245us/sample - loss: 1.0179 - output1_loss: 0.3978 - output2_loss: 0.6109 - output1_accuracy: 0.8297 - output1_mean_absolute_error: 0.2514 - output2_accuracy: 0.6665 - output2_mean_absolute_error: 0.4242 - val_loss: 1.1194 - val_output1_loss: 0.4531 - val_output2_loss: 0.6571 - val_output1_accuracy: 0.8121 - val_output1_mean_absolute_error: 0.2663 - val_output2_accuracy: 0.6214 - val_output2_mean_absolute_error: 0.4421\n",
      "Epoch 157/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0199 - output1_loss: 0.4008 - output2_loss: 0.6100 - output1_accuracy: 0.8296 - output1_mean_absolute_error: 0.2521 - output2_accuracy: 0.6645 - output2_mean_absolute_error: 0.4237 - val_loss: 1.1160 - val_output1_loss: 0.4517 - val_output2_loss: 0.6556 - val_output1_accuracy: 0.8121 - val_output1_mean_absolute_error: 0.2655 - val_output2_accuracy: 0.6240 - val_output2_mean_absolute_error: 0.4432\n",
      "Epoch 158/250\n",
      "16800/16800 [==============================] - 4s 248us/sample - loss: 1.0212 - output1_loss: 0.4004 - output2_loss: 0.6111 - output1_accuracy: 0.8274 - output1_mean_absolute_error: 0.2520 - output2_accuracy: 0.6666 - output2_mean_absolute_error: 0.4238 - val_loss: 1.1178 - val_output1_loss: 0.4527 - val_output2_loss: 0.6551 - val_output1_accuracy: 0.8145 - val_output1_mean_absolute_error: 0.2629 - val_output2_accuracy: 0.6264 - val_output2_mean_absolute_error: 0.4437\n",
      "Epoch 159/250\n",
      "16800/16800 [==============================] - 4s 246us/sample - loss: 1.0214 - output1_loss: 0.4013 - output2_loss: 0.6109 - output1_accuracy: 0.8291 - output1_mean_absolute_error: 0.2516 - output2_accuracy: 0.6620 - output2_mean_absolute_error: 0.4241 - val_loss: 1.1162 - val_output1_loss: 0.4528 - val_output2_loss: 0.6547 - val_output1_accuracy: 0.8081 - val_output1_mean_absolute_error: 0.2709 - val_output2_accuracy: 0.6224 - val_output2_mean_absolute_error: 0.4429\n",
      "Epoch 160/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0192 - output1_loss: 0.3994 - output2_loss: 0.6111 - output1_accuracy: 0.8296 - output1_mean_absolute_error: 0.2513 - output2_accuracy: 0.6645 - output2_mean_absolute_error: 0.4237 - val_loss: 1.1151 - val_output1_loss: 0.4517 - val_output2_loss: 0.6534 - val_output1_accuracy: 0.8121 - val_output1_mean_absolute_error: 0.2622 - val_output2_accuracy: 0.6240 - val_output2_mean_absolute_error: 0.4446\n",
      "Epoch 161/250\n",
      "16800/16800 [==============================] - 4s 245us/sample - loss: 1.0178 - output1_loss: 0.3990 - output2_loss: 0.6099 - output1_accuracy: 0.8273 - output1_mean_absolute_error: 0.2507 - output2_accuracy: 0.6611 - output2_mean_absolute_error: 0.4233 - val_loss: 1.1213 - val_output1_loss: 0.4542 - val_output2_loss: 0.6577 - val_output1_accuracy: 0.8119 - val_output1_mean_absolute_error: 0.2612 - val_output2_accuracy: 0.6231 - val_output2_mean_absolute_error: 0.4411\n",
      "Epoch 162/250\n",
      "16800/16800 [==============================] - 4s 252us/sample - loss: 1.0147 - output1_loss: 0.3959 - output2_loss: 0.6093 - output1_accuracy: 0.8321 - output1_mean_absolute_error: 0.2498 - output2_accuracy: 0.6655 - output2_mean_absolute_error: 0.4229 - val_loss: 1.1156 - val_output1_loss: 0.4492 - val_output2_loss: 0.6567 - val_output1_accuracy: 0.8129 - val_output1_mean_absolute_error: 0.2581 - val_output2_accuracy: 0.6250 - val_output2_mean_absolute_error: 0.4390\n",
      "Epoch 163/250\n",
      "16800/16800 [==============================] - 4s 245us/sample - loss: 1.0218 - output1_loss: 0.4013 - output2_loss: 0.6117 - output1_accuracy: 0.8285 - output1_mean_absolute_error: 0.2507 - output2_accuracy: 0.6611 - output2_mean_absolute_error: 0.4235 - val_loss: 1.1123 - val_output1_loss: 0.4495 - val_output2_loss: 0.6534 - val_output1_accuracy: 0.8090 - val_output1_mean_absolute_error: 0.2659 - val_output2_accuracy: 0.6274 - val_output2_mean_absolute_error: 0.4413\n",
      "Epoch 164/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0175 - output1_loss: 0.3988 - output2_loss: 0.6089 - output1_accuracy: 0.8288 - output1_mean_absolute_error: 0.2519 - output2_accuracy: 0.6663 - output2_mean_absolute_error: 0.4222 - val_loss: 1.1202 - val_output1_loss: 0.4533 - val_output2_loss: 0.6590 - val_output1_accuracy: 0.8121 - val_output1_mean_absolute_error: 0.2550 - val_output2_accuracy: 0.6264 - val_output2_mean_absolute_error: 0.4420\n",
      "Epoch 165/250\n",
      "16800/16800 [==============================] - 4s 245us/sample - loss: 1.0178 - output1_loss: 0.3993 - output2_loss: 0.6093 - output1_accuracy: 0.8308 - output1_mean_absolute_error: 0.2489 - output2_accuracy: 0.6599 - output2_mean_absolute_error: 0.4231 - val_loss: 1.1113 - val_output1_loss: 0.4483 - val_output2_loss: 0.6547 - val_output1_accuracy: 0.8100 - val_output1_mean_absolute_error: 0.2674 - val_output2_accuracy: 0.6200 - val_output2_mean_absolute_error: 0.4419\n",
      "Epoch 166/250\n",
      "16800/16800 [==============================] - 4s 249us/sample - loss: 1.0146 - output1_loss: 0.3978 - output2_loss: 0.6080 - output1_accuracy: 0.8295 - output1_mean_absolute_error: 0.2506 - output2_accuracy: 0.6655 - output2_mean_absolute_error: 0.4213 - val_loss: 1.1158 - val_output1_loss: 0.4503 - val_output2_loss: 0.6555 - val_output1_accuracy: 0.8105 - val_output1_mean_absolute_error: 0.2639 - val_output2_accuracy: 0.6226 - val_output2_mean_absolute_error: 0.4407\n",
      "Epoch 167/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0139 - output1_loss: 0.3966 - output2_loss: 0.6075 - output1_accuracy: 0.8295 - output1_mean_absolute_error: 0.2497 - output2_accuracy: 0.6670 - output2_mean_absolute_error: 0.4207 - val_loss: 1.1181 - val_output1_loss: 0.4510 - val_output2_loss: 0.6577 - val_output1_accuracy: 0.8110 - val_output1_mean_absolute_error: 0.2641 - val_output2_accuracy: 0.6169 - val_output2_mean_absolute_error: 0.4439\n",
      "Epoch 168/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0185 - output1_loss: 0.3982 - output2_loss: 0.6110 - output1_accuracy: 0.8293 - output1_mean_absolute_error: 0.2503 - output2_accuracy: 0.6623 - output2_mean_absolute_error: 0.4235 - val_loss: 1.1175 - val_output1_loss: 0.4522 - val_output2_loss: 0.6561 - val_output1_accuracy: 0.8112 - val_output1_mean_absolute_error: 0.2626 - val_output2_accuracy: 0.6240 - val_output2_mean_absolute_error: 0.4408\n",
      "Epoch 169/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0152 - output1_loss: 0.3974 - output2_loss: 0.6087 - output1_accuracy: 0.8286 - output1_mean_absolute_error: 0.2494 - output2_accuracy: 0.6660 - output2_mean_absolute_error: 0.4218 - val_loss: 1.1178 - val_output1_loss: 0.4510 - val_output2_loss: 0.6571 - val_output1_accuracy: 0.8095 - val_output1_mean_absolute_error: 0.2717 - val_output2_accuracy: 0.6267 - val_output2_mean_absolute_error: 0.4392\n",
      "Epoch 170/250\n",
      "16800/16800 [==============================] - 4s 252us/sample - loss: 1.0162 - output1_loss: 0.3989 - output2_loss: 0.6077 - output1_accuracy: 0.8288 - output1_mean_absolute_error: 0.2508 - output2_accuracy: 0.6675 - output2_mean_absolute_error: 0.4212 - val_loss: 1.1160 - val_output1_loss: 0.4508 - val_output2_loss: 0.6565 - val_output1_accuracy: 0.8102 - val_output1_mean_absolute_error: 0.2708 - val_output2_accuracy: 0.6236 - val_output2_mean_absolute_error: 0.4423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0183 - output1_loss: 0.3992 - output2_loss: 0.6095 - output1_accuracy: 0.8302 - output1_mean_absolute_error: 0.2521 - output2_accuracy: 0.6644 - output2_mean_absolute_error: 0.4216 - val_loss: 1.1128 - val_output1_loss: 0.4512 - val_output2_loss: 0.6527 - val_output1_accuracy: 0.8098 - val_output1_mean_absolute_error: 0.2598 - val_output2_accuracy: 0.6217 - val_output2_mean_absolute_error: 0.4448\n",
      "Epoch 172/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0163 - output1_loss: 0.3979 - output2_loss: 0.6091 - output1_accuracy: 0.8288 - output1_mean_absolute_error: 0.2500 - output2_accuracy: 0.6662 - output2_mean_absolute_error: 0.4226 - val_loss: 1.1159 - val_output1_loss: 0.4512 - val_output2_loss: 0.6547 - val_output1_accuracy: 0.8095 - val_output1_mean_absolute_error: 0.2673 - val_output2_accuracy: 0.6243 - val_output2_mean_absolute_error: 0.4431\n",
      "Epoch 173/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0181 - output1_loss: 0.3989 - output2_loss: 0.6095 - output1_accuracy: 0.8271 - output1_mean_absolute_error: 0.2511 - output2_accuracy: 0.6665 - output2_mean_absolute_error: 0.4215 - val_loss: 1.1158 - val_output1_loss: 0.4526 - val_output2_loss: 0.6531 - val_output1_accuracy: 0.8095 - val_output1_mean_absolute_error: 0.2645 - val_output2_accuracy: 0.6212 - val_output2_mean_absolute_error: 0.4458\n",
      "Epoch 174/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0164 - output1_loss: 0.3972 - output2_loss: 0.6098 - output1_accuracy: 0.8283 - output1_mean_absolute_error: 0.2493 - output2_accuracy: 0.6653 - output2_mean_absolute_error: 0.4230 - val_loss: 1.1203 - val_output1_loss: 0.4566 - val_output2_loss: 0.6541 - val_output1_accuracy: 0.8100 - val_output1_mean_absolute_error: 0.2604 - val_output2_accuracy: 0.6245 - val_output2_mean_absolute_error: 0.4439\n",
      "Epoch 175/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0179 - output1_loss: 0.3983 - output2_loss: 0.6098 - output1_accuracy: 0.8292 - output1_mean_absolute_error: 0.2495 - output2_accuracy: 0.6646 - output2_mean_absolute_error: 0.4227 - val_loss: 1.1191 - val_output1_loss: 0.4534 - val_output2_loss: 0.6574 - val_output1_accuracy: 0.8079 - val_output1_mean_absolute_error: 0.2718 - val_output2_accuracy: 0.6183 - val_output2_mean_absolute_error: 0.4421\n",
      "Epoch 176/250\n",
      "16800/16800 [==============================] - 4s 246us/sample - loss: 1.0163 - output1_loss: 0.3981 - output2_loss: 0.6092 - output1_accuracy: 0.8274 - output1_mean_absolute_error: 0.2512 - output2_accuracy: 0.6657 - output2_mean_absolute_error: 0.4221 - val_loss: 1.1201 - val_output1_loss: 0.4543 - val_output2_loss: 0.6570 - val_output1_accuracy: 0.8117 - val_output1_mean_absolute_error: 0.2638 - val_output2_accuracy: 0.6162 - val_output2_mean_absolute_error: 0.4424\n",
      "Epoch 177/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0130 - output1_loss: 0.3951 - output2_loss: 0.6082 - output1_accuracy: 0.8321 - output1_mean_absolute_error: 0.2487 - output2_accuracy: 0.6695 - output2_mean_absolute_error: 0.4212 - val_loss: 1.1183 - val_output1_loss: 0.4548 - val_output2_loss: 0.6529 - val_output1_accuracy: 0.8067 - val_output1_mean_absolute_error: 0.2612 - val_output2_accuracy: 0.6217 - val_output2_mean_absolute_error: 0.4437\n",
      "Epoch 178/250\n",
      "16800/16800 [==============================] - 4s 249us/sample - loss: 1.0166 - output1_loss: 0.3971 - output2_loss: 0.6097 - output1_accuracy: 0.8283 - output1_mean_absolute_error: 0.2503 - output2_accuracy: 0.6668 - output2_mean_absolute_error: 0.4231 - val_loss: 1.1193 - val_output1_loss: 0.4546 - val_output2_loss: 0.6547 - val_output1_accuracy: 0.8088 - val_output1_mean_absolute_error: 0.2569 - val_output2_accuracy: 0.6257 - val_output2_mean_absolute_error: 0.4439\n",
      "Epoch 179/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0167 - output1_loss: 0.3981 - output2_loss: 0.6094 - output1_accuracy: 0.8276 - output1_mean_absolute_error: 0.2488 - output2_accuracy: 0.6672 - output2_mean_absolute_error: 0.4225 - val_loss: 1.1185 - val_output1_loss: 0.4538 - val_output2_loss: 0.6547 - val_output1_accuracy: 0.8081 - val_output1_mean_absolute_error: 0.2671 - val_output2_accuracy: 0.6217 - val_output2_mean_absolute_error: 0.4457\n",
      "Epoch 180/250\n",
      "16800/16800 [==============================] - 4s 240us/sample - loss: 1.0135 - output1_loss: 0.3970 - output2_loss: 0.6069 - output1_accuracy: 0.8307 - output1_mean_absolute_error: 0.2504 - output2_accuracy: 0.6696 - output2_mean_absolute_error: 0.4202 - val_loss: 1.1185 - val_output1_loss: 0.4543 - val_output2_loss: 0.6545 - val_output1_accuracy: 0.8110 - val_output1_mean_absolute_error: 0.2645 - val_output2_accuracy: 0.6207 - val_output2_mean_absolute_error: 0.4447\n",
      "Epoch 181/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0145 - output1_loss: 0.3944 - output2_loss: 0.6105 - output1_accuracy: 0.8291 - output1_mean_absolute_error: 0.2488 - output2_accuracy: 0.6654 - output2_mean_absolute_error: 0.4238 - val_loss: 1.1205 - val_output1_loss: 0.4544 - val_output2_loss: 0.6571 - val_output1_accuracy: 0.8071 - val_output1_mean_absolute_error: 0.2653 - val_output2_accuracy: 0.6214 - val_output2_mean_absolute_error: 0.4414\n",
      "Epoch 182/250\n",
      "16800/16800 [==============================] - 4s 251us/sample - loss: 1.0194 - output1_loss: 0.3984 - output2_loss: 0.6111 - output1_accuracy: 0.8292 - output1_mean_absolute_error: 0.2499 - output2_accuracy: 0.6623 - output2_mean_absolute_error: 0.4236 - val_loss: 1.1163 - val_output1_loss: 0.4518 - val_output2_loss: 0.6544 - val_output1_accuracy: 0.8069 - val_output1_mean_absolute_error: 0.2688 - val_output2_accuracy: 0.6243 - val_output2_mean_absolute_error: 0.4419\n",
      "Epoch 183/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0127 - output1_loss: 0.3947 - output2_loss: 0.6083 - output1_accuracy: 0.8299 - output1_mean_absolute_error: 0.2492 - output2_accuracy: 0.6677 - output2_mean_absolute_error: 0.4210 - val_loss: 1.1195 - val_output1_loss: 0.4559 - val_output2_loss: 0.6538 - val_output1_accuracy: 0.8095 - val_output1_mean_absolute_error: 0.2581 - val_output2_accuracy: 0.6257 - val_output2_mean_absolute_error: 0.4430\n",
      "Epoch 184/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0134 - output1_loss: 0.3977 - output2_loss: 0.6067 - output1_accuracy: 0.8282 - output1_mean_absolute_error: 0.2495 - output2_accuracy: 0.6662 - output2_mean_absolute_error: 0.4207 - val_loss: 1.1214 - val_output1_loss: 0.4579 - val_output2_loss: 0.6543 - val_output1_accuracy: 0.8110 - val_output1_mean_absolute_error: 0.2584 - val_output2_accuracy: 0.6214 - val_output2_mean_absolute_error: 0.4429\n",
      "Epoch 185/250\n",
      "16800/16800 [==============================] - 4s 249us/sample - loss: 1.0130 - output1_loss: 0.3955 - output2_loss: 0.6074 - output1_accuracy: 0.8298 - output1_mean_absolute_error: 0.2499 - output2_accuracy: 0.6663 - output2_mean_absolute_error: 0.4203 - val_loss: 1.1181 - val_output1_loss: 0.4555 - val_output2_loss: 0.6529 - val_output1_accuracy: 0.8074 - val_output1_mean_absolute_error: 0.2602 - val_output2_accuracy: 0.6229 - val_output2_mean_absolute_error: 0.4444\n",
      "Epoch 186/250\n",
      "16800/16800 [==============================] - 4s 247us/sample - loss: 1.0176 - output1_loss: 0.3977 - output2_loss: 0.6103 - output1_accuracy: 0.8293 - output1_mean_absolute_error: 0.2490 - output2_accuracy: 0.6654 - output2_mean_absolute_error: 0.4238 - val_loss: 1.1172 - val_output1_loss: 0.4564 - val_output2_loss: 0.6518 - val_output1_accuracy: 0.8079 - val_output1_mean_absolute_error: 0.2648 - val_output2_accuracy: 0.6240 - val_output2_mean_absolute_error: 0.4427\n",
      "Epoch 187/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0148 - output1_loss: 0.3969 - output2_loss: 0.6079 - output1_accuracy: 0.8279 - output1_mean_absolute_error: 0.2490 - output2_accuracy: 0.6683 - output2_mean_absolute_error: 0.4205 - val_loss: 1.1181 - val_output1_loss: 0.4557 - val_output2_loss: 0.6541 - val_output1_accuracy: 0.8071 - val_output1_mean_absolute_error: 0.2712 - val_output2_accuracy: 0.6183 - val_output2_mean_absolute_error: 0.4481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/250\n",
      "16800/16800 [==============================] - 4s 239us/sample - loss: 1.0152 - output1_loss: 0.3971 - output2_loss: 0.6084 - output1_accuracy: 0.8298 - output1_mean_absolute_error: 0.2498 - output2_accuracy: 0.6666 - output2_mean_absolute_error: 0.4225 - val_loss: 1.1170 - val_output1_loss: 0.4533 - val_output2_loss: 0.6533 - val_output1_accuracy: 0.8088 - val_output1_mean_absolute_error: 0.2653 - val_output2_accuracy: 0.6240 - val_output2_mean_absolute_error: 0.4449\n",
      "Epoch 189/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0141 - output1_loss: 0.3962 - output2_loss: 0.6079 - output1_accuracy: 0.8290 - output1_mean_absolute_error: 0.2497 - output2_accuracy: 0.6676 - output2_mean_absolute_error: 0.4214 - val_loss: 1.1211 - val_output1_loss: 0.4583 - val_output2_loss: 0.6528 - val_output1_accuracy: 0.8090 - val_output1_mean_absolute_error: 0.2625 - val_output2_accuracy: 0.6198 - val_output2_mean_absolute_error: 0.4456\n",
      "Epoch 190/250\n",
      "16800/16800 [==============================] - 4s 248us/sample - loss: 1.0154 - output1_loss: 0.3966 - output2_loss: 0.6088 - output1_accuracy: 0.8304 - output1_mean_absolute_error: 0.2487 - output2_accuracy: 0.6683 - output2_mean_absolute_error: 0.4220 - val_loss: 1.1182 - val_output1_loss: 0.4559 - val_output2_loss: 0.6524 - val_output1_accuracy: 0.8098 - val_output1_mean_absolute_error: 0.2589 - val_output2_accuracy: 0.6217 - val_output2_mean_absolute_error: 0.4446\n",
      "Epoch 191/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0164 - output1_loss: 0.3963 - output2_loss: 0.6103 - output1_accuracy: 0.8289 - output1_mean_absolute_error: 0.2487 - output2_accuracy: 0.6666 - output2_mean_absolute_error: 0.4234 - val_loss: 1.1210 - val_output1_loss: 0.4576 - val_output2_loss: 0.6537 - val_output1_accuracy: 0.8064 - val_output1_mean_absolute_error: 0.2670 - val_output2_accuracy: 0.6183 - val_output2_mean_absolute_error: 0.4436\n",
      "Epoch 192/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0151 - output1_loss: 0.3994 - output2_loss: 0.6057 - output1_accuracy: 0.8285 - output1_mean_absolute_error: 0.2504 - output2_accuracy: 0.6670 - output2_mean_absolute_error: 0.4203 - val_loss: 1.1127 - val_output1_loss: 0.4522 - val_output2_loss: 0.6499 - val_output1_accuracy: 0.8062 - val_output1_mean_absolute_error: 0.2681 - val_output2_accuracy: 0.6224 - val_output2_mean_absolute_error: 0.4435\n",
      "Epoch 193/250\n",
      "16800/16800 [==============================] - 4s 251us/sample - loss: 1.0125 - output1_loss: 0.3959 - output2_loss: 0.6069 - output1_accuracy: 0.8287 - output1_mean_absolute_error: 0.2491 - output2_accuracy: 0.6713 - output2_mean_absolute_error: 0.4206 - val_loss: 1.1207 - val_output1_loss: 0.4571 - val_output2_loss: 0.6546 - val_output1_accuracy: 0.8064 - val_output1_mean_absolute_error: 0.2694 - val_output2_accuracy: 0.6236 - val_output2_mean_absolute_error: 0.4397\n",
      "Epoch 194/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0119 - output1_loss: 0.3953 - output2_loss: 0.6070 - output1_accuracy: 0.8275 - output1_mean_absolute_error: 0.2489 - output2_accuracy: 0.6715 - output2_mean_absolute_error: 0.4197 - val_loss: 1.1219 - val_output1_loss: 0.4561 - val_output2_loss: 0.6556 - val_output1_accuracy: 0.8083 - val_output1_mean_absolute_error: 0.2665 - val_output2_accuracy: 0.6162 - val_output2_mean_absolute_error: 0.4430\n",
      "Epoch 195/250\n",
      "16800/16800 [==============================] - 4s 247us/sample - loss: 1.0163 - output1_loss: 0.3977 - output2_loss: 0.6085 - output1_accuracy: 0.8296 - output1_mean_absolute_error: 0.2498 - output2_accuracy: 0.6685 - output2_mean_absolute_error: 0.4222 - val_loss: 1.1212 - val_output1_loss: 0.4572 - val_output2_loss: 0.6547 - val_output1_accuracy: 0.8067 - val_output1_mean_absolute_error: 0.2649 - val_output2_accuracy: 0.6252 - val_output2_mean_absolute_error: 0.4384\n",
      "Epoch 196/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0137 - output1_loss: 0.3963 - output2_loss: 0.6076 - output1_accuracy: 0.8286 - output1_mean_absolute_error: 0.2497 - output2_accuracy: 0.6662 - output2_mean_absolute_error: 0.4209 - val_loss: 1.1236 - val_output1_loss: 0.4591 - val_output2_loss: 0.6544 - val_output1_accuracy: 0.8102 - val_output1_mean_absolute_error: 0.2596 - val_output2_accuracy: 0.6193 - val_output2_mean_absolute_error: 0.4394\n",
      "Epoch 197/250\n",
      "16800/16800 [==============================] - 4s 249us/sample - loss: 1.0152 - output1_loss: 0.3977 - output2_loss: 0.6074 - output1_accuracy: 0.8295 - output1_mean_absolute_error: 0.2493 - output2_accuracy: 0.6677 - output2_mean_absolute_error: 0.4199 - val_loss: 1.1279 - val_output1_loss: 0.4625 - val_output2_loss: 0.6550 - val_output1_accuracy: 0.8057 - val_output1_mean_absolute_error: 0.2696 - val_output2_accuracy: 0.6200 - val_output2_mean_absolute_error: 0.4425\n",
      "Epoch 198/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0157 - output1_loss: 0.3968 - output2_loss: 0.6086 - output1_accuracy: 0.8276 - output1_mean_absolute_error: 0.2495 - output2_accuracy: 0.6695 - output2_mean_absolute_error: 0.4219 - val_loss: 1.1232 - val_output1_loss: 0.4579 - val_output2_loss: 0.6568 - val_output1_accuracy: 0.8048 - val_output1_mean_absolute_error: 0.2749 - val_output2_accuracy: 0.6236 - val_output2_mean_absolute_error: 0.4418\n",
      "Epoch 199/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0139 - output1_loss: 0.3953 - output2_loss: 0.6084 - output1_accuracy: 0.8298 - output1_mean_absolute_error: 0.2489 - output2_accuracy: 0.6654 - output2_mean_absolute_error: 0.4217 - val_loss: 1.1221 - val_output1_loss: 0.4576 - val_output2_loss: 0.6530 - val_output1_accuracy: 0.8121 - val_output1_mean_absolute_error: 0.2624 - val_output2_accuracy: 0.6210 - val_output2_mean_absolute_error: 0.4432\n",
      "Epoch 200/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0115 - output1_loss: 0.3944 - output2_loss: 0.6072 - output1_accuracy: 0.8321 - output1_mean_absolute_error: 0.2476 - output2_accuracy: 0.6697 - output2_mean_absolute_error: 0.4200 - val_loss: 1.1228 - val_output1_loss: 0.4618 - val_output2_loss: 0.6518 - val_output1_accuracy: 0.8017 - val_output1_mean_absolute_error: 0.2727 - val_output2_accuracy: 0.6279 - val_output2_mean_absolute_error: 0.4396\n",
      "Epoch 201/250\n",
      "16800/16800 [==============================] - 4s 249us/sample - loss: 1.0107 - output1_loss: 0.3952 - output2_loss: 0.6056 - output1_accuracy: 0.8307 - output1_mean_absolute_error: 0.2493 - output2_accuracy: 0.6709 - output2_mean_absolute_error: 0.4190 - val_loss: 1.1188 - val_output1_loss: 0.4580 - val_output2_loss: 0.6505 - val_output1_accuracy: 0.8088 - val_output1_mean_absolute_error: 0.2627 - val_output2_accuracy: 0.6302 - val_output2_mean_absolute_error: 0.4400\n",
      "Epoch 202/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0145 - output1_loss: 0.3972 - output2_loss: 0.6071 - output1_accuracy: 0.8290 - output1_mean_absolute_error: 0.2498 - output2_accuracy: 0.6665 - output2_mean_absolute_error: 0.4205 - val_loss: 1.1183 - val_output1_loss: 0.4567 - val_output2_loss: 0.6509 - val_output1_accuracy: 0.8086 - val_output1_mean_absolute_error: 0.2716 - val_output2_accuracy: 0.6243 - val_output2_mean_absolute_error: 0.4439\n",
      "Epoch 203/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0117 - output1_loss: 0.3958 - output2_loss: 0.6057 - output1_accuracy: 0.8293 - output1_mean_absolute_error: 0.2485 - output2_accuracy: 0.6693 - output2_mean_absolute_error: 0.4203 - val_loss: 1.1212 - val_output1_loss: 0.4565 - val_output2_loss: 0.6543 - val_output1_accuracy: 0.8062 - val_output1_mean_absolute_error: 0.2746 - val_output2_accuracy: 0.6183 - val_output2_mean_absolute_error: 0.4423\n",
      "Epoch 204/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0136 - output1_loss: 0.3965 - output2_loss: 0.6070 - output1_accuracy: 0.8297 - output1_mean_absolute_error: 0.2501 - output2_accuracy: 0.6689 - output2_mean_absolute_error: 0.4197 - val_loss: 1.1254 - val_output1_loss: 0.4586 - val_output2_loss: 0.6566 - val_output1_accuracy: 0.8069 - val_output1_mean_absolute_error: 0.2700 - val_output2_accuracy: 0.6257 - val_output2_mean_absolute_error: 0.4358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/250\n",
      "16800/16800 [==============================] - 4s 253us/sample - loss: 1.0140 - output1_loss: 0.3965 - output2_loss: 0.6072 - output1_accuracy: 0.8302 - output1_mean_absolute_error: 0.2489 - output2_accuracy: 0.6716 - output2_mean_absolute_error: 0.4199 - val_loss: 1.1250 - val_output1_loss: 0.4594 - val_output2_loss: 0.6547 - val_output1_accuracy: 0.8095 - val_output1_mean_absolute_error: 0.2601 - val_output2_accuracy: 0.6224 - val_output2_mean_absolute_error: 0.4419\n",
      "Epoch 206/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0084 - output1_loss: 0.3949 - output2_loss: 0.6036 - output1_accuracy: 0.8308 - output1_mean_absolute_error: 0.2479 - output2_accuracy: 0.6710 - output2_mean_absolute_error: 0.4182 - val_loss: 1.1282 - val_output1_loss: 0.4578 - val_output2_loss: 0.6588 - val_output1_accuracy: 0.8090 - val_output1_mean_absolute_error: 0.2619 - val_output2_accuracy: 0.6221 - val_output2_mean_absolute_error: 0.4360\n",
      "Epoch 207/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0136 - output1_loss: 0.3956 - output2_loss: 0.6079 - output1_accuracy: 0.8300 - output1_mean_absolute_error: 0.2488 - output2_accuracy: 0.6671 - output2_mean_absolute_error: 0.4188 - val_loss: 1.1204 - val_output1_loss: 0.4575 - val_output2_loss: 0.6521 - val_output1_accuracy: 0.8088 - val_output1_mean_absolute_error: 0.2657 - val_output2_accuracy: 0.6231 - val_output2_mean_absolute_error: 0.4429\n",
      "Epoch 208/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0146 - output1_loss: 0.3984 - output2_loss: 0.6067 - output1_accuracy: 0.8304 - output1_mean_absolute_error: 0.2496 - output2_accuracy: 0.6704 - output2_mean_absolute_error: 0.4205 - val_loss: 1.1233 - val_output1_loss: 0.4592 - val_output2_loss: 0.6538 - val_output1_accuracy: 0.8105 - val_output1_mean_absolute_error: 0.2624 - val_output2_accuracy: 0.6214 - val_output2_mean_absolute_error: 0.4421\n",
      "Epoch 209/250\n",
      "16800/16800 [==============================] - 4s 252us/sample - loss: 1.0118 - output1_loss: 0.3960 - output2_loss: 0.6057 - output1_accuracy: 0.8293 - output1_mean_absolute_error: 0.2502 - output2_accuracy: 0.6701 - output2_mean_absolute_error: 0.4195 - val_loss: 1.1239 - val_output1_loss: 0.4597 - val_output2_loss: 0.6554 - val_output1_accuracy: 0.8119 - val_output1_mean_absolute_error: 0.2609 - val_output2_accuracy: 0.6217 - val_output2_mean_absolute_error: 0.4439\n",
      "Epoch 210/250\n",
      "16800/16800 [==============================] - 4s 240us/sample - loss: 1.0126 - output1_loss: 0.3960 - output2_loss: 0.6068 - output1_accuracy: 0.8292 - output1_mean_absolute_error: 0.2482 - output2_accuracy: 0.6678 - output2_mean_absolute_error: 0.4200 - val_loss: 1.1217 - val_output1_loss: 0.4571 - val_output2_loss: 0.6548 - val_output1_accuracy: 0.8076 - val_output1_mean_absolute_error: 0.2655 - val_output2_accuracy: 0.6207 - val_output2_mean_absolute_error: 0.4436\n",
      "Epoch 211/250\n",
      "16800/16800 [==============================] - 4s 241us/sample - loss: 1.0123 - output1_loss: 0.3950 - output2_loss: 0.6074 - output1_accuracy: 0.8298 - output1_mean_absolute_error: 0.2492 - output2_accuracy: 0.6678 - output2_mean_absolute_error: 0.4204 - val_loss: 1.1268 - val_output1_loss: 0.4620 - val_output2_loss: 0.6545 - val_output1_accuracy: 0.8117 - val_output1_mean_absolute_error: 0.2538 - val_output2_accuracy: 0.6245 - val_output2_mean_absolute_error: 0.4425\n",
      "Epoch 212/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0103 - output1_loss: 0.3937 - output2_loss: 0.6067 - output1_accuracy: 0.8314 - output1_mean_absolute_error: 0.2463 - output2_accuracy: 0.6657 - output2_mean_absolute_error: 0.4204 - val_loss: 1.1228 - val_output1_loss: 0.4590 - val_output2_loss: 0.6540 - val_output1_accuracy: 0.8095 - val_output1_mean_absolute_error: 0.2628 - val_output2_accuracy: 0.6262 - val_output2_mean_absolute_error: 0.4411\n",
      "Epoch 213/250\n",
      "16800/16800 [==============================] - 4s 251us/sample - loss: 1.0137 - output1_loss: 0.3962 - output2_loss: 0.6067 - output1_accuracy: 0.8299 - output1_mean_absolute_error: 0.2492 - output2_accuracy: 0.6664 - output2_mean_absolute_error: 0.4200 - val_loss: 1.1224 - val_output1_loss: 0.4578 - val_output2_loss: 0.6532 - val_output1_accuracy: 0.8093 - val_output1_mean_absolute_error: 0.2627 - val_output2_accuracy: 0.6260 - val_output2_mean_absolute_error: 0.4428\n",
      "Epoch 214/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0128 - output1_loss: 0.3959 - output2_loss: 0.6067 - output1_accuracy: 0.8292 - output1_mean_absolute_error: 0.2485 - output2_accuracy: 0.6699 - output2_mean_absolute_error: 0.4206 - val_loss: 1.1240 - val_output1_loss: 0.4617 - val_output2_loss: 0.6528 - val_output1_accuracy: 0.8069 - val_output1_mean_absolute_error: 0.2681 - val_output2_accuracy: 0.6243 - val_output2_mean_absolute_error: 0.4409\n",
      "Epoch 215/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0125 - output1_loss: 0.3965 - output2_loss: 0.6061 - output1_accuracy: 0.8292 - output1_mean_absolute_error: 0.2489 - output2_accuracy: 0.6703 - output2_mean_absolute_error: 0.4194 - val_loss: 1.1229 - val_output1_loss: 0.4594 - val_output2_loss: 0.6545 - val_output1_accuracy: 0.8098 - val_output1_mean_absolute_error: 0.2687 - val_output2_accuracy: 0.6236 - val_output2_mean_absolute_error: 0.4441\n",
      "Epoch 216/250\n",
      "16800/16800 [==============================] - 4s 246us/sample - loss: 1.0139 - output1_loss: 0.3959 - output2_loss: 0.6076 - output1_accuracy: 0.8318 - output1_mean_absolute_error: 0.2488 - output2_accuracy: 0.6678 - output2_mean_absolute_error: 0.4212 - val_loss: 1.1246 - val_output1_loss: 0.4587 - val_output2_loss: 0.6564 - val_output1_accuracy: 0.8107 - val_output1_mean_absolute_error: 0.2623 - val_output2_accuracy: 0.6221 - val_output2_mean_absolute_error: 0.4415\n",
      "Epoch 217/250\n",
      "16800/16800 [==============================] - 4s 247us/sample - loss: 1.0097 - output1_loss: 0.3939 - output2_loss: 0.6055 - output1_accuracy: 0.8315 - output1_mean_absolute_error: 0.2483 - output2_accuracy: 0.6724 - output2_mean_absolute_error: 0.4191 - val_loss: 1.1210 - val_output1_loss: 0.4583 - val_output2_loss: 0.6526 - val_output1_accuracy: 0.8074 - val_output1_mean_absolute_error: 0.2655 - val_output2_accuracy: 0.6267 - val_output2_mean_absolute_error: 0.4445\n",
      "Epoch 218/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0136 - output1_loss: 0.3976 - output2_loss: 0.6063 - output1_accuracy: 0.8333 - output1_mean_absolute_error: 0.2487 - output2_accuracy: 0.6699 - output2_mean_absolute_error: 0.4204 - val_loss: 1.1281 - val_output1_loss: 0.4626 - val_output2_loss: 0.6547 - val_output1_accuracy: 0.8076 - val_output1_mean_absolute_error: 0.2592 - val_output2_accuracy: 0.6205 - val_output2_mean_absolute_error: 0.4420\n",
      "Epoch 219/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0132 - output1_loss: 0.3971 - output2_loss: 0.6058 - output1_accuracy: 0.8293 - output1_mean_absolute_error: 0.2495 - output2_accuracy: 0.6692 - output2_mean_absolute_error: 0.4197 - val_loss: 1.1232 - val_output1_loss: 0.4566 - val_output2_loss: 0.6561 - val_output1_accuracy: 0.8086 - val_output1_mean_absolute_error: 0.2698 - val_output2_accuracy: 0.6248 - val_output2_mean_absolute_error: 0.4384\n",
      "Epoch 220/250\n",
      "16800/16800 [==============================] - 4s 247us/sample - loss: 1.0116 - output1_loss: 0.3959 - output2_loss: 0.6053 - output1_accuracy: 0.8307 - output1_mean_absolute_error: 0.2492 - output2_accuracy: 0.6698 - output2_mean_absolute_error: 0.4193 - val_loss: 1.1245 - val_output1_loss: 0.4586 - val_output2_loss: 0.6547 - val_output1_accuracy: 0.8069 - val_output1_mean_absolute_error: 0.2731 - val_output2_accuracy: 0.6248 - val_output2_mean_absolute_error: 0.4409\n",
      "Epoch 221/250\n",
      "16800/16800 [==============================] - 4s 246us/sample - loss: 1.0119 - output1_loss: 0.3960 - output2_loss: 0.6058 - output1_accuracy: 0.8307 - output1_mean_absolute_error: 0.2486 - output2_accuracy: 0.6699 - output2_mean_absolute_error: 0.4183 - val_loss: 1.1280 - val_output1_loss: 0.4607 - val_output2_loss: 0.6565 - val_output1_accuracy: 0.8100 - val_output1_mean_absolute_error: 0.2641 - val_output2_accuracy: 0.6250 - val_output2_mean_absolute_error: 0.4437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0105 - output1_loss: 0.3948 - output2_loss: 0.6054 - output1_accuracy: 0.8311 - output1_mean_absolute_error: 0.2487 - output2_accuracy: 0.6704 - output2_mean_absolute_error: 0.4187 - val_loss: 1.1259 - val_output1_loss: 0.4581 - val_output2_loss: 0.6578 - val_output1_accuracy: 0.8043 - val_output1_mean_absolute_error: 0.2661 - val_output2_accuracy: 0.6176 - val_output2_mean_absolute_error: 0.4408\n",
      "Epoch 223/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0093 - output1_loss: 0.3961 - output2_loss: 0.6025 - output1_accuracy: 0.8304 - output1_mean_absolute_error: 0.2488 - output2_accuracy: 0.6732 - output2_mean_absolute_error: 0.4181 - val_loss: 1.1246 - val_output1_loss: 0.4558 - val_output2_loss: 0.6581 - val_output1_accuracy: 0.8050 - val_output1_mean_absolute_error: 0.2738 - val_output2_accuracy: 0.6193 - val_output2_mean_absolute_error: 0.4419\n",
      "Epoch 224/250\n",
      "16800/16800 [==============================] - 4s 252us/sample - loss: 1.0078 - output1_loss: 0.3950 - output2_loss: 0.6027 - output1_accuracy: 0.8313 - output1_mean_absolute_error: 0.2489 - output2_accuracy: 0.6729 - output2_mean_absolute_error: 0.4169 - val_loss: 1.1243 - val_output1_loss: 0.4571 - val_output2_loss: 0.6562 - val_output1_accuracy: 0.8095 - val_output1_mean_absolute_error: 0.2633 - val_output2_accuracy: 0.6274 - val_output2_mean_absolute_error: 0.4404\n",
      "Epoch 225/250\n",
      "16800/16800 [==============================] - 4s 247us/sample - loss: 1.0084 - output1_loss: 0.3911 - output2_loss: 0.6068 - output1_accuracy: 0.8317 - output1_mean_absolute_error: 0.2465 - output2_accuracy: 0.6680 - output2_mean_absolute_error: 0.4192 - val_loss: 1.1217 - val_output1_loss: 0.4587 - val_output2_loss: 0.6530 - val_output1_accuracy: 0.8064 - val_output1_mean_absolute_error: 0.2692 - val_output2_accuracy: 0.6269 - val_output2_mean_absolute_error: 0.4428\n",
      "Epoch 226/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0088 - output1_loss: 0.3954 - output2_loss: 0.6033 - output1_accuracy: 0.8308 - output1_mean_absolute_error: 0.2488 - output2_accuracy: 0.6727 - output2_mean_absolute_error: 0.4177 - val_loss: 1.1283 - val_output1_loss: 0.4583 - val_output2_loss: 0.6592 - val_output1_accuracy: 0.8055 - val_output1_mean_absolute_error: 0.2658 - val_output2_accuracy: 0.6257 - val_output2_mean_absolute_error: 0.4384\n",
      "Epoch 227/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0089 - output1_loss: 0.3916 - output2_loss: 0.6065 - output1_accuracy: 0.8332 - output1_mean_absolute_error: 0.2462 - output2_accuracy: 0.6672 - output2_mean_absolute_error: 0.4196 - val_loss: 1.1223 - val_output1_loss: 0.4567 - val_output2_loss: 0.6548 - val_output1_accuracy: 0.8105 - val_output1_mean_absolute_error: 0.2656 - val_output2_accuracy: 0.6240 - val_output2_mean_absolute_error: 0.4400\n",
      "Epoch 228/250\n",
      "16800/16800 [==============================] - 4s 253us/sample - loss: 1.0093 - output1_loss: 0.3923 - output2_loss: 0.6064 - output1_accuracy: 0.8313 - output1_mean_absolute_error: 0.2470 - output2_accuracy: 0.6700 - output2_mean_absolute_error: 0.4190 - val_loss: 1.1250 - val_output1_loss: 0.4593 - val_output2_loss: 0.6559 - val_output1_accuracy: 0.8074 - val_output1_mean_absolute_error: 0.2685 - val_output2_accuracy: 0.6269 - val_output2_mean_absolute_error: 0.4409\n",
      "Epoch 229/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0075 - output1_loss: 0.3953 - output2_loss: 0.6015 - output1_accuracy: 0.8299 - output1_mean_absolute_error: 0.2483 - output2_accuracy: 0.6744 - output2_mean_absolute_error: 0.4168 - val_loss: 1.1272 - val_output1_loss: 0.4565 - val_output2_loss: 0.6597 - val_output1_accuracy: 0.8076 - val_output1_mean_absolute_error: 0.2682 - val_output2_accuracy: 0.6255 - val_output2_mean_absolute_error: 0.4401\n",
      "Epoch 230/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0087 - output1_loss: 0.3947 - output2_loss: 0.6036 - output1_accuracy: 0.8309 - output1_mean_absolute_error: 0.2480 - output2_accuracy: 0.6713 - output2_mean_absolute_error: 0.4168 - val_loss: 1.1289 - val_output1_loss: 0.4624 - val_output2_loss: 0.6560 - val_output1_accuracy: 0.8069 - val_output1_mean_absolute_error: 0.2614 - val_output2_accuracy: 0.6198 - val_output2_mean_absolute_error: 0.4435\n",
      "Epoch 231/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0094 - output1_loss: 0.3938 - output2_loss: 0.6054 - output1_accuracy: 0.8294 - output1_mean_absolute_error: 0.2478 - output2_accuracy: 0.6679 - output2_mean_absolute_error: 0.4193 - val_loss: 1.1236 - val_output1_loss: 0.4565 - val_output2_loss: 0.6568 - val_output1_accuracy: 0.8090 - val_output1_mean_absolute_error: 0.2663 - val_output2_accuracy: 0.6205 - val_output2_mean_absolute_error: 0.4420\n",
      "Epoch 232/250\n",
      "16800/16800 [==============================] - 4s 251us/sample - loss: 1.0078 - output1_loss: 0.3942 - output2_loss: 0.6035 - output1_accuracy: 0.8318 - output1_mean_absolute_error: 0.2478 - output2_accuracy: 0.6726 - output2_mean_absolute_error: 0.4179 - val_loss: 1.1280 - val_output1_loss: 0.4605 - val_output2_loss: 0.6571 - val_output1_accuracy: 0.8090 - val_output1_mean_absolute_error: 0.2614 - val_output2_accuracy: 0.6226 - val_output2_mean_absolute_error: 0.4367\n",
      "Epoch 233/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0085 - output1_loss: 0.3959 - output2_loss: 0.6020 - output1_accuracy: 0.8304 - output1_mean_absolute_error: 0.2486 - output2_accuracy: 0.6721 - output2_mean_absolute_error: 0.4172 - val_loss: 1.1253 - val_output1_loss: 0.4589 - val_output2_loss: 0.6557 - val_output1_accuracy: 0.8088 - val_output1_mean_absolute_error: 0.2671 - val_output2_accuracy: 0.6210 - val_output2_mean_absolute_error: 0.4390\n",
      "Epoch 234/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0118 - output1_loss: 0.3949 - output2_loss: 0.6065 - output1_accuracy: 0.8280 - output1_mean_absolute_error: 0.2498 - output2_accuracy: 0.6717 - output2_mean_absolute_error: 0.4183 - val_loss: 1.1277 - val_output1_loss: 0.4582 - val_output2_loss: 0.6580 - val_output1_accuracy: 0.8090 - val_output1_mean_absolute_error: 0.2695 - val_output2_accuracy: 0.6271 - val_output2_mean_absolute_error: 0.4364\n",
      "Epoch 235/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0079 - output1_loss: 0.3948 - output2_loss: 0.6026 - output1_accuracy: 0.8317 - output1_mean_absolute_error: 0.2479 - output2_accuracy: 0.6695 - output2_mean_absolute_error: 0.4170 - val_loss: 1.1264 - val_output1_loss: 0.4578 - val_output2_loss: 0.6575 - val_output1_accuracy: 0.8138 - val_output1_mean_absolute_error: 0.2586 - val_output2_accuracy: 0.6262 - val_output2_mean_absolute_error: 0.4404\n",
      "Epoch 236/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0047 - output1_loss: 0.3912 - output2_loss: 0.6030 - output1_accuracy: 0.8326 - output1_mean_absolute_error: 0.2462 - output2_accuracy: 0.6720 - output2_mean_absolute_error: 0.4166 - val_loss: 1.1286 - val_output1_loss: 0.4596 - val_output2_loss: 0.6578 - val_output1_accuracy: 0.8093 - val_output1_mean_absolute_error: 0.2666 - val_output2_accuracy: 0.6221 - val_output2_mean_absolute_error: 0.4394\n",
      "Epoch 237/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0087 - output1_loss: 0.3947 - output2_loss: 0.6034 - output1_accuracy: 0.8316 - output1_mean_absolute_error: 0.2474 - output2_accuracy: 0.6729 - output2_mean_absolute_error: 0.4173 - val_loss: 1.1249 - val_output1_loss: 0.4597 - val_output2_loss: 0.6541 - val_output1_accuracy: 0.8090 - val_output1_mean_absolute_error: 0.2691 - val_output2_accuracy: 0.6207 - val_output2_mean_absolute_error: 0.4424\n",
      "Epoch 238/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0129 - output1_loss: 0.3947 - output2_loss: 0.6074 - output1_accuracy: 0.8289 - output1_mean_absolute_error: 0.2484 - output2_accuracy: 0.6680 - output2_mean_absolute_error: 0.4195 - val_loss: 1.1222 - val_output1_loss: 0.4557 - val_output2_loss: 0.6546 - val_output1_accuracy: 0.8081 - val_output1_mean_absolute_error: 0.2671 - val_output2_accuracy: 0.6226 - val_output2_mean_absolute_error: 0.4423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/250\n",
      "16800/16800 [==============================] - 4s 242us/sample - loss: 1.0073 - output1_loss: 0.3932 - output2_loss: 0.6039 - output1_accuracy: 0.8302 - output1_mean_absolute_error: 0.2478 - output2_accuracy: 0.6724 - output2_mean_absolute_error: 0.4182 - val_loss: 1.1244 - val_output1_loss: 0.4577 - val_output2_loss: 0.6550 - val_output1_accuracy: 0.8060 - val_output1_mean_absolute_error: 0.2746 - val_output2_accuracy: 0.6188 - val_output2_mean_absolute_error: 0.4407\n",
      "Epoch 240/250\n",
      "16800/16800 [==============================] - 4s 248us/sample - loss: 1.0039 - output1_loss: 0.3911 - output2_loss: 0.6017 - output1_accuracy: 0.8321 - output1_mean_absolute_error: 0.2471 - output2_accuracy: 0.6704 - output2_mean_absolute_error: 0.4170 - val_loss: 1.1350 - val_output1_loss: 0.4622 - val_output2_loss: 0.6620 - val_output1_accuracy: 0.8083 - val_output1_mean_absolute_error: 0.2622 - val_output2_accuracy: 0.6214 - val_output2_mean_absolute_error: 0.4385\n",
      "Epoch 241/250\n",
      "16800/16800 [==============================] - 4s 245us/sample - loss: 1.0082 - output1_loss: 0.3949 - output2_loss: 0.6029 - output1_accuracy: 0.8307 - output1_mean_absolute_error: 0.2478 - output2_accuracy: 0.6708 - output2_mean_absolute_error: 0.4167 - val_loss: 1.1265 - val_output1_loss: 0.4596 - val_output2_loss: 0.6563 - val_output1_accuracy: 0.8076 - val_output1_mean_absolute_error: 0.2591 - val_output2_accuracy: 0.6231 - val_output2_mean_absolute_error: 0.4409\n",
      "Epoch 242/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0118 - output1_loss: 0.3943 - output2_loss: 0.6068 - output1_accuracy: 0.8301 - output1_mean_absolute_error: 0.2472 - output2_accuracy: 0.6648 - output2_mean_absolute_error: 0.4195 - val_loss: 1.1244 - val_output1_loss: 0.4606 - val_output2_loss: 0.6525 - val_output1_accuracy: 0.8076 - val_output1_mean_absolute_error: 0.2669 - val_output2_accuracy: 0.6210 - val_output2_mean_absolute_error: 0.4427\n",
      "Epoch 243/250\n",
      "16800/16800 [==============================] - 4s 244us/sample - loss: 1.0064 - output1_loss: 0.3927 - output2_loss: 0.6028 - output1_accuracy: 0.8311 - output1_mean_absolute_error: 0.2473 - output2_accuracy: 0.6749 - output2_mean_absolute_error: 0.4171 - val_loss: 1.1293 - val_output1_loss: 0.4605 - val_output2_loss: 0.6582 - val_output1_accuracy: 0.8110 - val_output1_mean_absolute_error: 0.2636 - val_output2_accuracy: 0.6248 - val_output2_mean_absolute_error: 0.4397\n",
      "Epoch 244/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0057 - output1_loss: 0.3906 - output2_loss: 0.6043 - output1_accuracy: 0.8323 - output1_mean_absolute_error: 0.2462 - output2_accuracy: 0.6701 - output2_mean_absolute_error: 0.4176 - val_loss: 1.1268 - val_output1_loss: 0.4609 - val_output2_loss: 0.6565 - val_output1_accuracy: 0.8079 - val_output1_mean_absolute_error: 0.2617 - val_output2_accuracy: 0.6169 - val_output2_mean_absolute_error: 0.4417\n",
      "Epoch 245/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0076 - output1_loss: 0.3958 - output2_loss: 0.6011 - output1_accuracy: 0.8311 - output1_mean_absolute_error: 0.2472 - output2_accuracy: 0.6712 - output2_mean_absolute_error: 0.4162 - val_loss: 1.1275 - val_output1_loss: 0.4588 - val_output2_loss: 0.6578 - val_output1_accuracy: 0.8071 - val_output1_mean_absolute_error: 0.2697 - val_output2_accuracy: 0.6224 - val_output2_mean_absolute_error: 0.4423\n",
      "Epoch 246/250\n",
      "16800/16800 [==============================] - 4s 243us/sample - loss: 1.0075 - output1_loss: 0.3939 - output2_loss: 0.6031 - output1_accuracy: 0.8335 - output1_mean_absolute_error: 0.2473 - output2_accuracy: 0.6726 - output2_mean_absolute_error: 0.4166 - val_loss: 1.1280 - val_output1_loss: 0.4609 - val_output2_loss: 0.6565 - val_output1_accuracy: 0.8071 - val_output1_mean_absolute_error: 0.2618 - val_output2_accuracy: 0.6250 - val_output2_mean_absolute_error: 0.4438\n",
      "Epoch 247/250\n",
      "16800/16800 [==============================] - 4s 256us/sample - loss: 1.0091 - output1_loss: 0.3939 - output2_loss: 0.6046 - output1_accuracy: 0.8290 - output1_mean_absolute_error: 0.2472 - output2_accuracy: 0.6698 - output2_mean_absolute_error: 0.4180 - val_loss: 1.1257 - val_output1_loss: 0.4568 - val_output2_loss: 0.6571 - val_output1_accuracy: 0.8093 - val_output1_mean_absolute_error: 0.2688 - val_output2_accuracy: 0.6171 - val_output2_mean_absolute_error: 0.4412\n",
      "Epoch 248/250\n",
      "16800/16800 [==============================] - 4s 266us/sample - loss: 1.0073 - output1_loss: 0.3920 - output2_loss: 0.6043 - output1_accuracy: 0.8327 - output1_mean_absolute_error: 0.2459 - output2_accuracy: 0.6738 - output2_mean_absolute_error: 0.4178 - val_loss: 1.1299 - val_output1_loss: 0.4628 - val_output2_loss: 0.6572 - val_output1_accuracy: 0.8024 - val_output1_mean_absolute_error: 0.2736 - val_output2_accuracy: 0.6138 - val_output2_mean_absolute_error: 0.4422\n",
      "Epoch 249/250\n",
      "16800/16800 [==============================] - 4s 252us/sample - loss: 1.0077 - output1_loss: 0.3928 - output2_loss: 0.6042 - output1_accuracy: 0.8304 - output1_mean_absolute_error: 0.2475 - output2_accuracy: 0.6750 - output2_mean_absolute_error: 0.4182 - val_loss: 1.1296 - val_output1_loss: 0.4615 - val_output2_loss: 0.6576 - val_output1_accuracy: 0.8060 - val_output1_mean_absolute_error: 0.2669 - val_output2_accuracy: 0.6150 - val_output2_mean_absolute_error: 0.4459\n",
      "Epoch 250/250\n",
      "16800/16800 [==============================] - 4s 250us/sample - loss: 1.0050 - output1_loss: 0.3923 - output2_loss: 0.6019 - output1_accuracy: 0.8318 - output1_mean_absolute_error: 0.2468 - output2_accuracy: 0.6739 - output2_mean_absolute_error: 0.4167 - val_loss: 1.1296 - val_output1_loss: 0.4612 - val_output2_loss: 0.6586 - val_output1_accuracy: 0.8081 - val_output1_mean_absolute_error: 0.2655 - val_output2_accuracy: 0.6229 - val_output2_mean_absolute_error: 0.4401\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=orthogonal_loss,\n",
    "    optimizer='adam',\n",
    "    metrics=[\"accuracy\", \"mean_absolute_error\"]\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, [Y_train, sex_train] , batch_size=64, epochs=250, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3df68ea",
   "metadata": {},
   "source": [
    "# Get metrics on new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1be6d636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netwo\\anaconda3\\envs\\Thesis-minimum\\lib\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "# Scores on test set\n",
    "test_scores = model.predict(x_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afb51a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0657366 ],\n",
       "       [0.22863008],\n",
       "       [0.14244564],\n",
       "       ...,\n",
       "       [0.50963557],\n",
       "       [0.02086125],\n",
       "       [0.05090822]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "193046f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348078475456594"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train AUC\n",
    "roc_auc_score(Y_train, model.predict(x_train)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c144b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions (0 or 1) on test set\n",
    "test_preds = (test_scores >= np.mean(Y_test)) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24a18f1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netwo\\anaconda3\\envs\\Thesis-minimum\\lib\\site-packages\\fairlearn\\metrics\\_metric_frame.py:63: FutureWarning: You have provided 'metrics', 'y_true', 'y_pred' as positional arguments. Please pass them as keyword arguments. From version 0.10.0 passing them as positional arguments will result in an error.\n",
      "  warnings.warn(f\"You have provided {args_msg} as positional arguments. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.191163</td>\n",
       "      <td>0.399476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.228323</td>\n",
       "      <td>0.400236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             FPR       FNR\n",
       "SEX                       \n",
       "female  0.191163  0.399476\n",
       "male    0.228323  0.400236"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf = MetricFrame({\n",
    "    'FPR': false_positive_rate,\n",
    "    'FNR': false_negative_rate},\n",
    "    Y_test, test_preds, sensitive_features=A_str_test)\n",
    "\n",
    "mf.by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e393952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def get_metrics_df(models_dict, y_true, group):\n",
    "    metrics_dict = {\n",
    "        \"Overall selection rate\": (\n",
    "            lambda x: selection_rate(y_true, x), True),\n",
    "        \"Demographic parity difference\": (\n",
    "            lambda x: demographic_parity_difference(y_true, x, sensitive_features=group), True),\n",
    "        \"Demographic parity ratio\": (\n",
    "            lambda x: demographic_parity_ratio(y_true, x, sensitive_features=group), True),\n",
    "        \"------\": (lambda x: \"\", True),\n",
    "        \"Overall balanced error rate\": (\n",
    "            lambda x: 1-balanced_accuracy_score(y_true, x), True),\n",
    "        \"Balanced error rate difference\": (\n",
    "            lambda x: MetricFrame(metrics=balanced_accuracy_score, y_true=y_true, y_pred=x, sensitive_features=group).difference(method='between_groups'), True),\n",
    "        \" ------\": (lambda x: \"\", True),\n",
    "        \"False positive rate difference\": (\n",
    "            lambda x: false_positive_rate_difference(y_true, x, sensitive_features=group), True),\n",
    "        \"False negative rate difference\": (\n",
    "            lambda x: false_negative_rate_difference(y_true, x, sensitive_features=group), True),\n",
    "        \"Equalized odds difference\": (\n",
    "            lambda x: equalized_odds_difference(y_true, x, sensitive_features=group), True),\n",
    "        \"  ------\": (lambda x: \"\", True),\n",
    "        \"Overall AUC\": (\n",
    "            lambda x: roc_auc_score(y_true, x), False),\n",
    "        \"AUC difference\": (\n",
    "            lambda x: MetricFrame(metrics=roc_auc_score, y_true=y_true, y_pred=x, sensitive_features=group).difference(method='between_groups'), False),\n",
    "    }\n",
    "    df_dict = {}\n",
    "    for metric_name, (metric_func, use_preds) in metrics_dict.items():\n",
    "        df_dict[metric_name] = [metric_func(preds) if use_preds else metric_func(scores) \n",
    "                                for model_name, (preds, scores) in models_dict.items()]\n",
    "    return pd.DataFrame.from_dict(df_dict, orient=\"index\", columns=models_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "436ef7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unmitigated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overall selection rate</th>\n",
       "      <td>0.292556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic parity difference</th>\n",
       "      <td>0.042396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic parity ratio</th>\n",
       "      <td>0.866898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>------</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall balanced error rate</th>\n",
       "      <td>0.302482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced error rate difference</th>\n",
       "      <td>0.01896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>------</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False positive rate difference</th>\n",
       "      <td>0.03716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False negative rate difference</th>\n",
       "      <td>0.000761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalized odds difference</th>\n",
       "      <td>0.03716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>------</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall AUC</th>\n",
       "      <td>0.758403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC difference</th>\n",
       "      <td>0.012576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Unmitigated\n",
       "Overall selection rate            0.292556\n",
       "Demographic parity difference     0.042396\n",
       "Demographic parity ratio          0.866898\n",
       "------                                    \n",
       "Overall balanced error rate       0.302482\n",
       "Balanced error rate difference     0.01896\n",
       " ------                                   \n",
       "False positive rate difference     0.03716\n",
       "False negative rate difference    0.000761\n",
       "Equalized odds difference          0.03716\n",
       "  ------                                  \n",
       "Overall AUC                       0.758403\n",
       "AUC difference                    0.012576"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrics\n",
    "models_dict = {\"Unmitigated\": (test_preds, test_scores)}\n",
    "get_metrics_df(models_dict, Y_test, A_str_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
