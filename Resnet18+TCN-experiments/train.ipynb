{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ec5745-e308-495d-889a-d463769faa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sethupat/.conda/envs/ELIR-p39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c20e248-37eb-4994-865e-d02dbd5e1a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import transforms\n",
    "\n",
    "def generate_dataloader(batch_size, csv, root):\n",
    "    dataset = datasets.VideoDataset(csv,\n",
    "                                    root,\n",
    "                                    transform=torchvision.transforms.Compose([transforms.VideoFolderPathToTensor()]))\n",
    "\n",
    "    return DataLoader(dataset,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      num_workers=2)\n",
    "\n",
    "\n",
    "def get_dataloader(batch_size, csv_train, root_train, csv_test, root_test):\n",
    "    return {\n",
    "        'train': generate_dataloader(batch_size, csv_train, root_train),\n",
    "        'test': generate_dataloader(batch_size, csv_test, root_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e4d96c3-cad9-4bed-9650-9ded9631ca33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce GTX 1080\n",
      "x is on CPU.\n"
     ]
    }
   ],
   "source": [
    "# os.chdir(os.path.join(os.getcwd(),'elearning-teaching-intervention-recommender'))\n",
    "\n",
    "import torch\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the current device (GPU or CPU)\n",
    "    current_device = torch.cuda.current_device()\n",
    "    \n",
    "    # Get the name of the current device\n",
    "    device_name = torch.cuda.get_device_name(current_device)\n",
    "    \n",
    "    print(f\"Using GPU: {device_name}\")\n",
    "else:\n",
    "    print(\"CUDA (GPU support) is not available. Using CPU.\")\n",
    "\n",
    "# Create a tensor and check the device it's on\n",
    "x = torch.tensor([1.0])\n",
    "if x.is_cuda:\n",
    "    print(\"x is on GPU.\")\n",
    "else:\n",
    "    print(\"x is on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280ff21c-6e82-49d4-8b95-dc289e2298db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cuda\n",
      "{'train': 5698, 'test': 1784}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 1/100 Loss: 0.9905852909337516 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 135    1  149   89]\n",
      " [  12    0  134   67]\n",
      " [  41    2 1592  982]\n",
      " [  23    3 1352 1116]]\n",
      "\n",
      "accuracy\t0.49894699894699895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 1/100 Loss: 1.1688555027337353 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  2   0   2   0]\n",
      " [ 22   0  62   0]\n",
      " [190   0 692   0]\n",
      " [174   0 638   2]]\n",
      "\n",
      "accuracy\t0.3901345291479821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 2/100 Loss: 0.899705556138602 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 243    0  114   17]\n",
      " [  12    0  135   66]\n",
      " [  48    0 1737  832]\n",
      " [  28    0 1403 1063]]\n",
      "\n",
      "accuracy\t0.534047034047034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 2/100 Loss: 0.9474060083718577 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  1   0   0   3]\n",
      " [  3   0  26  55]\n",
      " [ 43   0 286 553]\n",
      " [ 40   0 196 578]]\n",
      "\n",
      "accuracy\t0.4848654708520179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 3/100 Loss: 0.8556227897208546 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 297    1   63   13]\n",
      " [  14    0  146   53]\n",
      " [  34    1 1737  845]\n",
      " [  12    0 1418 1064]]\n",
      "\n",
      "accuracy\t0.5436995436995437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 3/100 Loss: 0.8949894230862904 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   0   3   1]\n",
      " [  0   0  23  61]\n",
      " [  1   0 184 697]\n",
      " [  0   0 137 677]]\n",
      "\n",
      "accuracy\t0.4826233183856502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 4/100 Loss: 0.8349948858913516 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 299    4   61   10]\n",
      " [  14    4  140   55]\n",
      " [  16    3 1856  742]\n",
      " [  15    1 1406 1072]]\n",
      "\n",
      "accuracy\t0.567041067041067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 4/100 Loss: 0.9139516300150097 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  1   0   0   3]\n",
      " [  3   0   4  77]\n",
      " [  8   0   5 869]\n",
      " [  4   0   0 810]]\n",
      "\n",
      "accuracy\t0.45739910313901344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 5/100 Loss: 0.7999665517478962 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 335    2   34    3]\n",
      " [  10    4  151   48]\n",
      " [  19    7 1902  689]\n",
      " [   5    1 1428 1060]]\n",
      "\n",
      "accuracy\t0.5793260793260794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 5/100 Loss: 0.8806130441047686 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   0   1   3]\n",
      " [  4   0   8  72]\n",
      " [ 15   0  48 819]\n",
      " [ 10   0  16 788]]\n",
      "\n",
      "accuracy\t0.46860986547085204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 6/100 Loss: 0.7809936280583616 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 356    2   14    2]\n",
      " [   7    4  147   55]\n",
      " [  15    6 1896  700]\n",
      " [   7    2 1381 1104]]\n",
      "\n",
      "accuracy\t0.5896805896805897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 6/100 Loss: 0.8962355405760453 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  1   0   3   0]\n",
      " [  0   0  84   0]\n",
      " [  0   0 882   0]\n",
      " [  1   0 813   0]]\n",
      "\n",
      "accuracy\t0.49495515695067266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 7/100 Loss: 0.7781438563906883 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 352    2   18    2]\n",
      " [  10    3  162   38]\n",
      " [  15    9 1973  620]\n",
      " [   7    1 1433 1053]]\n",
      "\n",
      "accuracy\t0.5933660933660934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 7/100 Loss: 0.8605613189962412 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   0   3   1]\n",
      " [  0   0  73  11]\n",
      " [  0   0 845  37]\n",
      " [  0   0 695 119]]\n",
      "\n",
      "accuracy\t0.5403587443946188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 8/100 Loss: 0.7694208956927993 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 361    0   11    2]\n",
      " [  10    0  165   38]\n",
      " [  10    5 1991  611]\n",
      " [   6    1 1449 1038]]\n",
      "\n",
      "accuracy\t0.594945594945595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 8/100 Loss: 0.8664293346650932 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   0   3   1]\n",
      " [  2   0  70  12]\n",
      " [ 13   0 837  32]\n",
      " [  8   0 703 103]]\n",
      "\n",
      "accuracy\t0.5269058295964125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 9/100 Loss: 0.7491521500273309 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 367    3    4    0]\n",
      " [   9    5  157   42]\n",
      " [   3   11 1962  641]\n",
      " [   6    1 1375 1112]]\n",
      "\n",
      "accuracy\t0.6047736047736048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 9/100 Loss: 0.8418472550241402 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   0   3   1]\n",
      " [  0   0  55  29]\n",
      " [  1   0 671 210]\n",
      " [  0   0 511 303]]\n",
      "\n",
      "accuracy\t0.5459641255605381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 10/100 Loss: 0.7454399747382385 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 356    0   14    4]\n",
      " [   7    9  173   24]\n",
      " [   6   13 2130  468]\n",
      " [   7    0 1447 1040]]\n",
      "\n",
      "accuracy\t0.6203931203931204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 10/100 Loss: 0.8862481348450408 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   0   4   0]\n",
      " [  0   3  75   6]\n",
      " [  1   4 842  35]\n",
      " [  0   0 716  98]]\n",
      "\n",
      "accuracy\t0.5285874439461884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 11/100 Loss: 0.7514453242748986 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 350    1   17    6]\n",
      " [   7   12  173   21]\n",
      " [   9   14 2105  489]\n",
      " [   7    3 1418 1066]]\n",
      "\n",
      "accuracy\t0.62004212004212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 11/100 Loss: 0.8678880348601149 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  1   0   2   1]\n",
      " [  1   0  39  44]\n",
      " [  2   0 372 508]\n",
      " [  3   0 314 497]]\n",
      "\n",
      "accuracy\t0.4876681614349776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 12/100 Loss: 0.7364622838311381 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 358    3    6    7]\n",
      " [   6   10  170   27]\n",
      " [   7   13 2086  511]\n",
      " [   9    1 1389 1095]]\n",
      "\n",
      "accuracy\t0.6228501228501229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 12/100 Loss: 0.8789048099330723 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   0   2   2]\n",
      " [  1   0  48  35]\n",
      " [  3   0 421 458]\n",
      " [  2   0 326 486]]\n",
      "\n",
      "accuracy\t0.5084080717488789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 13/100 Loss: 0.7146087796510667 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 367    1    6    0]\n",
      " [   8   16  166   23]\n",
      " [   6   16 2108  487]\n",
      " [   4    1 1323 1166]]\n",
      "\n",
      "accuracy\t0.6418041418041418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 13/100 Loss: 0.8899341451480249 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   1   3   0]\n",
      " [  0   5  79   0]\n",
      " [  0  13 869   0]\n",
      " [  2   4 808   0]]\n",
      "\n",
      "accuracy\t0.4899103139013453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 14/100 Loss: 0.7199907773061567 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 351    1   21    1]\n",
      " [   5   22  164   22]\n",
      " [   5   13 2052  547]\n",
      " [   4    0 1305 1185]]\n",
      "\n",
      "accuracy\t0.6335556335556336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 14/100 Loss: 0.978017863804984 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   1   2   1]\n",
      " [  5   3  70   6]\n",
      " [ 17   1 845  19]\n",
      " [ 17   0 720  77]]\n",
      "\n",
      "accuracy\t0.5184977578475336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 15/100 Loss: 0.6988661303441539 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 363    4    6    1]\n",
      " [   8   26  157   22]\n",
      " [   5   19 2097  496]\n",
      " [   7    1 1238 1248]]\n",
      "\n",
      "accuracy\t0.6553176553176553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 15/100 Loss: 0.850870547473698 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   0   2   2]\n",
      " [  1   0  38  45]\n",
      " [  0   1 380 501]\n",
      " [  0   0 238 576]]\n",
      "\n",
      "accuracy\t0.5358744394618834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 16/100 Loss: 0.6860285465990965 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 368    4    2    0]\n",
      " [   5   29  160   19]\n",
      " [   6   21 2107  483]\n",
      " [   4    2 1225 1263]]\n",
      "\n",
      "accuracy\t0.6611091611091611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 16/100 Loss: 0.905499862448517 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   1   0   3]\n",
      " [  0   2  33  49]\n",
      " [  0   1 282 599]\n",
      " [  0   0 157 657]]\n",
      "\n",
      "accuracy\t0.5274663677130045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 17/100 Loss: 0.661245274340826 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 371    2    0    1]\n",
      " [   4   40  146   23]\n",
      " [   2   22 2096  497]\n",
      " [   6    5 1158 1325]]\n",
      "\n",
      "accuracy\t0.6725166725166725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 17/100 Loss: 0.8713830649318182 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   0   3   1]\n",
      " [  0   0  53  31]\n",
      " [  0   0 666 216]\n",
      " [  0   0 483 331]]\n",
      "\n",
      "accuracy\t0.5588565022421524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 18/100 Loss: 0.6474383507497941 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 364    6    3    1]\n",
      " [   6   43  141   23]\n",
      " [   3   27 2123  464]\n",
      " [   5    1 1120 1368]]\n",
      "\n",
      "accuracy\t0.6840996840996841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 18/100 Loss: 0.8632451165551027 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   0   3   1]\n",
      " [  0   1  58  25]\n",
      " [  1   1 704 176]\n",
      " [  0   0 518 296]]\n",
      "\n",
      "accuracy\t0.5610986547085202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 19/100 Loss: 0.647589805694516 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 366    2    5    1]\n",
      " [   7   49  136   21]\n",
      " [   4   22 2061  530]\n",
      " [   5    0 1034 1455]]\n",
      "\n",
      "accuracy\t0.6898911898911899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 19/100 Loss: 1.0335224043962132 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   1   2   1]\n",
      " [  0   8  50  26]\n",
      " [  6  22 704 150]\n",
      " [  6   7 530 271]]\n",
      "\n",
      "accuracy\t0.5510089686098655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 20/100 Loss: 0.6333619040872139 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 363    1    8    2]\n",
      " [   6   46  144   17]\n",
      " [   7   22 2160  428]\n",
      " [   7    2 1082 1403]]\n",
      "\n",
      "accuracy\t0.6970866970866971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 20/100 Loss: 1.0098059876684116 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   0   3   1]\n",
      " [  0   0  72  12]\n",
      " [  0   0 807  75]\n",
      " [  0   0 658 156]]\n",
      "\n",
      "accuracy\t0.5397982062780269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 21/100 Loss: 0.6180502682788283 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 369    0    5    0]\n",
      " [   5   60  128   20]\n",
      " [   1   24 2142  450]\n",
      " [   4    2 1051 1437]]\n",
      "\n",
      "accuracy\t0.7034047034047034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 21/100 Loss: 0.8549978174436252 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   0   3   1]\n",
      " [  0   0  59  25]\n",
      " [  0   0 685 197]\n",
      " [  0   0 502 312]]\n",
      "\n",
      "accuracy\t0.5588565022421524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 22/100 Loss: 0.5932615519814761 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 365    3    2    4]\n",
      " [   6   66  129   12]\n",
      " [   3   17 2209  388]\n",
      " [   4    1 1037 1452]]\n",
      "\n",
      "accuracy\t0.7181467181467182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 22/100 Loss: 2.3810579202768514 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   2   2   0]\n",
      " [  1  31  46   6]\n",
      " [  3 319 500  60]\n",
      " [  1 205 481 127]]\n",
      "\n",
      "accuracy\t0.3688340807174888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 23/100 Loss: 0.5928641860894714 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 365    2    5    2]\n",
      " [  11   61  121   20]\n",
      " [   4   18 2168  427]\n",
      " [   3    2  984 1505]]\n",
      "\n",
      "accuracy\t0.7193752193752194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 23/100 Loss: 1.2087765849725816 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   0   3   1]\n",
      " [  0   0  65  19]\n",
      " [  0   5 792  85]\n",
      " [  0   3 640 171]]\n",
      "\n",
      "accuracy\t0.5397982062780269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 24/100 Loss: 0.5720933968081636 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 364    6    4    0]\n",
      " [  12   63  122   16]\n",
      " [   1   19 2144  453]\n",
      " [   2    3  880 1609]]\n",
      "\n",
      "accuracy\t0.7335907335907336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 24/100 Loss: 0.9239076262365008 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   1   2   1]\n",
      " [  0   2  60  22]\n",
      " [  1   3 763 115]\n",
      " [  0   0 601 213]]\n",
      "\n",
      "accuracy\t0.5482062780269058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 25/100 Loss: 0.5743708532550704 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 358    2   11    3]\n",
      " [   7   76  117   13]\n",
      " [   2   23 2218  374]\n",
      " [   3    5  909 1577]]\n",
      "\n",
      "accuracy\t0.7421902421902422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 25/100 Loss: 1.0169354619065742 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   1   2   1]\n",
      " [  0   5  70   9]\n",
      " [  2   9 759 112]\n",
      " [  6  11 669 128]]\n",
      "\n",
      "accuracy\t0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1896814468.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# from ResTCN import ResTCN\n",
    "from ResTCN import ResTCN\n",
    "\n",
    "torch.manual_seed(0)\n",
    "num_epochs = 100\n",
    "batch_size = 4\n",
    "lr = .001\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device being used:\", device, flush=True)\n",
    "\n",
    "\n",
    "dataloader = get_dataloader(batch_size,\n",
    "                            'Train.csv',\n",
    "                            os.path.join(os.getcwd()),\n",
    "                            'Test.csv',\n",
    "                            os.path.join(os.getcwd()))\n",
    "dataset_sizes = {x: len(dataloader[x].dataset) for x in ['train', 'test']}\n",
    "print(dataset_sizes, flush=True)\n",
    "\n",
    "\n",
    "model = ResTCN().to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=.1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for phase in ['train', 'test']:\n",
    "\n",
    "        running_loss = .0\n",
    "        y_trues = np.empty([0])\n",
    "        y_preds = np.empty([0])\n",
    "\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        for inputs, labels in tqdm(dataloader[phase], disable=True):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.long().squeeze().to(device)\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            preds = torch.max(softmax(outputs), 1)[1]\n",
    "            y_trues = np.append(y_trues, labels.data.cpu().numpy())\n",
    "            y_preds = np.append(y_preds, preds.cpu())\n",
    "\n",
    "        # if phase == 'train':\n",
    "        #     scheduler.step()\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "        print(\"[{}] Epoch: {}/{} Loss: {} LR: {}\".format(\n",
    "            phase, epoch + 1, num_epochs, epoch_loss, scheduler.get_last_lr()), flush=True)\n",
    "        print('\\nconfusion matrix\\n' + str(confusion_matrix(y_trues, y_preds)))\n",
    "        print('\\naccuracy\\t' + str(accuracy_score(y_trues, y_preds)))\n",
    "\n",
    "torch.save(model, \"model-v2.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48eef98c-aa15-4da6-9dc8-f9edc5f524eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.5'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b54a6cbe-6dfe-4530-9997-74c985a29c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = torch.load(\"model-aug.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5746d987-e75f-4e22-bade-a39defbbfd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[  0   1   2   1]\n",
    " [  0   2  60  22]\n",
    " [  1   3 763 115]\n",
    " [  0   0 601 213]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab1ade98-e9b2-459b-980d-72610e040c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: [0.0, 0.3333333333333333, 0.5350631136044881, 0.6068376068376068]\n",
      "Recall: [0.0, 0.023809523809523808, 0.8650793650793651, 0.2616707616707617]\n",
      "Accuracy: 3.096412556053812\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(confusion_matrix):\n",
    "    # Assuming confusion_matrix is a 2D list of shape (n, n)\n",
    "    n = len(confusion_matrix)\n",
    "\n",
    "    # Calculate True Positives, False Positives, False Negatives, and True Negatives\n",
    "    tp = [confusion_matrix[i][i] for i in range(n)]\n",
    "    fp = [sum(confusion_matrix[j][i] for j in range(n) if j != i) for i in range(n)]\n",
    "    fn = [sum(confusion_matrix[i][j] for j in range(n) if j != i) for i in range(n)]\n",
    "    tn = [sum(confusion_matrix[i][j] for j in range(n) for i in range(n)) - tp[i] - fp[i] - fn[i] for i in range(n)]\n",
    "\n",
    "    # Calculate Precision, Recall, and Accuracy\n",
    "    precision = [tp[i] / (tp[i] + fp[i]) if (tp[i] + fp[i]) != 0 else 0 for i in range(n)]\n",
    "    recall = [tp[i] / (tp[i] + fn[i]) if (tp[i] + fn[i]) != 0 else 0 for i in range(n)]\n",
    "    accuracy = sum(tp[i] + tn[i] for i in range(n)) / sum(sum(row) for row in confusion_matrix)\n",
    "\n",
    "    return precision, recall, accuracy\n",
    "\n",
    "# Example usage:\n",
    "confusion_matrix = [\n",
    "    [  0 ,1 ,2 ,1],\n",
    "    [  0,2,60,22],\n",
    "    [  1,3,763,115],\n",
    "    [  0,0,601,213]\n",
    "]\n",
    "\n",
    "precision, recall, accuracy = calculate_metrics(confusion_matrix)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c46df782-a51c-475e-9cef-f8f0263eb328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(confusion_matrix):\n",
    "    true_positives = np.diag(confusion_matrix)\n",
    "    false_positives = np.sum(confusion_matrix, axis=0) - true_positives\n",
    "    false_negatives = np.sum(confusion_matrix, axis=1) - true_positives\n",
    "    true_negatives = np.sum(confusion_matrix) - (true_positives + false_positives + false_negatives)\n",
    "\n",
    "    accuracy = (true_positives + true_negatives) / np.sum(confusion_matrix)\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "    print(np.sum(true_positives+true_negatives) / np.sum(confusion_matrix) ) \n",
    "\n",
    "    return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5aa961e-5810-401b-a7c3-a23dcdf84feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.096412556053812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.99719731, 0.95179372, 0.56165919, 0.58576233]),\n",
       " array([0.        , 0.33333333, 0.53506311, 0.60683761]),\n",
       " array([0.        , 0.02380952, 0.86507937, 0.26167076]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(np.array(confusion_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff15b8-1dd0-4ea9-97c9-8ce9a7e388ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.48\n",
    "0.381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47c3eb23-c447-41e8-803d-c0551d3e8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_combines = [\n",
    "    [   1,0,3],\n",
    "    [   3,6,75],\n",
    "    [  13,24,1659]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ce56217-6b25-439d-9e3d-2be90f0d7b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.867713004484305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.98934978, 0.94282511, 0.93553812]),\n",
       " array([0.05882353, 0.2       , 0.95509499]),\n",
       " array([0.25      , 0.07142857, 0.97818396]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(np.array(conf_matrix_combines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f960fd-0d9d-49f2-a173-bbe0cabdcb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.40\n",
    "0.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6fd587-e5e4-4fa7-a567-556d326675a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e14a0e87-e2a0-47e1-9a0d-ae6e154c002a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy\t0.5061659192825112\n"
     ]
    }
   ],
   "source": [
    "print('\\naccuracy\\t' + str(accuracy_score(y_trues, y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcb704a1-f03f-420b-8fda-886b6b95b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix\n",
      "[[  0   0   1   3]\n",
      " [  0   2  33  49]\n",
      " [  2   0 378 502]\n",
      " [  2   1 288 523]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nconfusion matrix\\n' + str(confusion_matrix(y_trues, y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d374fa4-24df-4a3a-b0fa-fe24dfe2fcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix\n",
      "[[  1   0   0   3]\n",
      " [  3   6  33  42]\n",
      " [  6  14 319 543]\n",
      " [  7  10 269 528]]\n"
     ]
    }
   ],
   "source": [
    "# y_true_mod \n",
    "print('\\nconfusion matrix\\n' + str(confusion_matrix(y_trues, y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de370c95-d141-4274-80c8-8f198913c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_true_mod = np.copy(y_trues)\n",
    "y_pred_mod = np.copy(y_preds)\n",
    "\n",
    "y_true_mod[y_true_mod==3] = 2\n",
    "y_pred_mod[y_pred_mod==3] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c078cd8-d169-4ee6-8564-f10893ca88d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy\t0.9338565022421524\n"
     ]
    }
   ],
   "source": [
    "print('\\naccuracy\\t' + str(accuracy_score(y_true_mod, y_pred_mod)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a32f073-2b84-4b02-abce-d86f21eea80f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix\n",
      "[[   1    0    3]\n",
      " [   3    6   75]\n",
      " [  13   24 1659]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nconfusion matrix\\n' + str(confusion_matrix(y_true_mod, y_pred_mod)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db525314-085b-4122-8510-f4e8bd7be2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values with Counts:\n",
      "[[  0.   4.]\n",
      " [  1.  84.]\n",
      " [  2. 882.]\n",
      " [  3. 814.]]\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(y_trues, return_counts=True)\n",
    "\n",
    "# Combine unique values and counts\n",
    "unique_with_counts = np.column_stack((unique_values, counts))\n",
    "\n",
    "print(\"Unique Values with Counts:\")\n",
    "print(unique_with_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcd5f9d-a199-47e8-aaa6-b9dddc8cc318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af94687-d2ac-4afe-9c0b-3f8c903280d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08b9aba-2891-4de9-afe0-ebf2f27cc0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ea054-a7d9-4779-aacb-fa9fb3aed74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9a61e-3bef-4418-8ac0-cd6eaae5f12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d929ab24-2b31-42fb-bf59-400b6079ba9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a43523-6955-4e1e-9b56-d140e6bfcd87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa417f-9852-4568-91d0-1a9a231c6cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56f9c876-8034-4775-8de6-c4e4ac0ec809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# from ResTCN import ResTCN\n",
    "from ResTCN import ResTCN\n",
    "\n",
    "torch.manual_seed(0)\n",
    "num_epochs = 1\n",
    "batch_size = 4\n",
    "lr = .001\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device being used:\", device, flush=True)\n",
    "\n",
    "\n",
    "dataloader = get_dataloader(batch_size,\n",
    "                            'Train.csv',\n",
    "                            os.path.join(os.getcwd()),\n",
    "                            'Test.csv',\n",
    "                            os.path.join(os.getcwd()))\n",
    "dataset_sizes = {x: len(dataloader[x].dataset) for x in ['train', 'test']}\n",
    "print(dataset_sizes, flush=True)\n",
    "\n",
    "\n",
    "model = ResTCN().to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=.1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for phase in ['train', 'test']:\n",
    "\n",
    "        running_loss = .0\n",
    "        y_trues = np.empty([0])\n",
    "        y_preds = np.empty([0])\n",
    "\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        for inputs, labels in tqdm(dataloader[phase], disable=True):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.long().squeeze().to(device)\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            preds = torch.max(softmax(outputs), 1)[1]\n",
    "            y_trues = np.append(y_trues, labels.data.cpu().numpy())\n",
    "            y_preds = np.append(y_preds, preds.cpu())\n",
    "\n",
    "        # if phase == 'train':\n",
    "        #     scheduler.step()\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "        print(\"[{}] Epoch: {}/{} Loss: {} LR: {}\".format(\n",
    "            phase, epoch + 1, num_epochs, epoch_loss, scheduler.get_last_lr()), flush=True)\n",
    "        print('\\nconfusion matrix\\n' + str(confusion_matrix(y_trues, y_preds)))\n",
    "        print('\\naccuracy\\t' + str(accuracy_score(y_trues, y_preds)))\n",
    "\n",
    "# torch.save(model, \"model-v2.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6f95d55-901f-4f9e-9b8e-94747fba4958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cuda\n",
      "{'train': 5698, 'test': 1784}\n",
      "In init\n",
      "printing input shape\n",
      "torch.Size([4, 16, 3, 224, 224])\n",
      "printing z before transpose\n",
      "tensor([[[ 2.6490e-01,  6.4568e-01, -7.6464e-01,  ...,  1.2411e+00,\n",
      "          -4.1636e-01, -8.9891e-01],\n",
      "         [ 2.3127e-01,  6.1020e-01, -8.0479e-01,  ...,  1.3152e+00,\n",
      "          -4.3911e-01, -9.0772e-01],\n",
      "         [ 2.5385e-01,  6.9333e-01, -8.1505e-01,  ...,  1.2990e+00,\n",
      "          -4.7975e-01, -8.8040e-01],\n",
      "         ...,\n",
      "         [ 2.2413e-01,  8.3650e-01, -8.1287e-01,  ...,  1.4418e+00,\n",
      "          -4.6848e-01, -8.1583e-01],\n",
      "         [ 1.9923e-01,  7.4005e-01, -7.5658e-01,  ...,  1.3353e+00,\n",
      "          -4.4813e-01, -7.9885e-01],\n",
      "         [ 2.0489e-01,  6.7177e-01, -7.4626e-01,  ...,  1.3351e+00,\n",
      "          -4.2609e-01, -7.8578e-01]],\n",
      "\n",
      "        [[-9.9288e-01,  2.0541e-01, -7.2315e-01,  ...,  1.3025e+00,\n",
      "          -5.5616e-01, -1.4155e+00],\n",
      "         [-1.0772e+00,  2.2200e-01, -7.1238e-01,  ...,  1.2330e+00,\n",
      "          -5.6015e-01, -1.4154e+00],\n",
      "         [-1.0255e+00,  1.2521e-01, -6.8662e-01,  ...,  1.2074e+00,\n",
      "          -5.6516e-01, -1.4680e+00],\n",
      "         ...,\n",
      "         [-1.1294e+00, -1.4689e-02, -7.1267e-01,  ...,  1.2344e+00,\n",
      "          -6.1890e-01, -1.4578e+00],\n",
      "         [-1.0979e+00,  3.1163e-02, -7.3344e-01,  ...,  1.2509e+00,\n",
      "          -5.8037e-01, -1.4361e+00],\n",
      "         [-1.1069e+00,  1.1048e-01, -7.5721e-01,  ...,  1.2895e+00,\n",
      "          -6.1089e-01, -1.4774e+00]],\n",
      "\n",
      "        [[-5.5023e-01, -5.2044e-01, -7.5437e-01,  ...,  1.3010e+00,\n",
      "          -8.8480e-01, -3.0041e-01],\n",
      "         [-4.8038e-01, -5.4447e-01, -7.3488e-01,  ...,  1.3651e+00,\n",
      "          -8.3954e-01, -3.4031e-01],\n",
      "         [-5.1702e-01, -5.0768e-01, -7.3723e-01,  ...,  1.4107e+00,\n",
      "          -8.6963e-01, -2.9168e-01],\n",
      "         ...,\n",
      "         [-4.6966e-01, -4.8096e-01, -7.3602e-01,  ...,  1.2432e+00,\n",
      "          -9.2548e-01, -4.7409e-01],\n",
      "         [-4.8894e-01, -4.1969e-01, -7.6122e-01,  ...,  1.3432e+00,\n",
      "          -9.9079e-01, -4.8045e-01],\n",
      "         [-4.4933e-01, -4.2983e-01, -7.5325e-01,  ...,  1.3147e+00,\n",
      "          -1.0011e+00, -4.4750e-01]],\n",
      "\n",
      "        [[-1.5627e-02,  8.6935e-02, -3.2944e-01,  ...,  2.3950e+00,\n",
      "          -2.5780e-01, -6.8108e-01],\n",
      "         [ 1.9761e-02,  1.4948e-01, -3.1379e-01,  ...,  2.3243e+00,\n",
      "          -2.6996e-01, -6.4542e-01],\n",
      "         [-1.8732e-03,  1.2296e-01, -3.1345e-01,  ...,  2.2899e+00,\n",
      "          -2.3141e-01, -6.7565e-01],\n",
      "         ...,\n",
      "         [ 1.3211e-01,  7.8145e-02, -2.8284e-01,  ...,  2.3369e+00,\n",
      "          -1.1979e-01, -5.8047e-01],\n",
      "         [ 1.1911e-01,  8.5239e-02, -3.3606e-01,  ...,  2.3125e+00,\n",
      "          -1.1889e-01, -6.2310e-01],\n",
      "         [ 1.0044e-01,  6.7610e-02, -3.1340e-01,  ...,  2.2964e+00,\n",
      "          -8.5949e-02, -6.4025e-01]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "torch.Size([4, 16, 32])\n",
      "-------------------\n",
      "printing z after transpose\n",
      "tensor([[[ 2.6490e-01,  2.3127e-01,  2.5385e-01,  ...,  2.2413e-01,\n",
      "           1.9923e-01,  2.0489e-01],\n",
      "         [ 6.4568e-01,  6.1020e-01,  6.9333e-01,  ...,  8.3650e-01,\n",
      "           7.4005e-01,  6.7177e-01],\n",
      "         [-7.6464e-01, -8.0479e-01, -8.1505e-01,  ..., -8.1287e-01,\n",
      "          -7.5658e-01, -7.4626e-01],\n",
      "         ...,\n",
      "         [ 1.2411e+00,  1.3152e+00,  1.2990e+00,  ...,  1.4418e+00,\n",
      "           1.3353e+00,  1.3351e+00],\n",
      "         [-4.1636e-01, -4.3911e-01, -4.7975e-01,  ..., -4.6848e-01,\n",
      "          -4.4813e-01, -4.2609e-01],\n",
      "         [-8.9891e-01, -9.0772e-01, -8.8040e-01,  ..., -8.1583e-01,\n",
      "          -7.9885e-01, -7.8578e-01]],\n",
      "\n",
      "        [[-9.9288e-01, -1.0772e+00, -1.0255e+00,  ..., -1.1294e+00,\n",
      "          -1.0979e+00, -1.1069e+00],\n",
      "         [ 2.0541e-01,  2.2200e-01,  1.2521e-01,  ..., -1.4689e-02,\n",
      "           3.1163e-02,  1.1048e-01],\n",
      "         [-7.2315e-01, -7.1238e-01, -6.8662e-01,  ..., -7.1267e-01,\n",
      "          -7.3344e-01, -7.5721e-01],\n",
      "         ...,\n",
      "         [ 1.3025e+00,  1.2330e+00,  1.2074e+00,  ...,  1.2344e+00,\n",
      "           1.2509e+00,  1.2895e+00],\n",
      "         [-5.5616e-01, -5.6015e-01, -5.6516e-01,  ..., -6.1890e-01,\n",
      "          -5.8037e-01, -6.1089e-01],\n",
      "         [-1.4155e+00, -1.4154e+00, -1.4680e+00,  ..., -1.4578e+00,\n",
      "          -1.4361e+00, -1.4774e+00]],\n",
      "\n",
      "        [[-5.5023e-01, -4.8038e-01, -5.1702e-01,  ..., -4.6966e-01,\n",
      "          -4.8894e-01, -4.4933e-01],\n",
      "         [-5.2044e-01, -5.4447e-01, -5.0768e-01,  ..., -4.8096e-01,\n",
      "          -4.1969e-01, -4.2983e-01],\n",
      "         [-7.5437e-01, -7.3488e-01, -7.3723e-01,  ..., -7.3602e-01,\n",
      "          -7.6122e-01, -7.5325e-01],\n",
      "         ...,\n",
      "         [ 1.3010e+00,  1.3651e+00,  1.4107e+00,  ...,  1.2432e+00,\n",
      "           1.3432e+00,  1.3147e+00],\n",
      "         [-8.8480e-01, -8.3954e-01, -8.6963e-01,  ..., -9.2548e-01,\n",
      "          -9.9079e-01, -1.0011e+00],\n",
      "         [-3.0041e-01, -3.4031e-01, -2.9168e-01,  ..., -4.7409e-01,\n",
      "          -4.8045e-01, -4.4750e-01]],\n",
      "\n",
      "        [[-1.5627e-02,  1.9761e-02, -1.8732e-03,  ...,  1.3211e-01,\n",
      "           1.1911e-01,  1.0044e-01],\n",
      "         [ 8.6935e-02,  1.4948e-01,  1.2296e-01,  ...,  7.8145e-02,\n",
      "           8.5239e-02,  6.7610e-02],\n",
      "         [-3.2944e-01, -3.1379e-01, -3.1345e-01,  ..., -2.8284e-01,\n",
      "          -3.3606e-01, -3.1340e-01],\n",
      "         ...,\n",
      "         [ 2.3950e+00,  2.3243e+00,  2.2899e+00,  ...,  2.3369e+00,\n",
      "           2.3125e+00,  2.2964e+00],\n",
      "         [-2.5780e-01, -2.6996e-01, -2.3141e-01,  ..., -1.1979e-01,\n",
      "          -1.1889e-01, -8.5949e-02],\n",
      "         [-6.8108e-01, -6.4542e-01, -6.7565e-01,  ..., -5.8047e-01,\n",
      "          -6.2310e-01, -6.4025e-01]]], device='cuda:0',\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "torch.Size([4, 32, 16])\n",
      "-------------------\n",
      "printing y\n",
      "tensor([[[0.0412, 0.1173, 0.1151,  ..., 0.0434, 0.0445, 0.1722],\n",
      "         [0.1269, 0.1036, 0.1157,  ..., 0.1388, 0.1357, 0.1377],\n",
      "         [0.1160, 0.1030, 0.1203,  ..., 0.1354, 0.1640, 0.1302],\n",
      "         ...,\n",
      "         [0.0557, 0.0568, 0.0872,  ..., 0.0833, 0.0599, 0.0825],\n",
      "         [0.0592, 0.0704, 0.0213,  ..., 0.0376, 0.1969, 0.0499],\n",
      "         [0.0340, 0.0628, 0.0639,  ..., 0.3067, 0.2038, 0.0606]],\n",
      "\n",
      "        [[0.0516, 0.0974, 0.0766,  ..., 0.2674, 0.0546, 0.1317],\n",
      "         [0.1363, 0.1402, 0.1680,  ..., 0.1386, 0.1276, 0.0560],\n",
      "         [0.0874, 0.0838, 0.0758,  ..., 0.1324, 0.1058, 0.1258],\n",
      "         ...,\n",
      "         [0.0666, 0.0328, 0.0571,  ..., 0.0563, 0.0129, 0.0625],\n",
      "         [0.0803, 0.0651, 0.0882,  ..., 0.1584, 0.1649, 0.1828],\n",
      "         [0.0510, 0.0596, 0.0660,  ..., 0.0505, 0.0551, 0.0500]],\n",
      "\n",
      "        [[0.0630, 0.0840, 0.0856,  ..., 0.2970, 0.1673, 0.1861],\n",
      "         [0.1649, 0.1595, 0.2594,  ..., 0.1501, 0.1877, 0.1698],\n",
      "         [0.1108, 0.1084, 0.1248,  ..., 0.1776, 0.1229, 0.1333],\n",
      "         ...,\n",
      "         [0.0267, 0.0477, 0.0257,  ..., 0.0627, 0.0419, 0.0428],\n",
      "         [0.0571, 0.0286, 0.0779,  ..., 0.1561, 0.1934, 0.2060],\n",
      "         [0.0625, 0.0591, 0.0585,  ..., 0.0356, 0.2899, 0.1153]],\n",
      "\n",
      "        [[0.0720, 0.0944, 0.0711,  ..., 0.2506, 0.1935, 0.0651],\n",
      "         [0.1257, 0.1282, 0.1591,  ..., 0.1482, 0.1310, 0.1682],\n",
      "         [0.0676, 0.0504, 0.0437,  ..., 0.1031, 0.1192, 0.1074],\n",
      "         ...,\n",
      "         [0.0586, 0.0556, 0.0409,  ..., 0.0617, 0.0548, 0.0660],\n",
      "         [0.0363, 0.0599, 0.0804,  ..., 0.0414, 0.1424, 0.1744],\n",
      "         [0.0557, 0.0669, 0.0575,  ..., 0.1689, 0.1697, 0.0331]]],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "torch.Size([4, 128, 16])\n",
      "----------\n",
      "printing y sum along dim 2\n",
      "torch.Size([4, 128])\n",
      "torch.Size([4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1951303/260619403.py:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.max(softmax(outputs), 1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "printing input shape\n",
      "torch.Size([4, 16, 3, 224, 224])\n",
      "printing z before transpose\n",
      "tensor([[[-9.0812e-01,  3.2425e-01, -1.1335e+00,  ...,  1.5738e+00,\n",
      "          -2.2343e-02, -3.0762e-01],\n",
      "         [-8.7166e-01,  2.7194e-01, -1.1368e+00,  ...,  1.6885e+00,\n",
      "          -1.9232e-02, -3.0282e-01],\n",
      "         [-7.7375e-01,  3.2274e-01, -1.1702e+00,  ...,  1.5743e+00,\n",
      "          -3.5321e-02, -2.4089e-01],\n",
      "         ...,\n",
      "         [-1.0045e+00,  4.2009e-01, -1.2452e+00,  ...,  1.6912e+00,\n",
      "          -1.4274e-01, -1.3128e-01],\n",
      "         [-9.1295e-01,  4.7431e-01, -1.2426e+00,  ...,  1.6927e+00,\n",
      "          -5.3225e-02,  1.4605e-03],\n",
      "         [-8.1339e-01,  4.2340e-01, -1.1836e+00,  ...,  1.6204e+00,\n",
      "           6.6551e-02, -1.4055e-02]],\n",
      "\n",
      "        [[-6.9904e-01,  5.8570e-01, -1.4385e+00,  ...,  2.4265e+00,\n",
      "           6.8996e-02, -9.4630e-01],\n",
      "         [-6.5677e-01,  5.7836e-01, -1.4893e+00,  ...,  2.4733e+00,\n",
      "          -6.1878e-02, -9.9188e-01],\n",
      "         [-6.6010e-01,  5.8102e-01, -1.4218e+00,  ...,  2.4178e+00,\n",
      "          -1.4736e-02, -1.0068e+00],\n",
      "         ...,\n",
      "         [-6.0826e-01,  5.5152e-01, -1.3972e+00,  ...,  2.4923e+00,\n",
      "          -3.5248e-02, -1.0323e+00],\n",
      "         [-6.3621e-01,  4.5268e-01, -1.4099e+00,  ...,  2.4009e+00,\n",
      "          -1.1827e-01, -1.0425e+00],\n",
      "         [-6.2312e-01,  4.3490e-01, -1.3322e+00,  ...,  2.3285e+00,\n",
      "          -5.2548e-02, -1.0212e+00]],\n",
      "\n",
      "        [[-5.1319e-01,  4.0021e-01, -6.2796e-01,  ...,  5.3871e-01,\n",
      "          -4.4664e-01, -8.3324e-01],\n",
      "         [-4.8635e-01,  3.3258e-01, -6.0827e-01,  ...,  3.8018e-01,\n",
      "          -4.7146e-01, -8.2052e-01],\n",
      "         [-5.3284e-01,  3.1266e-01, -5.8837e-01,  ...,  4.2637e-01,\n",
      "          -4.2416e-01, -8.3454e-01],\n",
      "         ...,\n",
      "         [-4.4686e-01,  2.9700e-01, -5.7588e-01,  ...,  4.0315e-01,\n",
      "          -4.4934e-01, -7.4622e-01],\n",
      "         [-4.9251e-01,  2.2383e-01, -5.9907e-01,  ...,  3.8650e-01,\n",
      "          -4.2892e-01, -7.6999e-01],\n",
      "         [-4.7985e-01,  2.3997e-01, -5.3000e-01,  ...,  4.2004e-01,\n",
      "          -3.5148e-01, -7.5114e-01]],\n",
      "\n",
      "        [[ 2.7062e-01,  8.2053e-01, -2.4818e-01,  ...,  2.0319e+00,\n",
      "          -9.9542e-01, -1.7038e+00],\n",
      "         [ 8.0150e-02,  6.8317e-01, -3.4356e-01,  ...,  2.0046e+00,\n",
      "          -8.8858e-01, -1.9319e+00],\n",
      "         [ 1.0159e-01,  6.6378e-01, -3.5113e-01,  ...,  1.9909e+00,\n",
      "          -8.3438e-01, -1.8982e+00],\n",
      "         ...,\n",
      "         [ 1.1194e-01,  8.3554e-01, -1.5993e-01,  ...,  1.9422e+00,\n",
      "          -9.4103e-01, -1.5444e+00],\n",
      "         [ 7.8253e-02,  5.7620e-01,  3.1544e-02,  ...,  1.8554e+00,\n",
      "          -4.3626e-01, -1.8660e+00],\n",
      "         [ 7.3849e-02,  6.0082e-01,  1.5002e-02,  ...,  1.8188e+00,\n",
      "          -4.3028e-01, -1.8388e+00]]], device='cuda:0')\n",
      "torch.Size([4, 16, 32])\n",
      "-------------------\n",
      "printing z after transpose\n",
      "tensor([[[-9.0812e-01, -8.7166e-01, -7.7375e-01,  ..., -1.0045e+00,\n",
      "          -9.1295e-01, -8.1339e-01],\n",
      "         [ 3.2425e-01,  2.7194e-01,  3.2274e-01,  ...,  4.2009e-01,\n",
      "           4.7431e-01,  4.2340e-01],\n",
      "         [-1.1335e+00, -1.1368e+00, -1.1702e+00,  ..., -1.2452e+00,\n",
      "          -1.2426e+00, -1.1836e+00],\n",
      "         ...,\n",
      "         [ 1.5738e+00,  1.6885e+00,  1.5743e+00,  ...,  1.6912e+00,\n",
      "           1.6927e+00,  1.6204e+00],\n",
      "         [-2.2343e-02, -1.9232e-02, -3.5321e-02,  ..., -1.4274e-01,\n",
      "          -5.3225e-02,  6.6551e-02],\n",
      "         [-3.0762e-01, -3.0282e-01, -2.4089e-01,  ..., -1.3128e-01,\n",
      "           1.4605e-03, -1.4055e-02]],\n",
      "\n",
      "        [[-6.9904e-01, -6.5677e-01, -6.6010e-01,  ..., -6.0826e-01,\n",
      "          -6.3621e-01, -6.2312e-01],\n",
      "         [ 5.8570e-01,  5.7836e-01,  5.8102e-01,  ...,  5.5152e-01,\n",
      "           4.5268e-01,  4.3490e-01],\n",
      "         [-1.4385e+00, -1.4893e+00, -1.4218e+00,  ..., -1.3972e+00,\n",
      "          -1.4099e+00, -1.3322e+00],\n",
      "         ...,\n",
      "         [ 2.4265e+00,  2.4733e+00,  2.4178e+00,  ...,  2.4923e+00,\n",
      "           2.4009e+00,  2.3285e+00],\n",
      "         [ 6.8996e-02, -6.1878e-02, -1.4736e-02,  ..., -3.5248e-02,\n",
      "          -1.1827e-01, -5.2548e-02],\n",
      "         [-9.4630e-01, -9.9188e-01, -1.0068e+00,  ..., -1.0323e+00,\n",
      "          -1.0425e+00, -1.0212e+00]],\n",
      "\n",
      "        [[-5.1319e-01, -4.8635e-01, -5.3284e-01,  ..., -4.4686e-01,\n",
      "          -4.9251e-01, -4.7985e-01],\n",
      "         [ 4.0021e-01,  3.3258e-01,  3.1266e-01,  ...,  2.9700e-01,\n",
      "           2.2383e-01,  2.3997e-01],\n",
      "         [-6.2796e-01, -6.0827e-01, -5.8837e-01,  ..., -5.7588e-01,\n",
      "          -5.9907e-01, -5.3000e-01],\n",
      "         ...,\n",
      "         [ 5.3871e-01,  3.8018e-01,  4.2637e-01,  ...,  4.0315e-01,\n",
      "           3.8650e-01,  4.2004e-01],\n",
      "         [-4.4664e-01, -4.7146e-01, -4.2416e-01,  ..., -4.4934e-01,\n",
      "          -4.2892e-01, -3.5148e-01],\n",
      "         [-8.3324e-01, -8.2052e-01, -8.3454e-01,  ..., -7.4622e-01,\n",
      "          -7.6999e-01, -7.5114e-01]],\n",
      "\n",
      "        [[ 2.7062e-01,  8.0150e-02,  1.0159e-01,  ...,  1.1194e-01,\n",
      "           7.8253e-02,  7.3849e-02],\n",
      "         [ 8.2053e-01,  6.8317e-01,  6.6378e-01,  ...,  8.3554e-01,\n",
      "           5.7620e-01,  6.0082e-01],\n",
      "         [-2.4818e-01, -3.4356e-01, -3.5113e-01,  ..., -1.5993e-01,\n",
      "           3.1544e-02,  1.5002e-02],\n",
      "         ...,\n",
      "         [ 2.0319e+00,  2.0046e+00,  1.9909e+00,  ...,  1.9422e+00,\n",
      "           1.8554e+00,  1.8188e+00],\n",
      "         [-9.9542e-01, -8.8858e-01, -8.3438e-01,  ..., -9.4103e-01,\n",
      "          -4.3626e-01, -4.3028e-01],\n",
      "         [-1.7038e+00, -1.9319e+00, -1.8982e+00,  ..., -1.5444e+00,\n",
      "          -1.8660e+00, -1.8388e+00]]], device='cuda:0')\n",
      "torch.Size([4, 32, 16])\n",
      "-------------------\n",
      "printing y\n",
      "tensor([[[0.0291, 0.0805, 0.0785,  ..., 0.2045, 0.1918, 0.1900],\n",
      "         [0.0750, 0.0764, 0.0815,  ..., 0.1062, 0.1083, 0.1021],\n",
      "         [0.0987, 0.0947, 0.0907,  ..., 0.1013, 0.0929, 0.1048],\n",
      "         ...,\n",
      "         [0.0481, 0.0499, 0.0440,  ..., 0.0513, 0.0553, 0.0480],\n",
      "         [0.0634, 0.0653, 0.0724,  ..., 0.1280, 0.1314, 0.1394],\n",
      "         [0.0654, 0.0660, 0.0658,  ..., 0.0914, 0.0890, 0.0698]],\n",
      "\n",
      "        [[0.0167, 0.0626, 0.0490,  ..., 0.0477, 0.0621, 0.0785],\n",
      "         [0.0725, 0.0802, 0.1631,  ..., 0.1079, 0.1164, 0.1065],\n",
      "         [0.0570, 0.0543, 0.0543,  ..., 0.0679, 0.0653, 0.0661],\n",
      "         ...,\n",
      "         [0.0502, 0.0511, 0.0462,  ..., 0.0448, 0.0631, 0.0575],\n",
      "         [0.0646, 0.0662, 0.0724,  ..., 0.1496, 0.1346, 0.1512],\n",
      "         [0.0638, 0.0629, 0.0654,  ..., 0.0767, 0.0471, 0.0395]],\n",
      "\n",
      "        [[0.0371, 0.0370, 0.0342,  ..., 0.0361, 0.0346, 0.0337],\n",
      "         [0.0754, 0.0767, 0.1087,  ..., 0.1100, 0.1191, 0.1126],\n",
      "         [0.1030, 0.1051, 0.1037,  ..., 0.2242, 0.2246, 0.2170],\n",
      "         ...,\n",
      "         [0.0478, 0.0488, 0.0426,  ..., 0.0456, 0.0446, 0.0463],\n",
      "         [0.0616, 0.0616, 0.0695,  ..., 0.1318, 0.1282, 0.1396],\n",
      "         [0.0675, 0.0664, 0.0652,  ..., 0.0865, 0.0732, 0.0864]],\n",
      "\n",
      "        [[0.0054, 0.0552, 0.0537,  ..., 0.0570, 0.0607, 0.0248],\n",
      "         [0.0924, 0.0880, 0.1385,  ..., 0.1257, 0.1234, 0.1150],\n",
      "         [0.0437, 0.0473, 0.0447,  ..., 0.0645, 0.0682, 0.0714],\n",
      "         ...,\n",
      "         [0.0523, 0.0662, 0.0754,  ..., 0.0476, 0.0455, 0.0395],\n",
      "         [0.0625, 0.0625, 0.0686,  ..., 0.1537, 0.1487, 0.1642],\n",
      "         [0.0651, 0.0656, 0.0655,  ..., 0.0926, 0.0582, 0.0419]]],\n",
      "       device='cuda:0')\n",
      "torch.Size([4, 128, 16])\n",
      "----------\n",
      "printing y sum along dim 2\n",
      "torch.Size([4, 128])\n",
      "torch.Size([4, 4])\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# from ResTCN import ResTCN\n",
    "from ResTCN import ResTCN\n",
    "\n",
    "torch.manual_seed(0)\n",
    "num_epochs = 1\n",
    "batch_size = 4\n",
    "lr = .001\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device being used:\", device, flush=True)\n",
    "\n",
    "dataloader = get_dataloader(batch_size,\n",
    "                            'Train.csv',\n",
    "                            os.path.join(os.getcwd()),\n",
    "                            'Test.csv',\n",
    "                            os.path.join(os.getcwd()))\n",
    "dataset_sizes = {x: len(dataloader[x].dataset) for x in ['train', 'test']}\n",
    "print(dataset_sizes, flush=True)\n",
    "\n",
    "\n",
    "model = ResTCN().to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=.1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "model.train()\n",
    "\n",
    "phases = [\"train\",\"test\"]\n",
    "\n",
    "for phase in phases:\n",
    "    running_loss = .0\n",
    "    y_trues = np.empty([0])\n",
    "    y_preds = np.empty([0])\n",
    "\n",
    "    if phase == 'train':\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "        \n",
    "    for inputs, labels in tqdm(dataloader[phase], disable=True):\n",
    "        inputs = inputs.to(device)\n",
    "        print(\"printing input shape\")\n",
    "        print(inputs.shape)\n",
    "        labels = labels.long().squeeze().to(device)\n",
    "    \n",
    "        with torch.set_grad_enabled(phase == 'train'):\n",
    "            outputs = model(inputs).squeeze()\n",
    "            print(outputs.shape)\n",
    "            loss = criterion(outputs, labels)\n",
    "    \n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        preds = torch.max(softmax(outputs), 1)[1]\n",
    "        y_trues = np.append(y_trues, labels.data.cpu().numpy())\n",
    "        y_preds = np.append(y_preds, preds.cpu())\n",
    "        print(\"DONE\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23dd895d-1e8d-4ea4-9d3c-65802fc4cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0338,  0.0901, -0.1384],\n",
       "         [-0.2649,  0.0132, -0.1543]],\n",
       "\n",
       "        [[ 0.4264,  0.4951,  0.0973],\n",
       "         [-0.5939,  0.8031,  0.7879]],\n",
       "\n",
       "        [[-1.2858,  0.5795,  1.2327],\n",
       "         [ 0.9387, -1.4228, -1.0053]],\n",
       "\n",
       "        [[ 1.7012,  2.7311, -0.2984],\n",
       "         [-1.1312,  0.3651,  0.8213]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = torch.randn([4,2,3])\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34668a4e-aad8-409a-a2c9-7d43eeeb197b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9854, -0.4060],\n",
       "        [ 1.0189,  0.9971],\n",
       "        [ 0.5264, -1.4894],\n",
       "        [ 4.1340,  0.0552]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(vals, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d24593ed-b29c-4c4a-b582-41a0396aa1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResTCN(\n",
       "  (tcn): TemporalConvNet(\n",
       "    (network): Sequential(\n",
       "      (0): TemporalBlock(\n",
       "        (conv1): Conv1d(32, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(32, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (downsample): Conv1d(32, 128, kernel_size=(1,), stride=(1,))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): TemporalBlock(\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): TemporalBlock(\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(24,), dilation=(4,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(24,), dilation=(4,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(24,), dilation=(4,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(24,), dilation=(4,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (3): TemporalBlock(\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(48,), dilation=(8,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(48,), dilation=(8,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(48,), dilation=(8,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(48,), dilation=(8,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (4): TemporalBlock(\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(96,), dilation=(16,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(96,), dilation=(16,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(96,), dilation=(16,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(96,), dilation=(16,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (5): TemporalBlock(\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(192,), dilation=(32,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(192,), dilation=(32,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(192,), dilation=(32,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(192,), dilation=(32,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (6): TemporalBlock(\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(384,), dilation=(64,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(384,), dilation=(64,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(384,), dilation=(64,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(384,), dilation=(64,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (7): TemporalBlock(\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(768,), dilation=(128,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(768,), dilation=(128,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(768,), dilation=(128,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(768,), dilation=(128,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=128, out_features=4, bias=True)\n",
       "  (model_conv): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=32, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b201df3-9e84-4b24-afdf-5fd4df27acc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-p310-torch210-abx4kb",
   "language": "python",
   "name": "venv-p310-torch210-abx4kb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
